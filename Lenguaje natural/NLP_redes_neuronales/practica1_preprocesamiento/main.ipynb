{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text,Type,Source\\n', \"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...,Tweet,Hate Speech and Offensive Language Dataset\\n\", '!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!,Tweet,Hate Speech and Offensive Language Dataset\\n', '!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit,Tweet,Hate Speech and Offensive Language Dataset\\n', '!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny,Tweet,Hate Speech and Offensive Language Dataset\\n', '!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be f@ker than the bitch who told it to ya &#57361;,Tweet,Hate Speech and Offensive Language Dataset\\n', '\"!!!!!!!!!!!!!!!!!!\"\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"\"\",Tweet,Hate Speech and Offensive Language Dataset\\n', '@AppleSupport causing the reply to be disregarded and the tapped notification under the keyboard is openedüò°üò°üò°,Tweet,Customer Support on Twitter Dataset\\n', '\"@105835 Your business means a lot to us. Please DM your name, zip code and additional details about your concern. ^RR https://t.co/znUu1VJn9r\",Tweet,Customer Support on Twitter Dataset\\n', \"@76328 I really hope you all change but I'm sure you won't! Because you don't have to!,Tweet,Customer Support on Twitter Dataset\\n\", '\"@105836 LiveChat is online at the moment - https://t.co/SY94VtU8Kq or contact 03331 031 031 option 1, 4, 3 (Leave a message) to request a call back\",Tweet,Customer Support on Twitter Dataset\\n', \"@VirginTrains see attached error message. I've tried leaving a voicemail several times in the past week https://t.co/NxVZjlYx1k,Tweet,Customer Support on Twitter Dataset\\n\", '\"@105836 Have you tried from another device, Miriam ^MM\",Tweet,Customer Support on Twitter Dataset\\n', '\"@VirginTrains yep, I\\'ve tried laptop too several times over the past week and again today. I\\'ve tried different browsers too\",Tweet,Customer Support on Twitter Dataset\\n', '\"@105836 It\\'s working OK from here, Miriam. Does this link help https://t.co/0m2mpH15eh ? ^MM\",Tweet,Customer Support on Twitter Dataset\\n', '\"Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"\"Who was that singing ?\"\"\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n', '\"One of the best game music soundtracks - for a game I didn\\'t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there\\'s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren\\'t included I would still consider the collection worth it.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n', '\"Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n', '\"works fine, but Maha Energy is better: Check out Maha Energy\\'s website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n', '\"Great for the non-audiophile: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don\\'t want to replace them with DVD\\'s. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n', '\"DVD Player crapped out after one year: I also began having the incorrect disc problems that I\\'ve read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that\\'s a sign on bad quality. I\\'m giving up JVC after this as well. I\\'m sticking to Sony or giving another brand a shot.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n', 'Amber Smith ‚ÄúKandy Halloween: Return of the Haunted Mansion‚Äù Red Carpet #URL# via #USER#,Tweet,Fake News Detection Corpus\\n', '\"\"\"RT Reuters \"\"\"\"Russia: Pence Balkans comments expose Washington\\'s Cold War ideology #URL# #URL#\"\"\"\"\"\"\",Tweet,Fake News Detection Corpus\\n', 'Jennifer Lopez and Alex Rodriguez Step Out for the First Time at the 2019 Met Gala as an Engaged Couple #URL#,Tweet,Fake News Detection Corpus\\n', '\"\"\"92nd #HASHTAG# delayed in Brisbane, Adelaide &amp; Perth. #HASHTAG# #URL# #URL#\"\"\",Tweet,Fake News Detection Corpus\\n', '#HASHTAG# to represent Australia at #HASHTAG# 2020! #HASHTAG# #URL# #URL#,Tweet,Fake News Detection Corpus\\n', '\"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.\\\\n\",wiki,Wikipedia\\n', '\"Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\\\n\",wiki,Wikipedia\\n', '\"Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"\"Computing Machinery and Intelligence\"\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\\\n\",wiki,Wikipedia\\n', '\"The premise of symbolic NLP is well-summarized by John Searle\\'s Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\\\n\",wiki,Wikipedia\\n', '\"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[7]\\\\n\",wiki,Wikipedia\\n', '\"  In neuropsychology, linguistics, and philosophy of language, a natural language or ordinary language is any language that occurs naturally in a human community by a process of use, repetition, and change without conscious planning or premeditation. It can take different forms, namely either a spoken language or a sign language. Natural languages are distinguished from constructed and formal languages such as those used to program computers or to study logic.[1]\",wiki,Wikipedia\\n', '\"All varieties of world languages are natural languages, including those that are associated with linguistic prescriptivism or language regulation. (Nonstandard dialects can be viewed as a wild type in comparison with standard languages.) An official language with a regulating academy such as Standard French, overseen by the Acad√©mie Fran√ßaise, is classified as a natural language (e.g. in the field of natural language processing), as its prescriptive aspects do not make it constructed enough to be a constructed language or controlled enough to be a controlled natural language.\",wiki,Wikipedia\\n', '\"Controlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce ambiguity and complexity. This may be accomplished by decreasing usage of superlative or adverbial forms, or irregular verbs. Typical purposes for developing and implementing a controlled natural language are to aid understanding by non-native speakers or to ease computer processing. An example of a widely-used controlled natural language is Simplified Technical English, which was originally developed for aerospace and avionics industry manuals.\",wiki,Wikipedia\\n', '\"Being constructed, International auxiliary languages such as Esperanto and Interlingua are not considered natural languages, with the possible exception of true native speakers of such languages.[3] Natural languages evolve, through fluctuations in vocabulary and syntax, to incrementally improve human communication. In contrast, Esperanto was created by Polish ophthalmologist L. L. Zamenhof in the late 19th century.\",wiki,Wikipedia\\n', '\"Some natural languages have become organically \"\"standardized\"\" through the synthesis of two or more pre-existing natural languages over a relatively short period of time through the development of a pidgin, which is not considered a language, into a stable creole language. A creole such as Haitian Creole has its own grammar, vocabulary and literature. It is spoken by over 10 million people worldwide and is one of the two official languages of the Republic of Haiti.\",wiki,Wikipedia']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"src/Sample Texts - Hoja 1.csv\", 'r+', encoding='utf-8', errors='ignore')\n",
    "textos = file.readlines()\n",
    "\n",
    "print(textos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a filtrar con expresiones regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creamos los patrones para las expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuario = re.compile(r\"@[A-Za-z0-9_]+:?\")\n",
    "retweet = re.compile(r\"!*\\s?RT \")\n",
    "enlace = re.compile(r\"https?://.+\")\n",
    "emogi = re.compile(r\"[üòÄüòÉüòÑüòÅüòÜüòÖü§£üòÇüôÇüôÉüòâüòäüòáü•∞üòçü§©üòòüòó‚ò∫üòöüòôüòãüòõüòúü§™üòùü§ëü§óü§≠ü§´ü§îü§êü§®üòêüòëüò∂üòèüòíüôÑüò¨ü§•üòåüòîüò™ü§§üò¥üò∑ü§íü§ïü§¢ü§Æü§ßü•µü•∂ü•¥üòµü§Øü§†ü•≥üòéü§ìüßêüòïüòüüôÅ‚òπüòÆüòØüò≤üò≥ü•∫üò¶üòßüò®üò∞üò•üò¢üò≠üò±üòñüò£üòûüòìüò©üò´üò§üò†ü§¨üòàüëøüíÄ‚ò†üí©ü§°üëπüë∫üëªüëΩüëæü§ñüò∫üò∏üòπüòªüòºüòΩüôÄüòøüòæüôàüôâüôäüíãüíåüíòüíùüíñüíóüíìüíûüíïüíü‚ù£üíî‚ù§üß°üíõüíöüíôüíúüñ§üíØüí¢üí•üí´üí¶üí®üï≥üí£üí¨üëÅÔ∏è‚Äçüó®Ô∏èüó®üóØüí≠üí§üëãü§öüñê‚úãüññüëå‚úåü§ûü§üü§òü§ôüëàüëâüëÜüñïüëá‚òùüëçüëé‚úäüëäü§õü§úüëèüôåüëêü§≤ü§ùüôè‚úçüíÖü§≥üí™ü¶µü¶∂üëÇüëÉüß†ü¶∑ü¶¥üëÄüëÅüëÖüëÑüë∂üßíüë¶üëßüßëüë±üë®üßîüë±‚Äç‚ôÇÔ∏èüë®‚Äçü¶∞üë®‚Äçü¶±üë®‚Äçü¶≥üë®‚Äçü¶≤üë©üë±‚Äç‚ôÄÔ∏èüë©‚Äçü¶∞üë©‚Äçü¶±üë©‚Äçü¶≥üë©‚Äçü¶≤üßìüë¥üëµüôçüôç‚Äç‚ôÇÔ∏èüôç‚Äç‚ôÄÔ∏èüôéüôé‚Äç‚ôÇÔ∏èüôé‚Äç‚ôÄÔ∏èüôÖüôÖ‚Äç‚ôÇÔ∏èüôÖ‚Äç‚ôÄÔ∏èüôÜüôÜ‚Äç‚ôÇÔ∏èüôÜ‚Äç‚ôÄÔ∏èüíÅüíÅ‚Äç‚ôÇÔ∏èüíÅ‚Äç‚ôÄÔ∏èüôãüôã‚Äç‚ôÇÔ∏èüôã‚Äç‚ôÄÔ∏èüôáüôá‚Äç‚ôÇÔ∏èüôá‚Äç‚ôÄÔ∏èü§¶ü§¶‚Äç‚ôÇÔ∏èü§¶‚Äç‚ôÄÔ∏èü§∑ü§∑‚Äç‚ôÇÔ∏èü§∑‚Äç‚ôÄÔ∏èüë®‚Äç‚öïÔ∏èüë©‚Äç‚öïÔ∏èüë®‚Äçüéìüë©‚Äçüéìüë®‚Äçüè´üë©‚Äçüè´üë®‚Äç‚öñÔ∏èüë©‚Äç‚öñÔ∏èüë®‚Äçüåæüë©‚Äçüåæüë®‚Äçüç≥üë©‚Äçüç≥üë®‚Äçüîßüë©‚Äçüîßüë®‚Äçüè≠üë©‚Äçüè≠üë®‚Äçüíºüë©‚Äçüíºüë®‚Äçüî¨üë©‚Äçüî¨üë®‚Äçüíªüë©‚Äçüíªüë®‚Äçüé§üë©‚Äçüé§üë®‚Äçüé®üë©‚Äçüé®üë®‚Äç‚úàÔ∏èüë©‚Äç‚úàÔ∏èüë®‚ÄçüöÄüë©‚ÄçüöÄüë®‚Äçüöíüë©‚ÄçüöíüëÆüëÆ‚Äç‚ôÇÔ∏èüëÆ‚Äç‚ôÄÔ∏èüïµüïµÔ∏è‚Äç‚ôÇÔ∏èüïµÔ∏è‚Äç‚ôÄÔ∏èüíÇüíÇ‚Äç‚ôÇÔ∏èüíÇ‚Äç‚ôÄÔ∏èüë∑üë∑‚Äç‚ôÇÔ∏èüë∑‚Äç‚ôÄÔ∏èü§¥üë∏üë≥üë≥‚Äç‚ôÇÔ∏èüë≥‚Äç‚ôÄÔ∏èüë≤üßïü§µüë∞ü§∞ü§±üëºüéÖü§∂ü¶∏ü¶∏‚Äç‚ôÇÔ∏èü¶∏‚Äç‚ôÄÔ∏èü¶πü¶π‚Äç‚ôÇÔ∏èü¶π‚Äç‚ôÄÔ∏èüßôüßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏èüßöüßö‚Äç‚ôÇÔ∏èüßö‚Äç‚ôÄÔ∏èüßõüßõ‚Äç‚ôÇÔ∏èüßõ‚Äç‚ôÄÔ∏èüßúüßú‚Äç‚ôÇÔ∏èüßú‚Äç‚ôÄÔ∏èüßùüßù‚Äç‚ôÇÔ∏èüßù‚Äç‚ôÄÔ∏èüßûüßû‚Äç‚ôÇÔ∏èüßû‚Äç‚ôÄÔ∏èüßüüßü‚Äç‚ôÇÔ∏èüßü‚Äç‚ôÄÔ∏èüíÜüíÜ‚Äç‚ôÇÔ∏èüíÜ‚Äç‚ôÄÔ∏èüíáüíá‚Äç‚ôÇÔ∏èüíá‚Äç‚ôÄÔ∏èüö∂üö∂‚Äç‚ôÇÔ∏èüö∂‚Äç‚ôÄÔ∏èüèÉüèÉ‚Äç‚ôÇÔ∏èüèÉ‚Äç‚ôÄÔ∏èüíÉüï∫üï¥üëØüëØ‚Äç‚ôÇÔ∏èüëØ‚Äç‚ôÄÔ∏èüßñüßñ‚Äç‚ôÇÔ∏èüßñ‚Äç‚ôÄÔ∏èüßóüßó‚Äç‚ôÇÔ∏èüßó‚Äç‚ôÄÔ∏èü§∫üèá‚õ∑üèÇüèåüèåÔ∏è‚Äç‚ôÇÔ∏èüèåÔ∏è‚Äç‚ôÄÔ∏èüèÑüèÑ‚Äç‚ôÇÔ∏èüèÑ‚Äç‚ôÄÔ∏èüö£üö£‚Äç‚ôÇÔ∏èüö£‚Äç‚ôÄÔ∏èüèäüèä‚Äç‚ôÇÔ∏èüèä‚Äç‚ôÄÔ∏è‚õπ‚õπÔ∏è‚Äç‚ôÇÔ∏è‚õπÔ∏è‚Äç‚ôÄÔ∏èüèãüèãÔ∏è‚Äç‚ôÇÔ∏èüèãÔ∏è‚Äç‚ôÄÔ∏èüö¥üö¥‚Äç‚ôÇÔ∏èüö¥‚Äç‚ôÄÔ∏èüöµüöµ‚Äç‚ôÇÔ∏èüöµ‚Äç‚ôÄÔ∏èü§∏ü§∏‚Äç‚ôÇÔ∏èü§∏‚Äç‚ôÄÔ∏èü§ºü§º‚Äç‚ôÇÔ∏èü§º‚Äç‚ôÄÔ∏èü§Ωü§Ω‚Äç‚ôÇÔ∏èü§Ω‚Äç‚ôÄÔ∏èü§æü§æ‚Äç‚ôÇÔ∏èü§æ‚Äç‚ôÄÔ∏èü§πü§π‚Äç‚ôÇÔ∏èü§π‚Äç‚ôÄÔ∏èüßòüßò‚Äç‚ôÇÔ∏èüßò‚Äç‚ôÄÔ∏èüõÄüõåüë≠üë´üë¨üíèüë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©üíëüë©‚Äç‚ù§Ô∏è‚Äçüë®üë®‚Äç‚ù§Ô∏è‚Äçüë®üë©‚Äç‚ù§Ô∏è‚Äçüë©üë™üë®‚Äçüë©‚Äçüë¶üë®‚Äçüë©‚Äçüëßüë®‚Äçüë©‚Äçüëß‚Äçüë¶üë®‚Äçüë©‚Äçüë¶‚Äçüë¶üë®‚Äçüë©‚Äçüëß‚Äçüëßüë®‚Äçüë®‚Äçüë¶üë®‚Äçüë®‚Äçüëßüë®‚Äçüë®‚Äçüëß‚Äçüë¶üë®‚Äçüë®‚Äçüë¶‚Äçüë¶üë®‚Äçüë®‚Äçüëß‚Äçüëßüë©‚Äçüë©‚Äçüë¶üë©‚Äçüë©‚Äçüëßüë©‚Äçüë©‚Äçüëß‚Äçüë¶üë©‚Äçüë©‚Äçüë¶‚Äçüë¶üë©‚Äçüë©‚Äçüëß‚Äçüëßüë®‚Äçüë¶üë®‚Äçüë¶‚Äçüë¶üë®‚Äçüëßüë®‚Äçüëß‚Äçüë¶üë®‚Äçüëß‚Äçüëßüë©‚Äçüë¶üë©‚Äçüë¶‚Äçüë¶üë©‚Äçüëßüë©‚Äçüëß‚Äçüë¶üë©‚Äçüëß‚Äçüëßüó£üë§üë•üë£ü¶∞ü¶±ü¶≥ü¶≤üêµüêíü¶çüê∂üêïüê©üê∫ü¶äü¶ùüê±üêàü¶ÅüêØüêÖüêÜüê¥üêéü¶Ñü¶ìü¶åüêÆüêÇüêÉüêÑüê∑üêñüêóüêΩüêèüêëüêêüê™üê´ü¶ôü¶íüêòü¶èü¶õüê≠üêÅüêÄüêπüê∞üêáüêøü¶îü¶áüêªüê®üêºü¶òü¶°üêæü¶Éüêîüêìüê£üê§üê•üê¶üêßüïäü¶Öü¶Üü¶¢ü¶âü¶öü¶úüê∏üêäüê¢ü¶éüêçüê≤üêâü¶ïü¶ñüê≥üêãüê¨üêüüê†üê°ü¶àüêôüêöüêåü¶ãüêõüêúüêùüêûü¶óüï∑üï∏ü¶Çü¶üü¶†üíêüå∏üíÆüèµüåπü•Äüå∫üåªüåºüå∑üå±üå≤üå≥üå¥üåµüåæüåø‚òòüçÄüçÅüçÇüçÉüçáüçàüçâüçäüçãüçåüççü•≠üçéüçèüçêüçëüçíüçìü•ùüçÖü••ü•ëüçÜü•îü•ïüåΩüå∂ü•íü•¨ü•¶üçÑü•úüå∞üçûü•êü•ñü•®ü•Øü•ûüßÄüçñüçóü•©ü•ìüçîüçüüçïüå≠ü•™üåÆüåØü•ôü•öüç≥ü•òüç≤ü•£ü•óüçøüßÇü•´üç±üçòüçôüçöüçõüçúüçùüç†üç¢üç£üç§üç•ü•Æüç°ü•üü•†ü•°ü¶Äü¶ûü¶êü¶ëüç¶üçßüç®üç©üç™üéÇüç∞üßÅü•ßüç´üç¨üç≠üçÆüçØüçºü•õ‚òïüçµüç∂üçæüç∑üç∏üçπüç∫üçªü•Çü•Éü•§ü•¢üçΩüç¥ü•Ñüî™üè∫üåçüåéüåèüåêüó∫üóæüß≠üèî‚õ∞üåãüóªüèïüèñüèúüèùüèûüèüüèõüèóüß±üèòüèöüè†üè°üè¢üè£üè§üè•üè¶üè®üè©üè™üè´üè¨üè≠üèØüè∞üííüóºüóΩ‚õ™üïåüïç‚õ©üïã‚õ≤‚õ∫üåÅüåÉüèôüåÑüåÖüåÜüåáüåâ‚ô®üååüé†üé°üé¢üíàüé™üöÇüöÉüöÑüöÖüöÜüöáüöàüöâüöäüöùüöûüöãüöåüöçüöéüöêüöëüöíüöìüöîüöïüöñüöóüöòüöôüööüöõüöúüèéüèçüõµüö≤üõ¥üõπüöèüõ£üõ§üõ¢‚õΩüö®üö•üö¶üõëüöß‚öì‚õµüõ∂üö§üõ≥‚õ¥üõ•üö¢‚úàüõ©üõ´üõ¨üí∫üöÅüöüüö†üö°üõ∞üöÄüõ∏üõéüß≥‚åõ‚è≥‚åö‚è∞‚è±‚è≤üï∞üïõüïßüïêüïúüïëüïùüïíüïûüïìüïüüïîüï†üïïüï°üïñüï¢üïóüï£üïòüï§üïôüï•üïöüï¶üåëüåíüåìüåîüåïüåñüåóüåòüåôüåöüåõüåúüå°‚òÄüåùüåû‚≠êüåüüå†‚òÅ‚õÖ‚õàüå§üå•üå¶üåßüå®üå©üå™üå´üå¨üåÄüåàüåÇ‚òÇ‚òî‚õ±‚ö°‚ùÑ‚òÉ‚õÑ‚òÑüî•üíßüåäüéÉüéÑüéÜüéáüß®‚ú®üéàüéâüéäüéãüéçüééüéèüéêüéëüßßüéÄüéÅüéóüéüüé´üéñüèÜüèÖü•áü•àü•â‚öΩ‚öæü•éüèÄüèêüèàüèâüéæü•èüé≥üèèüèëüèíü•çüèìüè∏ü•äü•ãü•Ö‚õ≥‚õ∏üé£üéΩüéøüõ∑ü•åüéØüé±üîÆüßøüéÆüïπüé∞üé≤üß©üß∏‚ô†‚ô•‚ô¶‚ô£‚ôüüÉèüÄÑüé¥üé≠üñºüé®üßµüß∂üëìüï∂ü•Ωü•ºüëîüëïüëñüß£üß§üß•üß¶üëóüëòüëôüëöüëõüëúüëùüõçüéíüëûüëüü•æü•øüë†üë°üë¢üëëüëíüé©üéìüß¢‚õëüìøüíÑüíçüíéüîáüîàüîâüîäüì¢üì£üìØüîîüîïüéºüéµüé∂üéôüéöüéõüé§üéßüìªüé∑üé∏üéπüé∫üéªü•Åüì±üì≤‚òéüìûüìüüì†üîãüîåüíªüñ•üñ®‚å®üñ±üñ≤üíΩüíæüíøüìÄüßÆüé•üéûüìΩüé¨üì∫üì∑üì∏üìπüìºüîçüîéüïØüí°üî¶üèÆüìîüìïüìñüìóüìòüìôüìöüììüìíüìÉüìúüìÑüì∞üóûüìëüîñüè∑üí∞üí¥üíµüí∂üí∑üí∏üí≥üßæüíπüí±üí≤‚úâüìßüì®üì©üì§üì•üì¶üì´üì™üì¨üì≠üìÆüó≥‚úè‚úíüñãüñäüñåüñçüìùüíºüìÅüìÇüóÇüìÖüìÜüóíüóìüìáüìàüìâüìäüìãüìåüìçüìéüñáüìèüìê‚úÇüóÉüóÑüóëüîíüîìüîèüîêüîëüóùüî®‚õè‚öíüõ†üó°‚öîüî´üèπüõ°üîßüî©‚öôüóú‚öñüîó‚õìüß∞üß≤‚öóüß™üß´üß¨üî¨üî≠üì°üíâüíäüö™üõèüõãüöΩüöøüõÅüß¥üß∑üßπüß∫üßªüßºüßΩüßØüõíüö¨‚ö∞‚ö±üóøüèßüöÆüö∞‚ôøüöπüö∫üöªüöºüöæüõÇüõÉüõÑüõÖ‚ö†üö∏‚õîüö´üö≥üö≠üöØüö±üö∑üìµüîû‚ò¢‚ò£‚¨Ü‚Üó‚û°‚Üò‚¨á‚Üô‚¨Ö‚Üñ‚Üï‚Üî‚Ü©‚Ü™‚§¥‚§µüîÉüîÑüîôüîöüîõüîúüîùüõê‚öõüïâ‚ú°‚ò∏‚òØ‚úù‚ò¶‚ò™‚òÆüïéüîØ‚ôà‚ôâ‚ôä‚ôã‚ôå‚ôç‚ôé‚ôè‚ôê‚ôë‚ôí‚ôì‚õéüîÄüîÅüîÇ‚ñ∂‚è©‚è≠‚èØ‚óÄ‚è™‚èÆüîº‚è´üîΩ‚è¨‚è∏‚èπ‚è∫‚èèüé¶üîÖüîÜüì∂üì≥üì¥‚ôÄ‚ôÇ‚öï‚ôæ‚ôª‚öúüî±üìõüî∞‚≠ï‚úÖ‚òë‚úî‚úñ‚ùå‚ùé‚ûï‚ûñ‚ûó‚û∞‚ûø„ÄΩ‚ú≥‚ú¥‚ùá‚Äº‚Åâ‚ùì‚ùî‚ùï‚ùó„Ä∞¬©¬Æ‚Ñ¢üîüüî†üî°üî¢üî£üî§üÖ∞üÜéüÖ±üÜëüÜíüÜìüÜî‚ìÇüÜïüÜñüÖæüÜóüÖøüÜòüÜôüÜöüàÅüàÇüà∑üà∂üàØüâêüàπüàöüà≤üâëüà∏üà¥üà≥„äó„äôüà∫üàµüî¥üîµ‚ö™‚ö´‚¨ú‚¨õ‚óº‚óª‚óΩ‚óæ‚ñ´‚ñ™üî∂üî∑üî∏üîπüî∫üîªüí†üîòüî≤üî≥üèÅüö©üéåüè¥üè≥üè≥Ô∏è‚Äçüåàüè¥‚Äç‚ò†Ô∏èüá¶üá®üá¶üá©üá¶üá™üá¶üá´üá¶üá¨üá¶üáÆüá¶üá±üá¶üá≤üá¶üá¥üá¶üá∂üá¶üá∑üá¶üá∏üá¶üáπüá¶üá∫üá¶üáºüá¶üáΩüá¶üáøüáßüá¶üáßüáßüáßüá©üáßüá™üáßüá´üáßüá¨üáßüá≠üáßüáÆüáßüáØüáßüá±üáßüá≤üáßüá≥üáßüá¥üáßüá∂üáßüá∑üáßüá∏üáßüáπüáßüáªüáßüáºüáßüáæüáßüáøüá®üá¶üá®üá®üá®üá©üá®üá´üá®üá¨üá®üá≠üá®üáÆüá®üá∞üá®üá±üá®üá≤üá®üá≥üá®üá¥üá®üáµüá®üá∑üá®üá∫üá®üáªüá®üáºüá®üáΩüá®üáæüá®üáøüá©üá™üá©üá¨üá©üáØüá©üá∞üá©üá≤üá©üá¥üá©üáøüá™üá¶üá™üá®üá™üá™üá™üá¨üá™üá≠üá™üá∑üá™üá∏üá™üáπüá™üá∫üá´üáÆüá´üáØüá´üá∞üá´üá≤üá´üá¥üá´üá∑üá¨üá¶üá¨üáßüá¨üá©üá¨üá™üá¨üá´üá¨üá¨üá¨üá≠üá¨üáÆüá¨üá±üá¨üá≤üá¨üá≥üá¨üáµüá¨üá∂üá¨üá∑üá¨üá∏üá¨üáπüá¨üá∫üá¨üáºüá¨üáæüá≠üá∞üá≠üá≤üá≠üá≥üá≠üá∑üá≠üáπüá≠üá∫üáÆüá®üáÆüá©üáÆüá™üáÆüá±üáÆüá≤üáÆüá≥üáÆüá¥üáÆüá∂üáÆüá∑üáÆüá∏üáÆüáπüáØüá™üáØüá≤üáØüá¥üáØüáµüá∞üá™üá∞üá¨üá∞üá≠üá∞üáÆüá∞üá≤üá∞üá≥üá∞üáµüá∞üá∑üá∞üáºüá∞üáæüá∞üáøüá±üá¶üá±üáßüá±üá®üá±üáÆüá±üá∞üá±üá∑üá±üá∏üá±üáπüá±üá∫üá±üáªüá±üáæüá≤üá¶üá≤üá®üá≤üá©üá≤üá™üá≤üá´üá≤üá¨üá≤üá≠üá≤üá∞üá≤üá±üá≤üá≤üá≤üá≥üá≤üá¥üá≤üáµüá≤üá∂üá≤üá∑üá≤üá∏üá≤üáπüá≤üá∫üá≤üáªüá≤üáºüá≤üáΩüá≤üáæüá≤üáøüá≥üá¶üá≥üá®üá≥üá™üá≥üá´üá≥üá¨üá≥üáÆüá≥üá±üá≥üá¥üá≥üáµüá≥üá∑üá≥üá∫üá≥üáøüá¥üá≤üáµüá¶üáµüá™üáµüá´üáµüá¨üáµüá≠üáµüá∞üáµüá±üáµüá≤üáµüá≥üáµüá∑üáµüá∏üáµüáπüáµüáºüáµüáæüá∂üá¶üá∑üá™üá∑üá¥üá∑üá∏üá∑üá∫üá∑üáºüá∏üá¶üá∏üáßüá∏üá®üá∏üá©üá∏üá™üá∏üá¨üá∏üá≠üá∏üáÆüá∏üáØüá∏üá∞üá∏üá±üá∏üá≤üá∏üá≥üá∏üá¥üá∏üá∑üá∏üá∏üá∏üáπüá∏üáªüá∏üáΩüá∏üáæüá∏üáøüáπüá¶üáπüá®üáπüá©üáπüá´üáπüá¨üáπüá≠üáπüáØüáπüá∞üáπüá±üáπüá≤üáπüá≥üáπüá¥üáπüá∑üáπüáπüáπüáªüáπüáºüáπüáøüá∫üá¶üá∫üá¨üá∫üá≤üá∫üá≥üá∫üá∏üá∫üáæüá∫üáøüáªüá¶üáªüá®üáªüá™üáªüá¨üáªüáÆüáªüá≥üáªüá∫üáºüá´üáºüá∏üáΩüá∞üáæüá™üáæüáπüáøüá¶üáøüá≤üáøüáºüè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åøüè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åøüè¥Û†ÅßÛ†Å¢Û†Å∑Û†Å¨Û†Å≥Û†Åø]\")\n",
    "html = re.compile(r\"&\\w+;\")\n",
    "hashtag = re.compile(r\"#\\w+#?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos los usuarios, los retweet y los enlaces por etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...,Tweet,Hate Speech and Offensive Language Dataset\n",
      "\n",
      "['@mayasolovely:']\n",
      "[['Text,Type,Source\\n'\n",
      "  \" _RETWEET_  _USER_  As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...,Tweet,Hate Speech and Offensive Language Dataset\\n\"\n",
      "  ' _RETWEET_  _USER_  boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  Dawg _RETWEET_  _User_  You ever fuck a bitch and she start to cry? You be confused as shit,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_   _User_  she look like a tranny,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  The shit you hear about me might be true or it might be f _User_  than the bitch who told it to ya &#57361;,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  '\"!!!!!!!!!!!!!!!!!!\"\" _USER_  The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"\"\",Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _USER_  causing the reply to be disregarded and the tapped notification under the keyboard is openedüò°üò°üò°,Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  Your business means a lot to us. Please DM your name, zip code and additional details about your concern. ^RR  _LINK_ \\n'\n",
      "  \" _USER_  I really hope you all change but I'm sure you won't! Because you don't have to!,Tweet,Customer Support on Twitter Dataset\\n\"\n",
      "  '\" _USER_  LiveChat is online at the moment -  _LINK_ \\n'\n",
      "  \" _USER_  see attached error message. I've tried leaving a voicemail several times in the past week  _LINK_ \\n\"\n",
      "  '\" _USER_  Have you tried from another device, Miriam ^MM\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  yep, I\\'ve tried laptop too several times over the past week and again today. I\\'ve tried different browsers too\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  It\\'s working OK from here, Miriam. Does this link help  _LINK_ \\n'\n",
      "  '\"Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"\"Who was that singing ?\"\"\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"One of the best game music soundtracks - for a game I didn\\'t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there\\'s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren\\'t included I would still consider the collection worth it.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"works fine, but Maha Energy is better: Check out Maha Energy\\'s website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Great for the non-audiophile: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don\\'t want to replace them with DVD\\'s. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"DVD Player crapped out after one year: I also began having the incorrect disc problems that I\\'ve read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that\\'s a sign on bad quality. I\\'m giving up JVC after this as well. I\\'m sticking to Sony or giving another brand a shot.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  'Amber Smith ‚ÄúKandy Halloween: Return of the Haunted Mansion‚Äù Red Carpet #URL# via #USER#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\" _RETWEET_ Reuters \"\"\"\"Russia: Pence Balkans comments expose Washington\\'s Cold War ideology #URL# #URL#\"\"\"\"\"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  'Jennifer Lopez and Alex Rodriguez Step Out for the First Time at the 2019 Met Gala as an Engaged Couple #URL#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\"92nd #HASHTAG# delayed in Brisbane, Adelaide &amp; Perth. #HASHTAG# #URL# #URL#\"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  '#HASHTAG# to represent Australia at #HASHTAG# 2020! #HASHTAG# #URL# #URL#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"\"Computing Machinery and Intelligence\"\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"The premise of symbolic NLP is well-summarized by John Searle\\'s Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[7]\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"  In neuropsychology, linguistics, and philosophy of language, a natural language or ordinary language is any language that occurs naturally in a human community by a process of use, repetition, and change without conscious planning or premeditation. It can take different forms, namely either a spoken language or a sign language. Natural languages are distinguished from constructed and formal languages such as those used to program computers or to study logic.[1]\",wiki,Wikipedia\\n'\n",
      "  '\"All varieties of world languages are natural languages, including those that are associated with linguistic prescriptivism or language regulation. (Nonstandard dialects can be viewed as a wild type in comparison with standard languages.) An official language with a regulating academy such as Standard French, overseen by the Acad√©mie Fran√ßaise, is classified as a natural language (e.g. in the field of natural language processing), as its prescriptive aspects do not make it constructed enough to be a constructed language or controlled enough to be a controlled natural language.\",wiki,Wikipedia\\n'\n",
      "  '\"Controlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce ambiguity and complexity. This may be accomplished by decreasing usage of superlative or adverbial forms, or irregular verbs. Typical purposes for developing and implementing a controlled natural language are to aid understanding by non-native speakers or to ease computer processing. An example of a widely-used controlled natural language is Simplified Technical English, which was originally developed for aerospace and avionics industry manuals.\",wiki,Wikipedia\\n'\n",
      "  '\"Being constructed, International auxiliary languages such as Esperanto and Interlingua are not considered natural languages, with the possible exception of true native speakers of such languages.[3] Natural languages evolve, through fluctuations in vocabulary and syntax, to incrementally improve human communication. In contrast, Esperanto was created by Polish ophthalmologist L. L. Zamenhof in the late 19th century.\",wiki,Wikipedia\\n'\n",
      "  '\"Some natural languages have become organically \"\"standardized\"\" through the synthesis of two or more pre-existing natural languages over a relatively short period of time through the development of a pidgin, which is not considered a language, into a stable creole language. A creole such as Haitian Creole has its own grammar, vocabulary and literature. It is spoken by over 10 million people worldwide and is one of the two official languages of the Republic of Haiti.\",wiki,Wikipedia']]\n"
     ]
    }
   ],
   "source": [
    "textos_procesados:list[str] = []\n",
    "\n",
    "print(textos[1])\n",
    "print(re.findall(usuario, textos[1]))\n",
    "\n",
    "# textos_procesados.append(textos[1].replace(re.findall(usuario, textos[1])[0],\"_USUARIO_\"))\n",
    "for i, texto in enumerate(textos):\n",
    "\n",
    "    if len(re.findall(usuario, texto)) > 0:\n",
    "\n",
    "        textos_procesados.append(texto.replace(re.findall(usuario, texto)[0],\" _USER_ \"))\n",
    "\n",
    "        if len(re.findall(usuario, textos_procesados[i])) > 0:\n",
    "\n",
    "            for find in re.findall(usuario, textos_procesados[i]):\n",
    "                textos_procesados[i] = textos_procesados[i].replace(find, \" _User_ \")\n",
    "\n",
    "        if len(re.findall(retweet, textos_procesados[i])) > 0:\n",
    "            textos_procesados[i] = textos_procesados[i].replace(re.findall(retweet, textos_procesados[i])[0], \" _RETWEET_ \")\n",
    "\n",
    "            if len(re.findall(retweet, textos_procesados[i])) > 0:\n",
    "\n",
    "                for find in re.findall(retweet, textos_procesados[i]):\n",
    "                    textos_procesados[i] = textos_procesados[i].replace(find, \" _RETWEET_ \")\n",
    "\n",
    "\n",
    "        if len(re.findall(enlace, textos_procesados[i])) > 0:\n",
    "\n",
    "            textos_procesados[i] = textos_procesados[i].replace(re.findall(enlace, textos_procesados[i])[0], \" _LINK_ \")\n",
    "            \n",
    "            if len(re.findall(enlace, textos_procesados[i])) > 0:\n",
    "\n",
    "                for find in re.findall(enlace, textos_procesados[i]):\n",
    "                    textos_procesados[i] = textos_procesados[i].replace(find, \" _LINK_ \")\n",
    "\n",
    "\n",
    "    elif len(re.findall(retweet, texto)) > 0:\n",
    "\n",
    "        textos_procesados.append(texto.replace(re.findall(retweet, texto)[0],\" _RETWEET_ \"))\n",
    "\n",
    "        if len(re.findall(retweet, textos_procesados[i])) > 0:\n",
    "\n",
    "                for find in re.findall(retweet, textos_procesados[i]):\n",
    "                    textos_procesados[i] = textos_procesados[i].replace(find, \" _RETWEET_ \")\n",
    "\n",
    "        if len(re.findall(enlace, textos_procesados[i])) > 0:\n",
    "                    \n",
    "            textos_procesados[i] = textos_procesados[i].replace(re.findall(enlace, textos_procesados[i])[0], \" _LINK_ \")\n",
    "\n",
    "            if len(re.findall(enlace, textos_procesados[i])) > 0:\n",
    "\n",
    "                for find in re.findall(enlace, textos_procesados[i]):\n",
    "                    textos_procesados[i] = textos_procesados[i].replace(find, \" _LINK_ \")\n",
    "\n",
    "\n",
    "    elif len(re.findall(enlace, texto)) > 0:\n",
    "\n",
    "        textos_procesados.append(texto.replace(re.findall(enlace, texto)[0],\" _LINK_ \"))\n",
    "\n",
    "        if len(re.findall(enlace, textos_procesados[i])) > 0:\n",
    "\n",
    "                for find in re.findall(enlace, textos_procesados[i]):\n",
    "                    textos_procesados[i] = textos_procesados[i].replace(find, \" _LINK_ \")\n",
    "\n",
    "    \n",
    "    else:\n",
    "        textos_procesados.append(texto)\n",
    "\n",
    "print(np.matrix(textos_procesados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminando Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Text,Type,Source\\n'\n",
      "  \" _RETWEET_  _USER_  As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...,Tweet,Hate Speech and Offensive Language Dataset\\n\"\n",
      "  ' _RETWEET_  _USER_  boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  Dawg _RETWEET_  _User_  You ever fuck a bitch and she start to cry? You be confused as shit,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_   _User_  she look like a tranny,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  The shit you hear about me might be true or it might be f _User_  than the bitch who told it to ya &#57361;,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  '\"!!!!!!!!!!!!!!!!!!\"\" _USER_  The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"\"\",Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _USER_  causing the reply to be disregarded and the tapped notification under the keyboard is openedüò°üò°üò°,Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  Your business means a lot to us. Please DM your name, zip code and additional details about your concern. ^RR  _LINK_ \\n'\n",
      "  \" _USER_  I really hope you all change but I'm sure you won't! Because you don't have to!,Tweet,Customer Support on Twitter Dataset\\n\"\n",
      "  '\" _USER_  LiveChat is online at the moment -  _LINK_ \\n'\n",
      "  \" _USER_  see attached error message. I've tried leaving a voicemail several times in the past week  _LINK_ \\n\"\n",
      "  '\" _USER_  Have you tried from another device, Miriam ^MM\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  yep, I\\'ve tried laptop too several times over the past week and again today. I\\'ve tried different browsers too\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  It\\'s working OK from here, Miriam. Does this link help  _LINK_ \\n'\n",
      "  '\"Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"\"Who was that singing ?\"\"\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"One of the best game music soundtracks - for a game I didn\\'t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there\\'s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren\\'t included I would still consider the collection worth it.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"works fine, but Maha Energy is better: Check out Maha Energy\\'s website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Great for the non-audiophile: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don\\'t want to replace them with DVD\\'s. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"DVD Player crapped out after one year: I also began having the incorrect disc problems that I\\'ve read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that\\'s a sign on bad quality. I\\'m giving up JVC after this as well. I\\'m sticking to Sony or giving another brand a shot.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  'Amber Smith ‚ÄúKandy Halloween: Return of the Haunted Mansion‚Äù Red Carpet #URL# via #USER#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\" _RETWEET_ Reuters \"\"\"\"Russia: Pence Balkans comments expose Washington\\'s Cold War ideology #URL# #URL#\"\"\"\"\"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  'Jennifer Lopez and Alex Rodriguez Step Out for the First Time at the 2019 Met Gala as an Engaged Couple #URL#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\"92nd #HASHTAG# delayed in Brisbane, Adelaide &amp; Perth. #HASHTAG# #URL# #URL#\"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  '#HASHTAG# to represent Australia at #HASHTAG# 2020! #HASHTAG# #URL# #URL#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"\"Computing Machinery and Intelligence\"\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"The premise of symbolic NLP is well-summarized by John Searle\\'s Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[7]\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"  In neuropsychology, linguistics, and philosophy of language, a natural language or ordinary language is any language that occurs naturally in a human community by a process of use, repetition, and change without conscious planning or premeditation. It can take different forms, namely either a spoken language or a sign language. Natural languages are distinguished from constructed and formal languages such as those used to program computers or to study logic.[1]\",wiki,Wikipedia\\n'\n",
      "  '\"All varieties of world languages are natural languages, including those that are associated with linguistic prescriptivism or language regulation. (Nonstandard dialects can be viewed as a wild type in comparison with standard languages.) An official language with a regulating academy such as Standard French, overseen by the Acad√©mie Fran√ßaise, is classified as a natural language (e.g. in the field of natural language processing), as its prescriptive aspects do not make it constructed enough to be a constructed language or controlled enough to be a controlled natural language.\",wiki,Wikipedia\\n'\n",
      "  '\"Controlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce ambiguity and complexity. This may be accomplished by decreasing usage of superlative or adverbial forms, or irregular verbs. Typical purposes for developing and implementing a controlled natural language are to aid understanding by non-native speakers or to ease computer processing. An example of a widely-used controlled natural language is Simplified Technical English, which was originally developed for aerospace and avionics industry manuals.\",wiki,Wikipedia\\n'\n",
      "  '\"Being constructed, International auxiliary languages such as Esperanto and Interlingua are not considered natural languages, with the possible exception of true native speakers of such languages.[3] Natural languages evolve, through fluctuations in vocabulary and syntax, to incrementally improve human communication. In contrast, Esperanto was created by Polish ophthalmologist L. L. Zamenhof in the late 19th century.\",wiki,Wikipedia\\n'\n",
      "  '\"Some natural languages have become organically \"\"standardized\"\" through the synthesis of two or more pre-existing natural languages over a relatively short period of time through the development of a pidgin, which is not considered a language, into a stable creole language. A creole such as Haitian Creole has its own grammar, vocabulary and literature. It is spoken by over 10 million people worldwide and is one of the two official languages of the Republic of Haiti.\",wiki,Wikipedia']]\n"
     ]
    }
   ],
   "source": [
    "for i, texto in enumerate(textos_procesados):\n",
    "\n",
    "    for emogi in re.findall(emogi, textos_procesados[i]):\n",
    "        textos_procesados[i] = textos_procesados[i].replace(emogi, \" _EMOjI_ \")\n",
    "\n",
    "    # emoji.replace_emoji(textos_procesados[i], replace=\" _EMOJI_ \")\n",
    "\n",
    "print(np.matrix(textos_procesados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No todos los emojis se pueden eliminar!!!! Es frustrante, pero no se pueden eliminar, ni siquiera con la libreria de emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las etiquetas de html &amp; entre otras, ya que el texto no parece tener etiquetas html <>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Text,Type,Source\\n'\n",
      "  \" _RETWEET_  _USER_  As a woman you shouldn't complain about cleaning up your house.  as a man you should always take the trash out...,Tweet,Hate Speech and Offensive Language Dataset\\n\"\n",
      "  ' _RETWEET_  _USER_  boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  Dawg _RETWEET_  _User_  You ever fuck a bitch and she start to cry? You be confused as shit,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_   _User_  she look like a tranny,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  The shit you hear about me might be true or it might be f _User_  than the bitch who told it to ya &#57361;,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  '\"!!!!!!!!!!!!!!!!!!\"\" _USER_  The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"\"\",Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _USER_  causing the reply to be disregarded and the tapped notification under the keyboard is openedüò°üò°üò°,Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  Your business means a lot to us. Please DM your name, zip code and additional details about your concern. ^RR  _LINK_ \\n'\n",
      "  \" _USER_  I really hope you all change but I'm sure you won't! Because you don't have to!,Tweet,Customer Support on Twitter Dataset\\n\"\n",
      "  '\" _USER_  LiveChat is online at the moment -  _LINK_ \\n'\n",
      "  \" _USER_  see attached error message. I've tried leaving a voicemail several times in the past week  _LINK_ \\n\"\n",
      "  '\" _USER_  Have you tried from another device, Miriam ^MM\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  yep, I\\'ve tried laptop too several times over the past week and again today. I\\'ve tried different browsers too\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  It\\'s working OK from here, Miriam. Does this link help  _LINK_ \\n'\n",
      "  '\"Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"\"Who was that singing ?\"\"\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"One of the best game music soundtracks - for a game I didn\\'t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there\\'s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren\\'t included I would still consider the collection worth it.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"works fine, but Maha Energy is better: Check out Maha Energy\\'s website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Great for the non-audiophile: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don\\'t want to replace them with DVD\\'s. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"DVD Player crapped out after one year: I also began having the incorrect disc problems that I\\'ve read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that\\'s a sign on bad quality. I\\'m giving up JVC after this as well. I\\'m sticking to Sony or giving another brand a shot.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  'Amber Smith ‚ÄúKandy Halloween: Return of the Haunted Mansion‚Äù Red Carpet #URL# via #USER#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\" _RETWEET_ Reuters \"\"\"\"Russia: Pence Balkans comments expose Washington\\'s Cold War ideology #URL# #URL#\"\"\"\"\"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  'Jennifer Lopez and Alex Rodriguez Step Out for the First Time at the 2019 Met Gala as an Engaged Couple #URL#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\"92nd #HASHTAG# delayed in Brisbane, Adelaide  Perth. #HASHTAG# #URL# #URL#\"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  '#HASHTAG# to represent Australia at #HASHTAG# 2020! #HASHTAG# #URL# #URL#,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"\"Computing Machinery and Intelligence\"\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"The premise of symbolic NLP is well-summarized by John Searle\\'s Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[7]\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"  In neuropsychology, linguistics, and philosophy of language, a natural language or ordinary language is any language that occurs naturally in a human community by a process of use, repetition, and change without conscious planning or premeditation. It can take different forms, namely either a spoken language or a sign language. Natural languages are distinguished from constructed and formal languages such as those used to program computers or to study logic.[1]\",wiki,Wikipedia\\n'\n",
      "  '\"All varieties of world languages are natural languages, including those that are associated with linguistic prescriptivism or language regulation. (Nonstandard dialects can be viewed as a wild type in comparison with standard languages.) An official language with a regulating academy such as Standard French, overseen by the Acad√©mie Fran√ßaise, is classified as a natural language (e.g. in the field of natural language processing), as its prescriptive aspects do not make it constructed enough to be a constructed language or controlled enough to be a controlled natural language.\",wiki,Wikipedia\\n'\n",
      "  '\"Controlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce ambiguity and complexity. This may be accomplished by decreasing usage of superlative or adverbial forms, or irregular verbs. Typical purposes for developing and implementing a controlled natural language are to aid understanding by non-native speakers or to ease computer processing. An example of a widely-used controlled natural language is Simplified Technical English, which was originally developed for aerospace and avionics industry manuals.\",wiki,Wikipedia\\n'\n",
      "  '\"Being constructed, International auxiliary languages such as Esperanto and Interlingua are not considered natural languages, with the possible exception of true native speakers of such languages.[3] Natural languages evolve, through fluctuations in vocabulary and syntax, to incrementally improve human communication. In contrast, Esperanto was created by Polish ophthalmologist L. L. Zamenhof in the late 19th century.\",wiki,Wikipedia\\n'\n",
      "  '\"Some natural languages have become organically \"\"standardized\"\" through the synthesis of two or more pre-existing natural languages over a relatively short period of time through the development of a pidgin, which is not considered a language, into a stable creole language. A creole such as Haitian Creole has its own grammar, vocabulary and literature. It is spoken by over 10 million people worldwide and is one of the two official languages of the Republic of Haiti.\",wiki,Wikipedia']]\n"
     ]
    }
   ],
   "source": [
    "for i, texto in enumerate(textos_procesados):\n",
    "\n",
    "    for etiqueta in re.findall(html, textos_procesados[i]):\n",
    "        textos_procesados[i] = textos_procesados[i].replace(etiqueta, \"\")\n",
    "\n",
    "print(np.matrix(textos_procesados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sustituyamos los hashtags por etiquetas _HASHTAG_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Text,Type,Source\\n'\n",
      "  \" _RETWEET_  _USER_  As a woman you shouldn't complain about cleaning up your house.  as a man you should always take the trash out...,Tweet,Hate Speech and Offensive Language Dataset\\n\"\n",
      "  ' _RETWEET_  _USER_  boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  Dawg _RETWEET_  _User_  You ever fuck a bitch and she start to cry? You be confused as shit,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_   _User_  she look like a tranny,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _RETWEET_  _USER_  The shit you hear about me might be true or it might be f _User_  than the bitch who told it to ya & _HASHTAG_ ;,Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  '\"!!!!!!!!!!!!!!!!!!\"\" _USER_  The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! & _HASHTAG_ ;& _HASHTAG_ ;& _HASHTAG_ ;\"\"\",Tweet,Hate Speech and Offensive Language Dataset\\n'\n",
      "  ' _USER_  causing the reply to be disregarded and the tapped notification under the keyboard is openedüò°üò°üò°,Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  Your business means a lot to us. Please DM your name, zip code and additional details about your concern. ^RR  _LINK_ \\n'\n",
      "  \" _USER_  I really hope you all change but I'm sure you won't! Because you don't have to!,Tweet,Customer Support on Twitter Dataset\\n\"\n",
      "  '\" _USER_  LiveChat is online at the moment -  _LINK_ \\n'\n",
      "  \" _USER_  see attached error message. I've tried leaving a voicemail several times in the past week  _LINK_ \\n\"\n",
      "  '\" _USER_  Have you tried from another device, Miriam ^MM\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  yep, I\\'ve tried laptop too several times over the past week and again today. I\\'ve tried different browsers too\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  '\" _USER_  It\\'s working OK from here, Miriam. Does this link help  _LINK_ \\n'\n",
      "  '\"Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"\"Who was that singing ?\"\"\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"One of the best game music soundtracks - for a game I didn\\'t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there\\'s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren\\'t included I would still consider the collection worth it.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"works fine, but Maha Energy is better: Check out Maha Energy\\'s website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"Great for the non-audiophile: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don\\'t want to replace them with DVD\\'s. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  '\"DVD Player crapped out after one year: I also began having the incorrect disc problems that I\\'ve read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that\\'s a sign on bad quality. I\\'m giving up JVC after this as well. I\\'m sticking to Sony or giving another brand a shot.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n'\n",
      "  'Amber Smith ‚ÄúKandy Halloween: Return of the Haunted Mansion‚Äù Red Carpet  _HASHTAG_  via  _HASHTAG_ ,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\" _RETWEET_ Reuters \"\"\"\"Russia: Pence Balkans comments expose Washington\\'s Cold War ideology  _HASHTAG_   _HASHTAG_ \"\"\"\"\"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  'Jennifer Lopez and Alex Rodriguez Step Out for the First Time at the 2019 Met Gala as an Engaged Couple  _HASHTAG_ ,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"\"\"92nd  _HASHTAG_  delayed in Brisbane, Adelaide  Perth.  _HASHTAG_   _HASHTAG_   _HASHTAG_ \"\"\",Tweet,Fake News Detection Corpus\\n'\n",
      "  ' _HASHTAG_  to represent Australia at  _HASHTAG_  2020!  _HASHTAG_   _HASHTAG_   _HASHTAG_ ,Tweet,Fake News Detection Corpus\\n'\n",
      "  '\"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"\"Computing Machinery and Intelligence\"\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"The premise of symbolic NLP is well-summarized by John Searle\\'s Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[7]\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"  In neuropsychology, linguistics, and philosophy of language, a natural language or ordinary language is any language that occurs naturally in a human community by a process of use, repetition, and change without conscious planning or premeditation. It can take different forms, namely either a spoken language or a sign language. Natural languages are distinguished from constructed and formal languages such as those used to program computers or to study logic.[1]\",wiki,Wikipedia\\n'\n",
      "  '\"All varieties of world languages are natural languages, including those that are associated with linguistic prescriptivism or language regulation. (Nonstandard dialects can be viewed as a wild type in comparison with standard languages.) An official language with a regulating academy such as Standard French, overseen by the Acad√©mie Fran√ßaise, is classified as a natural language (e.g. in the field of natural language processing), as its prescriptive aspects do not make it constructed enough to be a constructed language or controlled enough to be a controlled natural language.\",wiki,Wikipedia\\n'\n",
      "  '\"Controlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce ambiguity and complexity. This may be accomplished by decreasing usage of superlative or adverbial forms, or irregular verbs. Typical purposes for developing and implementing a controlled natural language are to aid understanding by non-native speakers or to ease computer processing. An example of a widely-used controlled natural language is Simplified Technical English, which was originally developed for aerospace and avionics industry manuals.\",wiki,Wikipedia\\n'\n",
      "  '\"Being constructed, International auxiliary languages such as Esperanto and Interlingua are not considered natural languages, with the possible exception of true native speakers of such languages.[3] Natural languages evolve, through fluctuations in vocabulary and syntax, to incrementally improve human communication. In contrast, Esperanto was created by Polish ophthalmologist L. L. Zamenhof in the late 19th century.\",wiki,Wikipedia\\n'\n",
      "  '\"Some natural languages have become organically \"\"standardized\"\" through the synthesis of two or more pre-existing natural languages over a relatively short period of time through the development of a pidgin, which is not considered a language, into a stable creole language. A creole such as Haitian Creole has its own grammar, vocabulary and literature. It is spoken by over 10 million people worldwide and is one of the two official languages of the Republic of Haiti.\",wiki,Wikipedia']]\n"
     ]
    }
   ],
   "source": [
    "for i, texto in enumerate(textos_procesados):\n",
    "\n",
    "    for gato in re.findall(hashtag, textos_procesados[i]):\n",
    "        textos_procesados[i] = textos_procesados[i].replace(gato, \" _HASHTAG_ \")\n",
    "\n",
    "print(np.matrix(textos_procesados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agreguemos el resultado a la segunda columna del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Text    Type  \\\n",
      "0   !!! RT @mayasolovely: As a woman you shouldn't...   Tweet   \n",
      "1   !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   Tweet   \n",
      "2   !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   Tweet   \n",
      "3   !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   Tweet   \n",
      "4   !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   Tweet   \n",
      "5   !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   Tweet   \n",
      "6   @AppleSupport causing the reply to be disregar...   Tweet   \n",
      "7   @105835 Your business means a lot to us. Pleas...   Tweet   \n",
      "8   @76328 I really hope you all change but I'm su...   Tweet   \n",
      "9   @105836 LiveChat is online at the moment - htt...   Tweet   \n",
      "10  @VirginTrains see attached error message. I've...   Tweet   \n",
      "11  @105836 Have you tried from another device, Mi...   Tweet   \n",
      "12  @VirginTrains yep, I've tried laptop too sever...   Tweet   \n",
      "13  @105836 It's working OK from here, Miriam. Doe...   Tweet   \n",
      "14  Great CD: My lovely Pat has one of the GREAT v...  Review   \n",
      "15  One of the best game music soundtracks - for a...  Review   \n",
      "16  Batteries died within a year ...: I bought thi...  Review   \n",
      "17  works fine, but Maha Energy is better: Check o...  Review   \n",
      "18  Great for the non-audiophile: Reviewed quite a...  Review   \n",
      "19  DVD Player crapped out after one year: I also ...  Review   \n",
      "20  Amber Smith ‚ÄúKandy Halloween: Return of the Ha...   Tweet   \n",
      "21  \"RT Reuters \"\"Russia: Pence Balkans comments e...   Tweet   \n",
      "22  Jennifer Lopez and Alex Rodriguez Step Out for...   Tweet   \n",
      "23  \"92nd #HASHTAG# delayed in Brisbane, Adelaide ...   Tweet   \n",
      "24  #HASHTAG# to represent Australia at #HASHTAG# ...   Tweet   \n",
      "25  Natural language processing (NLP) is an interd...    wiki   \n",
      "26  Challenges in natural language processing freq...    wiki   \n",
      "27  Natural language processing has its roots in t...    wiki   \n",
      "28  The premise of symbolic NLP is well-summarized...    wiki   \n",
      "29  Up to the 1980s, most natural language process...    wiki   \n",
      "30    In neuropsychology, linguistics, and philoso...    wiki   \n",
      "31  All varieties of world languages are natural l...    wiki   \n",
      "32  Controlled natural languages are subsets of na...    wiki   \n",
      "33  Being constructed, International auxiliary lan...    wiki   \n",
      "34  Some natural languages have become organically...    wiki   \n",
      "\n",
      "                                           Source  \n",
      "0      Hate Speech and Offensive Language Dataset  \n",
      "1      Hate Speech and Offensive Language Dataset  \n",
      "2      Hate Speech and Offensive Language Dataset  \n",
      "3      Hate Speech and Offensive Language Dataset  \n",
      "4      Hate Speech and Offensive Language Dataset  \n",
      "5      Hate Speech and Offensive Language Dataset  \n",
      "6             Customer Support on Twitter Dataset  \n",
      "7             Customer Support on Twitter Dataset  \n",
      "8             Customer Support on Twitter Dataset  \n",
      "9             Customer Support on Twitter Dataset  \n",
      "10            Customer Support on Twitter Dataset  \n",
      "11            Customer Support on Twitter Dataset  \n",
      "12            Customer Support on Twitter Dataset  \n",
      "13            Customer Support on Twitter Dataset  \n",
      "14  Amazon Reviews for Sentiment Analysis Dataset  \n",
      "15  Amazon Reviews for Sentiment Analysis Dataset  \n",
      "16  Amazon Reviews for Sentiment Analysis Dataset  \n",
      "17  Amazon Reviews for Sentiment Analysis Dataset  \n",
      "18  Amazon Reviews for Sentiment Analysis Dataset  \n",
      "19  Amazon Reviews for Sentiment Analysis Dataset  \n",
      "20                     Fake News Detection Corpus  \n",
      "21                     Fake News Detection Corpus  \n",
      "22                     Fake News Detection Corpus  \n",
      "23                     Fake News Detection Corpus  \n",
      "24                     Fake News Detection Corpus  \n",
      "25                                      Wikipedia  \n",
      "26                                      Wikipedia  \n",
      "27                                      Wikipedia  \n",
      "28                                      Wikipedia  \n",
      "29                                      Wikipedia  \n",
      "30                                      Wikipedia  \n",
      "31                                      Wikipedia  \n",
      "32                                      Wikipedia  \n",
      "33                                      Wikipedia  \n",
      "34                                      Wikipedia  \n"
     ]
    }
   ],
   "source": [
    "import pyexcel_ods as ods\n",
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_excel(\"src/Sample Texts.ods\")\n",
    "\n",
    "print (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Preprocessed\n",
      "0    _RETWEET_  _USER_  As a woman you shouldn't c...\n",
      "1    _RETWEET_  _USER_  boy dats cold...tyga dwn b...\n",
      "2    _RETWEET_  _USER_  Dawg _RETWEET_  _User_  Yo...\n",
      "3    _RETWEET_  _USER_   _User_  she look like a t...\n",
      "4    _RETWEET_  _USER_  The shit you hear about me...\n",
      "5   \"!!!!!!!!!!!!!!!!!!\"\" _USER_  The shit just bl...\n",
      "6    _USER_  causing the reply to be disregarded a...\n",
      "7   \" _USER_  Your business means a lot to us. Ple...\n",
      "8    _USER_  I really hope you all change but I'm ...\n",
      "9   \" _USER_  LiveChat is online at the moment -  ...\n",
      "10   _USER_  see attached error message. I've trie...\n",
      "11  \" _USER_  Have you tried from another device, ...\n",
      "12  \" _USER_  yep, I've tried laptop too several t...\n",
      "13  \" _USER_  It's working OK from here, Miriam. D...\n",
      "14  \"Great CD: My lovely Pat has one of the GREAT ...\n",
      "15  \"One of the best game music soundtracks - for ...\n",
      "16  \"Batteries died within a year ...: I bought th...\n",
      "17  \"works fine, but Maha Energy is better: Check ...\n",
      "18  \"Great for the non-audiophile: Reviewed quite ...\n",
      "19  \"DVD Player crapped out after one year: I also...\n",
      "20  Amber Smith ‚ÄúKandy Halloween: Return of the Ha...\n",
      "21  \"\"\" _RETWEET_ Reuters \"\"\"\"Russia: Pence Balkan...\n",
      "22  Jennifer Lopez and Alex Rodriguez Step Out for...\n",
      "23  \"\"\"92nd  _HASHTAG_  delayed in Brisbane, Adela...\n",
      "24   _HASHTAG_  to represent Australia at  _HASHTA...\n",
      "25  \"Natural language processing (NLP) is an inter...\n",
      "26  \"Challenges in natural language processing fre...\n",
      "27  \"Natural language processing has its roots in ...\n",
      "28  \"The premise of symbolic NLP is well-summarize...\n",
      "29  \"Up to the 1980s, most natural language proces...\n",
      "30  \"  In neuropsychology, linguistics, and philos...\n",
      "31  \"All varieties of world languages are natural ...\n",
      "32  \"Controlled natural languages are subsets of n...\n",
      "33  \"Being constructed, International auxiliary la...\n",
      "34  \"Some natural languages have become organicall...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nueva_columna = pd.DataFrame(textos_procesados[1:], columns=[\"Preprocessed\"])\n",
    "\n",
    "print(nueva_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Text    Type  \\\n",
      "0   !!! RT @mayasolovely: As a woman you shouldn't...   Tweet   \n",
      "1   !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   Tweet   \n",
      "2   !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   Tweet   \n",
      "3   !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   Tweet   \n",
      "4   !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   Tweet   \n",
      "5   !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   Tweet   \n",
      "6   @AppleSupport causing the reply to be disregar...   Tweet   \n",
      "7   @105835 Your business means a lot to us. Pleas...   Tweet   \n",
      "8   @76328 I really hope you all change but I'm su...   Tweet   \n",
      "9   @105836 LiveChat is online at the moment - htt...   Tweet   \n",
      "10  @VirginTrains see attached error message. I've...   Tweet   \n",
      "11  @105836 Have you tried from another device, Mi...   Tweet   \n",
      "12  @VirginTrains yep, I've tried laptop too sever...   Tweet   \n",
      "13  @105836 It's working OK from here, Miriam. Doe...   Tweet   \n",
      "14  Great CD: My lovely Pat has one of the GREAT v...  Review   \n",
      "15  One of the best game music soundtracks - for a...  Review   \n",
      "16  Batteries died within a year ...: I bought thi...  Review   \n",
      "17  works fine, but Maha Energy is better: Check o...  Review   \n",
      "18  Great for the non-audiophile: Reviewed quite a...  Review   \n",
      "19  DVD Player crapped out after one year: I also ...  Review   \n",
      "20  Amber Smith ‚ÄúKandy Halloween: Return of the Ha...   Tweet   \n",
      "21  \"RT Reuters \"\"Russia: Pence Balkans comments e...   Tweet   \n",
      "22  Jennifer Lopez and Alex Rodriguez Step Out for...   Tweet   \n",
      "23  \"92nd #HASHTAG# delayed in Brisbane, Adelaide ...   Tweet   \n",
      "24  #HASHTAG# to represent Australia at #HASHTAG# ...   Tweet   \n",
      "25  Natural language processing (NLP) is an interd...    wiki   \n",
      "26  Challenges in natural language processing freq...    wiki   \n",
      "27  Natural language processing has its roots in t...    wiki   \n",
      "28  The premise of symbolic NLP is well-summarized...    wiki   \n",
      "29  Up to the 1980s, most natural language process...    wiki   \n",
      "30    In neuropsychology, linguistics, and philoso...    wiki   \n",
      "31  All varieties of world languages are natural l...    wiki   \n",
      "32  Controlled natural languages are subsets of na...    wiki   \n",
      "33  Being constructed, International auxiliary lan...    wiki   \n",
      "34  Some natural languages have become organically...    wiki   \n",
      "\n",
      "                                           Source  \\\n",
      "0      Hate Speech and Offensive Language Dataset   \n",
      "1      Hate Speech and Offensive Language Dataset   \n",
      "2      Hate Speech and Offensive Language Dataset   \n",
      "3      Hate Speech and Offensive Language Dataset   \n",
      "4      Hate Speech and Offensive Language Dataset   \n",
      "5      Hate Speech and Offensive Language Dataset   \n",
      "6             Customer Support on Twitter Dataset   \n",
      "7             Customer Support on Twitter Dataset   \n",
      "8             Customer Support on Twitter Dataset   \n",
      "9             Customer Support on Twitter Dataset   \n",
      "10            Customer Support on Twitter Dataset   \n",
      "11            Customer Support on Twitter Dataset   \n",
      "12            Customer Support on Twitter Dataset   \n",
      "13            Customer Support on Twitter Dataset   \n",
      "14  Amazon Reviews for Sentiment Analysis Dataset   \n",
      "15  Amazon Reviews for Sentiment Analysis Dataset   \n",
      "16  Amazon Reviews for Sentiment Analysis Dataset   \n",
      "17  Amazon Reviews for Sentiment Analysis Dataset   \n",
      "18  Amazon Reviews for Sentiment Analysis Dataset   \n",
      "19  Amazon Reviews for Sentiment Analysis Dataset   \n",
      "20                     Fake News Detection Corpus   \n",
      "21                     Fake News Detection Corpus   \n",
      "22                     Fake News Detection Corpus   \n",
      "23                     Fake News Detection Corpus   \n",
      "24                     Fake News Detection Corpus   \n",
      "25                                      Wikipedia   \n",
      "26                                      Wikipedia   \n",
      "27                                      Wikipedia   \n",
      "28                                      Wikipedia   \n",
      "29                                      Wikipedia   \n",
      "30                                      Wikipedia   \n",
      "31                                      Wikipedia   \n",
      "32                                      Wikipedia   \n",
      "33                                      Wikipedia   \n",
      "34                                      Wikipedia   \n",
      "\n",
      "                                         Preprocessed  \n",
      "0    _RETWEET_  _USER_  As a woman you shouldn't c...  \n",
      "1    _RETWEET_  _USER_  boy dats cold...tyga dwn b...  \n",
      "2    _RETWEET_  _USER_  Dawg _RETWEET_  _User_  Yo...  \n",
      "3    _RETWEET_  _USER_   _User_  she look like a t...  \n",
      "4    _RETWEET_  _USER_  The shit you hear about me...  \n",
      "5   \"!!!!!!!!!!!!!!!!!!\"\" _USER_  The shit just bl...  \n",
      "6    _USER_  causing the reply to be disregarded a...  \n",
      "7   \" _USER_  Your business means a lot to us. Ple...  \n",
      "8    _USER_  I really hope you all change but I'm ...  \n",
      "9   \" _USER_  LiveChat is online at the moment -  ...  \n",
      "10   _USER_  see attached error message. I've trie...  \n",
      "11  \" _USER_  Have you tried from another device, ...  \n",
      "12  \" _USER_  yep, I've tried laptop too several t...  \n",
      "13  \" _USER_  It's working OK from here, Miriam. D...  \n",
      "14  \"Great CD: My lovely Pat has one of the GREAT ...  \n",
      "15  \"One of the best game music soundtracks - for ...  \n",
      "16  \"Batteries died within a year ...: I bought th...  \n",
      "17  \"works fine, but Maha Energy is better: Check ...  \n",
      "18  \"Great for the non-audiophile: Reviewed quite ...  \n",
      "19  \"DVD Player crapped out after one year: I also...  \n",
      "20  Amber Smith ‚ÄúKandy Halloween: Return of the Ha...  \n",
      "21  \"\"\" _RETWEET_ Reuters \"\"\"\"Russia: Pence Balkan...  \n",
      "22  Jennifer Lopez and Alex Rodriguez Step Out for...  \n",
      "23  \"\"\"92nd  _HASHTAG_  delayed in Brisbane, Adela...  \n",
      "24   _HASHTAG_  to represent Australia at  _HASHTA...  \n",
      "25  \"Natural language processing (NLP) is an inter...  \n",
      "26  \"Challenges in natural language processing fre...  \n",
      "27  \"Natural language processing has its roots in ...  \n",
      "28  \"The premise of symbolic NLP is well-summarize...  \n",
      "29  \"Up to the 1980s, most natural language proces...  \n",
      "30  \"  In neuropsychology, linguistics, and philos...  \n",
      "31  \"All varieties of world languages are natural ...  \n",
      "32  \"Controlled natural languages are subsets of n...  \n",
      "33  \"Being constructed, International auxiliary la...  \n",
      "34  \"Some natural languages have become organicall...  \n"
     ]
    }
   ],
   "source": [
    "dataframe_nueva_columna = pd.concat([dataframe, nueva_columna], axis=1)\n",
    "\n",
    "print(dataframe_nueva_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_nueva_columna.to_excel(\"src/Sample Texts_preprocesed.ods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora que tenemos el archivo, vamos con el √°rbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero seleccionemos 5 textos procesados al azar, considerando que ya tenemos la lista en una avariable, hagarr√©moslos desde ah√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\" _USER_  yep, I\\'ve tried laptop too several times over the past week and again today. I\\'ve tried different browsers too\",Tweet,Customer Support on Twitter Dataset\\n'\n",
      "  \" _USER_  see attached error message. I've tried leaving a voicemail several times in the past week  _LINK_ \\n\"\n",
      "  '\"Some natural languages have become organically \"\"standardized\"\" through the synthesis of two or more pre-existing natural languages over a relatively short period of time through the development of a pidgin, which is not considered a language, into a stable creole language. A creole such as Haitian Creole has its own grammar, vocabulary and literature. It is spoken by over 10 million people worldwide and is one of the two official languages of the Republic of Haiti.\",wiki,Wikipedia'\n",
      "  '\"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[7]\\\\n\",wiki,Wikipedia\\n'\n",
      "  '\"One of the best game music soundtracks - for a game I didn\\'t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there\\'s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren\\'t included I would still consider the collection worth it.\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n']]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "seleccionados:list[str] = []\n",
    "\n",
    "#apartamos dos de twitter\n",
    "for i in range(2):\n",
    "\n",
    "    seleccionados.append(textos_procesados[randint(0, 14)])\n",
    "\n",
    "#ahora terminamos de agregar ejemplos\n",
    "for i in range(3):\n",
    "\n",
    "    agregado:bool = False\n",
    "\n",
    "    while(not agregado):\n",
    "        aleatorio = randint(0, len(textos_procesados))\n",
    "\n",
    "        if not seleccionados.__contains__(textos_procesados[aleatorio]):\n",
    "            \n",
    "            seleccionados.append(textos_procesados[aleatorio])\n",
    "            agregado = True\n",
    "    \n",
    "\n",
    "\n",
    "print(np.matrix(seleccionados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Generar el √°rbol sint√°ctico!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer los arboles sint√°cticos por oraciones, vamos separar los textos seleccionados, siendo que cada que se encuentre un punto \".\" el algoritmo va a dividir el texto.\n",
    "\n",
    "Una vez que se tengan los textos, ahora s√≠ generamos el arbol sint√°ctico de cada oraci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:31 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\" _USER_  yep, I\\'ve tried laptop too several times over the past week and again today'\n",
      "  ' I\\'ve tried different browsers too\",Tweet,Customer Support on Twitter Dataset\\n']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9256b0b09f3e472da61b75ea82df1be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:32 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:32 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:32 INFO: Using device: cpu\n",
      "2023-11-26 23:48:32 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:32 INFO: Loading: pos\n",
      "2023-11-26 23:48:33 INFO: Loading: lemma\n",
      "2023-11-26 23:48:33 INFO: Loading: depparse\n",
      "2023-11-26 23:48:34 INFO: Done loading processors!\n",
      "2023-11-26 23:48:35 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: \"\thead id: 2\thead: _USER_\tdeprel: punct\n",
      "id: 2\tword: _USER_\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: yep\thead id: 2\thead: _USER_\tdeprel: discourse\n",
      "id: 4\tword: ,\thead id: 2\thead: _USER_\tdeprel: punct\n",
      "id: 1\tword: I\thead id: 3\thead: tried\tdeprel: nsubj\n",
      "id: 2\tword: 've\thead id: 3\thead: tried\tdeprel: aux\n",
      "id: 3\tword: tried\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: laptop\thead id: 3\thead: tried\tdeprel: obj\n",
      "id: 5\tword: too\thead id: 7\thead: times\tdeprel: advmod\n",
      "id: 6\tword: several\thead id: 7\thead: times\tdeprel: amod\n",
      "id: 7\tword: times\thead id: 3\thead: tried\tdeprel: obl:tmod\n",
      "id: 8\tword: over\thead id: 11\thead: week\tdeprel: case\n",
      "id: 9\tword: the\thead id: 11\thead: week\tdeprel: det\n",
      "id: 10\tword: past\thead id: 11\thead: week\tdeprel: amod\n",
      "id: 11\tword: week\thead id: 3\thead: tried\tdeprel: obl\n",
      "id: 12\tword: and\thead id: 14\thead: today\tdeprel: cc\n",
      "id: 13\tword: again\thead id: 14\thead: today\tdeprel: advmod\n",
      "id: 14\tword: today\thead id: 3\thead: tried\tdeprel: conj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481773e8372a4872b41742b830cdd3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:35 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:36 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:36 INFO: Using device: cpu\n",
      "2023-11-26 23:48:36 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:36 INFO: Loading: pos\n",
      "2023-11-26 23:48:36 INFO: Loading: lemma\n",
      "2023-11-26 23:48:36 INFO: Loading: depparse\n",
      "2023-11-26 23:48:37 INFO: Done loading processors!\n",
      "2023-11-26 23:48:38 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: I\thead id: 3\thead: tried\tdeprel: nsubj\n",
      "id: 2\tword: 've\thead id: 3\thead: tried\tdeprel: aux\n",
      "id: 3\tword: tried\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: different\thead id: 5\thead: browsers\tdeprel: amod\n",
      "id: 5\tword: browsers\thead id: 3\thead: tried\tdeprel: obj\n",
      "id: 6\tword: too\thead id: 3\thead: tried\tdeprel: advmod\n",
      "id: 7\tword: \"\thead id: 3\thead: tried\tdeprel: punct\n",
      "id: 8\tword: ,\thead id: 9\thead: Tweet\tdeprel: punct\n",
      "id: 9\tword: Tweet\thead id: 3\thead: tried\tdeprel: parataxis\n",
      "id: 10\tword: ,\thead id: 9\thead: Tweet\tdeprel: punct\n",
      "id: 11\tword: Customer\thead id: 12\thead: Support\tdeprel: compound\n",
      "id: 12\tword: Support\thead id: 9\thead: Tweet\tdeprel: list\n",
      "id: 13\tword: on\thead id: 15\thead: Dataset\tdeprel: case\n",
      "id: 14\tword: Twitter\thead id: 15\thead: Dataset\tdeprel: compound\n",
      "id: 15\tword: Dataset\thead id: 12\thead: Support\tdeprel: nmod\n",
      "[[' _USER_  see attached error message'\n",
      "  \" I've tried leaving a voicemail several times in the past week  _LINK_ \\n\"]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dde90a60b4e439bb6887ce2bac26bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:38 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:39 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:39 INFO: Using device: cpu\n",
      "2023-11-26 23:48:39 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:39 INFO: Loading: pos\n",
      "2023-11-26 23:48:39 INFO: Loading: lemma\n",
      "2023-11-26 23:48:39 INFO: Loading: depparse\n",
      "2023-11-26 23:48:40 INFO: Done loading processors!\n",
      "2023-11-26 23:48:40 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: _USER_\thead id: 2\thead: see\tdeprel: dep\n",
      "id: 2\tword: see\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: attached\thead id: 5\thead: message\tdeprel: amod\n",
      "id: 4\tword: error\thead id: 5\thead: message\tdeprel: compound\n",
      "id: 5\tword: message\thead id: 2\thead: see\tdeprel: obj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06befe4d2c084c729af716944634e985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:41 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:41 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:41 INFO: Using device: cpu\n",
      "2023-11-26 23:48:41 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:41 INFO: Loading: pos\n",
      "2023-11-26 23:48:42 INFO: Loading: lemma\n",
      "2023-11-26 23:48:42 INFO: Loading: depparse\n",
      "2023-11-26 23:48:42 INFO: Done loading processors!\n",
      "2023-11-26 23:48:43 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: I\thead id: 3\thead: tried\tdeprel: nsubj\n",
      "id: 2\tword: 've\thead id: 3\thead: tried\tdeprel: aux\n",
      "id: 3\tword: tried\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: leaving\thead id: 3\thead: tried\tdeprel: xcomp\n",
      "id: 5\tword: a\thead id: 6\thead: voicemail\tdeprel: det\n",
      "id: 6\tword: voicemail\thead id: 4\thead: leaving\tdeprel: obj\n",
      "id: 7\tword: several\thead id: 8\thead: times\tdeprel: amod\n",
      "id: 8\tword: times\thead id: 4\thead: leaving\tdeprel: obl:tmod\n",
      "id: 9\tword: in\thead id: 12\thead: week\tdeprel: case\n",
      "id: 10\tword: the\thead id: 12\thead: week\tdeprel: det\n",
      "id: 11\tword: past\thead id: 12\thead: week\tdeprel: amod\n",
      "id: 12\tword: week\thead id: 4\thead: leaving\tdeprel: obl\n",
      "id: 13\tword: _LINK_\thead id: 3\thead: tried\tdeprel: discourse\n",
      "[['\"Some natural languages have become organically \"\"standardized\"\" through the synthesis of two or more pre-existing natural languages over a relatively short period of time through the development of a pidgin, which is not considered a language, into a stable creole language'\n",
      "  ' A creole such as Haitian Creole has its own grammar, vocabulary and literature'\n",
      "  ' It is spoken by over 10 million people worldwide and is one of the two official languages of the Republic of Haiti'\n",
      "  '\",wiki,Wikipedia']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d645e865824b4ea102f5c44d90cb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:44 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:44 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:44 INFO: Using device: cpu\n",
      "2023-11-26 23:48:44 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:44 INFO: Loading: pos\n",
      "2023-11-26 23:48:45 INFO: Loading: lemma\n",
      "2023-11-26 23:48:45 INFO: Loading: depparse\n",
      "2023-11-26 23:48:46 INFO: Done loading processors!\n",
      "2023-11-26 23:48:49 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: \"\thead id: 6\thead: become\tdeprel: punct\n",
      "id: 2\tword: Some\thead id: 4\thead: languages\tdeprel: det\n",
      "id: 3\tword: natural\thead id: 4\thead: languages\tdeprel: amod\n",
      "id: 4\tword: languages\thead id: 6\thead: become\tdeprel: nsubj\n",
      "id: 5\tword: have\thead id: 6\thead: become\tdeprel: aux\n",
      "id: 6\tword: become\thead id: 0\thead: root\tdeprel: root\n",
      "id: 7\tword: organically\thead id: 10\thead: standardized\tdeprel: advmod\n",
      "id: 8\tword: \"\thead id: 10\thead: standardized\tdeprel: punct\n",
      "id: 9\tword: \"\thead id: 10\thead: standardized\tdeprel: punct\n",
      "id: 10\tword: standardized\thead id: 6\thead: become\tdeprel: xcomp\n",
      "id: 11\tword: \"\thead id: 10\thead: standardized\tdeprel: punct\n",
      "id: 12\tword: \"\thead id: 10\thead: standardized\tdeprel: punct\n",
      "id: 13\tword: through\thead id: 15\thead: synthesis\tdeprel: case\n",
      "id: 14\tword: the\thead id: 15\thead: synthesis\tdeprel: det\n",
      "id: 15\tword: synthesis\thead id: 6\thead: become\tdeprel: obl\n",
      "id: 16\tword: of\thead id: 22\thead: languages\tdeprel: case\n",
      "id: 17\tword: two\thead id: 22\thead: languages\tdeprel: nummod\n",
      "id: 18\tword: or\thead id: 19\thead: more\tdeprel: cc\n",
      "id: 19\tword: more\thead id: 17\thead: two\tdeprel: conj\n",
      "id: 20\tword: pre-existing\thead id: 22\thead: languages\tdeprel: amod\n",
      "id: 21\tword: natural\thead id: 22\thead: languages\tdeprel: amod\n",
      "id: 22\tword: languages\thead id: 15\thead: synthesis\tdeprel: nmod\n",
      "id: 23\tword: over\thead id: 27\thead: period\tdeprel: case\n",
      "id: 24\tword: a\thead id: 27\thead: period\tdeprel: det\n",
      "id: 25\tword: relatively\thead id: 26\thead: short\tdeprel: advmod\n",
      "id: 26\tword: short\thead id: 27\thead: period\tdeprel: amod\n",
      "id: 27\tword: period\thead id: 15\thead: synthesis\tdeprel: nmod\n",
      "id: 28\tword: of\thead id: 29\thead: time\tdeprel: case\n",
      "id: 29\tword: time\thead id: 27\thead: period\tdeprel: nmod\n",
      "id: 30\tword: through\thead id: 32\thead: development\tdeprel: case\n",
      "id: 31\tword: the\thead id: 32\thead: development\tdeprel: det\n",
      "id: 32\tword: development\thead id: 27\thead: period\tdeprel: nmod\n",
      "id: 33\tword: of\thead id: 35\thead: pidgin\tdeprel: case\n",
      "id: 34\tword: a\thead id: 35\thead: pidgin\tdeprel: det\n",
      "id: 35\tword: pidgin\thead id: 32\thead: development\tdeprel: nmod\n",
      "id: 36\tword: ,\thead id: 32\thead: development\tdeprel: punct\n",
      "id: 37\tword: which\thead id: 40\thead: considered\tdeprel: nsubj:pass\n",
      "id: 38\tword: is\thead id: 40\thead: considered\tdeprel: aux:pass\n",
      "id: 39\tword: not\thead id: 40\thead: considered\tdeprel: advmod\n",
      "id: 40\tword: considered\thead id: 22\thead: languages\tdeprel: acl:relcl\n",
      "id: 41\tword: a\thead id: 42\thead: language\tdeprel: det\n",
      "id: 42\tword: language\thead id: 40\thead: considered\tdeprel: xcomp\n",
      "id: 43\tword: ,\thead id: 48\thead: language\tdeprel: punct\n",
      "id: 44\tword: into\thead id: 48\thead: language\tdeprel: case\n",
      "id: 45\tword: a\thead id: 48\thead: language\tdeprel: det\n",
      "id: 46\tword: stable\thead id: 48\thead: language\tdeprel: amod\n",
      "id: 47\tword: creole\thead id: 48\thead: language\tdeprel: amod\n",
      "id: 48\tword: language\thead id: 40\thead: considered\tdeprel: obl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a0d9b15eb9409d9f2b2cb597f5e8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:50 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:50 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:50 INFO: Using device: cpu\n",
      "2023-11-26 23:48:50 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:50 INFO: Loading: pos\n",
      "2023-11-26 23:48:51 INFO: Loading: lemma\n",
      "2023-11-26 23:48:51 INFO: Loading: depparse\n",
      "2023-11-26 23:48:51 INFO: Done loading processors!\n",
      "2023-11-26 23:48:52 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: A\thead id: 2\thead: creole\tdeprel: det\n",
      "id: 2\tword: creole\thead id: 7\thead: has\tdeprel: nsubj\n",
      "id: 3\tword: such\thead id: 6\thead: Creole\tdeprel: case\n",
      "id: 4\tword: as\thead id: 3\thead: such\tdeprel: fixed\n",
      "id: 5\tword: Haitian\thead id: 6\thead: Creole\tdeprel: amod\n",
      "id: 6\tword: Creole\thead id: 2\thead: creole\tdeprel: nmod\n",
      "id: 7\tword: has\thead id: 0\thead: root\tdeprel: root\n",
      "id: 8\tword: its\thead id: 10\thead: grammar\tdeprel: nmod:poss\n",
      "id: 9\tword: own\thead id: 10\thead: grammar\tdeprel: amod\n",
      "id: 10\tword: grammar\thead id: 7\thead: has\tdeprel: obj\n",
      "id: 11\tword: ,\thead id: 12\thead: vocabulary\tdeprel: punct\n",
      "id: 12\tword: vocabulary\thead id: 10\thead: grammar\tdeprel: conj\n",
      "id: 13\tword: and\thead id: 14\thead: literature\tdeprel: cc\n",
      "id: 14\tword: literature\thead id: 10\thead: grammar\tdeprel: conj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f875e7640049d79eac0f78e46e3c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:53 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:53 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:53 INFO: Using device: cpu\n",
      "2023-11-26 23:48:53 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:53 INFO: Loading: pos\n",
      "2023-11-26 23:48:54 INFO: Loading: lemma\n",
      "2023-11-26 23:48:54 INFO: Loading: depparse\n",
      "2023-11-26 23:48:54 INFO: Done loading processors!\n",
      "2023-11-26 23:48:56 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: It\thead id: 3\thead: spoken\tdeprel: nsubj:pass\n",
      "id: 2\tword: is\thead id: 3\thead: spoken\tdeprel: aux:pass\n",
      "id: 3\tword: spoken\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: by\thead id: 8\thead: people\tdeprel: case\n",
      "id: 5\tword: over\thead id: 7\thead: million\tdeprel: advmod\n",
      "id: 6\tword: 10\thead id: 7\thead: million\tdeprel: compound\n",
      "id: 7\tword: million\thead id: 8\thead: people\tdeprel: nummod\n",
      "id: 8\tword: people\thead id: 3\thead: spoken\tdeprel: obl\n",
      "id: 9\tword: worldwide\thead id: 3\thead: spoken\tdeprel: advmod\n",
      "id: 10\tword: and\thead id: 12\thead: one\tdeprel: cc\n",
      "id: 11\tword: is\thead id: 12\thead: one\tdeprel: cop\n",
      "id: 12\tword: one\thead id: 3\thead: spoken\tdeprel: conj\n",
      "id: 13\tword: of\thead id: 17\thead: languages\tdeprel: case\n",
      "id: 14\tword: the\thead id: 17\thead: languages\tdeprel: det\n",
      "id: 15\tword: two\thead id: 17\thead: languages\tdeprel: nummod\n",
      "id: 16\tword: official\thead id: 17\thead: languages\tdeprel: amod\n",
      "id: 17\tword: languages\thead id: 12\thead: one\tdeprel: nmod\n",
      "id: 18\tword: of\thead id: 20\thead: Republic\tdeprel: case\n",
      "id: 19\tword: the\thead id: 20\thead: Republic\tdeprel: det\n",
      "id: 20\tword: Republic\thead id: 17\thead: languages\tdeprel: nmod\n",
      "id: 21\tword: of\thead id: 22\thead: Haiti\tdeprel: case\n",
      "id: 22\tword: Haiti\thead id: 20\thead: Republic\tdeprel: nmod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b589a5787a545fcbca51a99601650a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:56 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:48:57 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:48:57 INFO: Using device: cpu\n",
      "2023-11-26 23:48:57 INFO: Loading: tokenize\n",
      "2023-11-26 23:48:57 INFO: Loading: pos\n",
      "2023-11-26 23:48:58 INFO: Loading: lemma\n",
      "2023-11-26 23:48:58 INFO: Loading: depparse\n",
      "2023-11-26 23:48:58 INFO: Done loading processors!\n",
      "2023-11-26 23:48:59 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: \"\thead id: 3\thead: wiki\tdeprel: punct\n",
      "id: 2\tword: ,\thead id: 3\thead: wiki\tdeprel: punct\n",
      "id: 3\tword: wiki\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: ,\thead id: 3\thead: wiki\tdeprel: punct\n",
      "id: 5\tword: Wikipedia\thead id: 3\thead: wiki\tdeprel: list\n",
      "[['\"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules'\n",
      "  '  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing'\n",
      "  \"  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e\"\n",
      "  'g'\n",
      "  ' transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing'\n",
      "  '[7]\\\\n\",wiki,Wikipedia\\n']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85081c3bd4fb412ea61b7ecbab43412a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:48:59 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:00 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:00 INFO: Using device: cpu\n",
      "2023-11-26 23:49:00 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:00 INFO: Loading: pos\n",
      "2023-11-26 23:49:00 INFO: Loading: lemma\n",
      "2023-11-26 23:49:00 INFO: Loading: depparse\n",
      "2023-11-26 23:49:01 INFO: Done loading processors!\n",
      "2023-11-26 23:49:02 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: \"\thead id: 13\thead: based\tdeprel: punct\n",
      "id: 2\tword: Up\thead id: 5\thead: 1980s\tdeprel: case\n",
      "id: 3\tword: to\thead id: 5\thead: 1980s\tdeprel: case\n",
      "id: 4\tword: the\thead id: 5\thead: 1980s\tdeprel: det\n",
      "id: 5\tword: 1980s\thead id: 13\thead: based\tdeprel: obl\n",
      "id: 6\tword: ,\thead id: 13\thead: based\tdeprel: punct\n",
      "id: 7\tword: most\thead id: 11\thead: systems\tdeprel: amod\n",
      "id: 8\tword: natural\thead id: 11\thead: systems\tdeprel: amod\n",
      "id: 9\tword: language\thead id: 10\thead: processing\tdeprel: compound\n",
      "id: 10\tword: processing\thead id: 11\thead: systems\tdeprel: compound\n",
      "id: 11\tword: systems\thead id: 13\thead: based\tdeprel: nsubj:pass\n",
      "id: 12\tword: were\thead id: 13\thead: based\tdeprel: aux:pass\n",
      "id: 13\tword: based\thead id: 0\thead: root\tdeprel: root\n",
      "id: 14\tword: on\thead id: 16\thead: sets\tdeprel: case\n",
      "id: 15\tword: complex\thead id: 16\thead: sets\tdeprel: amod\n",
      "id: 16\tword: sets\thead id: 13\thead: based\tdeprel: obl\n",
      "id: 17\tword: of\thead id: 21\thead: rules\tdeprel: case\n",
      "id: 18\tword: hand\thead id: 20\thead: written\tdeprel: compound\n",
      "id: 19\tword: -\thead id: 20\thead: written\tdeprel: punct\n",
      "id: 20\tword: written\thead id: 21\thead: rules\tdeprel: amod\n",
      "id: 21\tword: rules\thead id: 16\thead: sets\tdeprel: nmod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3422e360ff941d0b021ff8b2b15e8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:02 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:03 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:03 INFO: Using device: cpu\n",
      "2023-11-26 23:49:03 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:03 INFO: Loading: pos\n",
      "2023-11-26 23:49:04 INFO: Loading: lemma\n",
      "2023-11-26 23:49:04 INFO: Loading: depparse\n",
      "2023-11-26 23:49:04 INFO: Done loading processors!\n",
      "2023-11-26 23:49:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Starting\thead id: 10\thead: was\tdeprel: advcl\n",
      "id: 2\tword: in\thead id: 5\thead: 1980s\tdeprel: case\n",
      "id: 3\tword: the\thead id: 5\thead: 1980s\tdeprel: det\n",
      "id: 4\tword: late\thead id: 5\thead: 1980s\tdeprel: amod\n",
      "id: 5\tword: 1980s\thead id: 1\thead: Starting\tdeprel: obl\n",
      "id: 6\tword: ,\thead id: 1\thead: Starting\tdeprel: punct\n",
      "id: 7\tword: however\thead id: 10\thead: was\tdeprel: advmod\n",
      "id: 8\tword: ,\thead id: 7\thead: however\tdeprel: punct\n",
      "id: 9\tword: there\thead id: 10\thead: was\tdeprel: expl\n",
      "id: 10\tword: was\thead id: 0\thead: root\tdeprel: root\n",
      "id: 11\tword: a\thead id: 12\thead: revolution\tdeprel: det\n",
      "id: 12\tword: revolution\thead id: 10\thead: was\tdeprel: nsubj\n",
      "id: 13\tword: in\thead id: 16\thead: processing\tdeprel: case\n",
      "id: 14\tword: natural\thead id: 15\thead: language\tdeprel: amod\n",
      "id: 15\tword: language\thead id: 16\thead: processing\tdeprel: compound\n",
      "id: 16\tword: processing\thead id: 12\thead: revolution\tdeprel: nmod\n",
      "id: 17\tword: with\thead id: 19\thead: introduction\tdeprel: case\n",
      "id: 18\tword: the\thead id: 19\thead: introduction\tdeprel: det\n",
      "id: 19\tword: introduction\thead id: 12\thead: revolution\tdeprel: nmod\n",
      "id: 20\tword: of\thead id: 23\thead: algorithms\tdeprel: case\n",
      "id: 21\tword: machine\thead id: 22\thead: learning\tdeprel: compound\n",
      "id: 22\tword: learning\thead id: 23\thead: algorithms\tdeprel: compound\n",
      "id: 23\tword: algorithms\thead id: 19\thead: introduction\tdeprel: nmod\n",
      "id: 24\tword: for\thead id: 26\thead: processing\tdeprel: case\n",
      "id: 25\tword: language\thead id: 26\thead: processing\tdeprel: compound\n",
      "id: 26\tword: processing\thead id: 23\thead: algorithms\tdeprel: nmod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb62c5ec85814165811c334a46c2b2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:07 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:07 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:07 INFO: Using device: cpu\n",
      "2023-11-26 23:49:07 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:07 INFO: Loading: pos\n",
      "2023-11-26 23:49:08 INFO: Loading: lemma\n",
      "2023-11-26 23:49:08 INFO: Loading: depparse\n",
      "2023-11-26 23:49:08 INFO: Done loading processors!\n",
      "2023-11-26 23:49:10 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: This\thead id: 8\thead: increase\tdeprel: nsubj\n",
      "id: 2\tword: was\thead id: 8\thead: increase\tdeprel: cop\n",
      "id: 3\tword: due\thead id: 8\thead: increase\tdeprel: case\n",
      "id: 4\tword: to\thead id: 3\thead: due\tdeprel: fixed\n",
      "id: 5\tword: both\thead id: 8\thead: increase\tdeprel: cc:preconj\n",
      "id: 6\tword: the\thead id: 8\thead: increase\tdeprel: det\n",
      "id: 7\tword: steady\thead id: 8\thead: increase\tdeprel: amod\n",
      "id: 8\tword: increase\thead id: 0\thead: root\tdeprel: root\n",
      "id: 9\tword: in\thead id: 11\thead: power\tdeprel: case\n",
      "id: 10\tword: computational\thead id: 11\thead: power\tdeprel: amod\n",
      "id: 11\tword: power\thead id: 8\thead: increase\tdeprel: nmod\n",
      "id: 12\tword: (\thead id: 13\thead: see\tdeprel: punct\n",
      "id: 13\tword: see\thead id: 8\thead: increase\tdeprel: parataxis\n",
      "id: 14\tword: Moore\thead id: 16\thead: law\tdeprel: nmod:poss\n",
      "id: 15\tword: 's\thead id: 14\thead: Moore\tdeprel: case\n",
      "id: 16\tword: law\thead id: 13\thead: see\tdeprel: obj\n",
      "id: 17\tword: )\thead id: 13\thead: see\tdeprel: punct\n",
      "id: 18\tword: and\thead id: 21\thead: lessening\tdeprel: cc\n",
      "id: 19\tword: the\thead id: 21\thead: lessening\tdeprel: det\n",
      "id: 20\tword: gradual\thead id: 21\thead: lessening\tdeprel: amod\n",
      "id: 21\tword: lessening\thead id: 8\thead: increase\tdeprel: conj\n",
      "id: 22\tword: of\thead id: 24\thead: dominance\tdeprel: case\n",
      "id: 23\tword: the\thead id: 24\thead: dominance\tdeprel: det\n",
      "id: 24\tword: dominance\thead id: 21\thead: lessening\tdeprel: nmod\n",
      "id: 25\tword: of\thead id: 27\thead: theories\tdeprel: case\n",
      "id: 26\tword: Chomskyan\thead id: 27\thead: theories\tdeprel: compound\n",
      "id: 27\tword: theories\thead id: 24\thead: dominance\tdeprel: nmod\n",
      "id: 28\tword: of\thead id: 29\thead: linguistics\tdeprel: case\n",
      "id: 29\tword: linguistics\thead id: 27\thead: theories\tdeprel: nmod\n",
      "id: 30\tword: (\thead id: 31\thead: e\tdeprel: punct\n",
      "id: 31\tword: e\thead id: 8\thead: increase\tdeprel: dep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27d9fe429934aee84c89755ad7d55ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:11 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:12 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:12 INFO: Using device: cpu\n",
      "2023-11-26 23:49:12 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:12 INFO: Loading: pos\n",
      "2023-11-26 23:49:12 INFO: Loading: lemma\n",
      "2023-11-26 23:49:12 INFO: Loading: depparse\n",
      "2023-11-26 23:49:13 INFO: Done loading processors!\n",
      "2023-11-26 23:49:13 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: g\thead id: 0\thead: root\tdeprel: root\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4143c639758e4f3c8318cf6dc78622d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:13 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:14 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:14 INFO: Using device: cpu\n",
      "2023-11-26 23:49:14 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:14 INFO: Loading: pos\n",
      "2023-11-26 23:49:15 INFO: Loading: lemma\n",
      "2023-11-26 23:49:15 INFO: Loading: depparse\n",
      "2023-11-26 23:49:15 INFO: Done loading processors!\n",
      "2023-11-26 23:49:17 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: transformational\thead id: 2\thead: grammar\tdeprel: amod\n",
      "id: 2\tword: grammar\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: )\thead id: 2\thead: grammar\tdeprel: punct\n",
      "id: 4\tword: ,\thead id: 8\thead: discouraged\tdeprel: punct\n",
      "id: 5\tword: whose\thead id: 7\thead: underpinnings\tdeprel: nmod:poss\n",
      "id: 6\tword: theoretical\thead id: 7\thead: underpinnings\tdeprel: amod\n",
      "id: 7\tword: underpinnings\thead id: 8\thead: discouraged\tdeprel: nsubj\n",
      "id: 8\tword: discouraged\thead id: 2\thead: grammar\tdeprel: acl:relcl\n",
      "id: 9\tword: the\thead id: 10\thead: sort\tdeprel: det\n",
      "id: 10\tword: sort\thead id: 8\thead: discouraged\tdeprel: obj\n",
      "id: 11\tword: of\thead id: 13\thead: linguistics\tdeprel: case\n",
      "id: 12\tword: corpus\thead id: 13\thead: linguistics\tdeprel: compound\n",
      "id: 13\tword: linguistics\thead id: 10\thead: sort\tdeprel: nmod\n",
      "id: 14\tword: that\thead id: 15\thead: underlies\tdeprel: nsubj\n",
      "id: 15\tword: underlies\thead id: 13\thead: linguistics\tdeprel: acl:relcl\n",
      "id: 16\tword: the\thead id: 20\thead: approach\tdeprel: det\n",
      "id: 17\tword: machine\thead id: 19\thead: learning\tdeprel: compound\n",
      "id: 18\tword: -\thead id: 17\thead: machine\tdeprel: punct\n",
      "id: 19\tword: learning\thead id: 20\thead: approach\tdeprel: compound\n",
      "id: 20\tword: approach\thead id: 15\thead: underlies\tdeprel: obj\n",
      "id: 21\tword: to\thead id: 23\thead: processing\tdeprel: case\n",
      "id: 22\tword: language\thead id: 23\thead: processing\tdeprel: compound\n",
      "id: 23\tword: processing\thead id: 20\thead: approach\tdeprel: nmod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66116d5b1fbe4eb3a8e8d994ca6cf485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:18 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:19 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:19 INFO: Using device: cpu\n",
      "2023-11-26 23:49:19 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:19 INFO: Loading: pos\n",
      "2023-11-26 23:49:19 INFO: Loading: lemma\n",
      "2023-11-26 23:49:19 INFO: Loading: depparse\n",
      "2023-11-26 23:49:20 INFO: Done loading processors!\n",
      "2023-11-26 23:49:20 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: [\thead id: 2\thead: 7]\tdeprel: punct\n",
      "id: 2\tword: 7]\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: \\n\thead id: 2\thead: 7]\tdeprel: dep\n",
      "id: 4\tword: \"\thead id: 2\thead: 7]\tdeprel: punct\n",
      "id: 5\tword: ,\thead id: 6\thead: wiki\tdeprel: punct\n",
      "id: 6\tword: wiki\thead id: 2\thead: 7]\tdeprel: parataxis\n",
      "id: 7\tword: ,\thead id: 8\thead: Wikipedia\tdeprel: punct\n",
      "id: 8\tword: Wikipedia\thead id: 2\thead: 7]\tdeprel: appos\n",
      "[['\"One of the best game music soundtracks - for a game I didn\\'t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums'\n",
      "  ' There is an incredible mix of fun, epic, and emotional songs'\n",
      "  \" Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks\"\n",
      "  ' I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions'\n",
      "  'My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting'\n",
      "  \" But even if those weren't included I would still consider the collection worth it\"\n",
      "  '\",Review,Amazon Reviews for Sentiment Analysis Dataset\\n']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6396e62d5b804a699d0665a070107fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:21 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:22 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:22 INFO: Using device: cpu\n",
      "2023-11-26 23:49:22 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:22 INFO: Loading: pos\n",
      "2023-11-26 23:49:22 INFO: Loading: lemma\n",
      "2023-11-26 23:49:22 INFO: Loading: depparse\n",
      "2023-11-26 23:49:23 INFO: Done loading processors!\n",
      "2023-11-26 23:49:27 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: \"\thead id: 2\thead: One\tdeprel: punct\n",
      "id: 2\tword: One\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: of\thead id: 8\thead: soundtracks\tdeprel: case\n",
      "id: 4\tword: the\thead id: 8\thead: soundtracks\tdeprel: det\n",
      "id: 5\tword: best\thead id: 8\thead: soundtracks\tdeprel: amod\n",
      "id: 6\tword: game\thead id: 8\thead: soundtracks\tdeprel: compound\n",
      "id: 7\tword: music\thead id: 8\thead: soundtracks\tdeprel: compound\n",
      "id: 8\tword: soundtracks\thead id: 2\thead: One\tdeprel: nmod\n",
      "id: 9\tword: -\thead id: 2\thead: One\tdeprel: punct\n",
      "id: 10\tword: for\thead id: 12\thead: game\tdeprel: case\n",
      "id: 11\tword: a\thead id: 12\thead: game\tdeprel: det\n",
      "id: 12\tword: game\thead id: 2\thead: One\tdeprel: nmod\n",
      "id: 13\tword: I\thead id: 17\thead: play\tdeprel: nsubj\n",
      "id: 14\tword: did\thead id: 17\thead: play\tdeprel: aux\n",
      "id: 15\tword: n't\thead id: 17\thead: play\tdeprel: advmod\n",
      "id: 16\tword: really\thead id: 17\thead: play\tdeprel: advmod\n",
      "id: 17\tword: play\thead id: 12\thead: game\tdeprel: acl:relcl\n",
      "id: 18\tword: :\thead id: 2\thead: One\tdeprel: punct\n",
      "id: 19\tword: Despite\thead id: 21\thead: fact\tdeprel: case\n",
      "id: 20\tword: the\thead id: 21\thead: fact\tdeprel: det\n",
      "id: 21\tword: fact\thead id: 51\thead: led\tdeprel: obl\n",
      "id: 22\tword: that\thead id: 26\thead: played\tdeprel: mark\n",
      "id: 23\tword: I\thead id: 26\thead: played\tdeprel: nsubj\n",
      "id: 24\tword: have\thead id: 26\thead: played\tdeprel: aux\n",
      "id: 25\tword: only\thead id: 26\thead: played\tdeprel: advmod\n",
      "id: 26\tword: played\thead id: 21\thead: fact\tdeprel: acl\n",
      "id: 27\tword: a\thead id: 29\thead: portion\tdeprel: det\n",
      "id: 28\tword: small\thead id: 29\thead: portion\tdeprel: amod\n",
      "id: 29\tword: portion\thead id: 26\thead: played\tdeprel: obj\n",
      "id: 30\tword: of\thead id: 32\thead: game\tdeprel: case\n",
      "id: 31\tword: the\thead id: 32\thead: game\tdeprel: det\n",
      "id: 32\tword: game\thead id: 29\thead: portion\tdeprel: nmod\n",
      "id: 33\tword: ,\thead id: 51\thead: led\tdeprel: punct\n",
      "id: 34\tword: the\thead id: 35\thead: music\tdeprel: det\n",
      "id: 35\tword: music\thead id: 51\thead: led\tdeprel: nsubj\n",
      "id: 36\tword: I\thead id: 37\thead: heard\tdeprel: nsubj\n",
      "id: 37\tword: heard\thead id: 35\thead: music\tdeprel: acl:relcl\n",
      "id: 38\tword: (\thead id: 41\thead: connection\tdeprel: punct\n",
      "id: 39\tword: plus\thead id: 41\thead: connection\tdeprel: cc\n",
      "id: 40\tword: the\thead id: 41\thead: connection\tdeprel: det\n",
      "id: 41\tword: connection\thead id: 35\thead: music\tdeprel: conj\n",
      "id: 42\tword: to\thead id: 44\thead: Trigger\tdeprel: case\n",
      "id: 43\tword: Chrono\thead id: 41\thead: connection\tdeprel: nmod\n",
      "id: 44\tword: Trigger\thead id: 43\thead: Chrono\tdeprel: flat\n",
      "id: 45\tword: which\thead id: 47\thead: great\tdeprel: nsubj\n",
      "id: 46\tword: was\thead id: 47\thead: great\tdeprel: cop\n",
      "id: 47\tword: great\thead id: 41\thead: connection\tdeprel: acl:relcl\n",
      "id: 48\tword: as\thead id: 47\thead: great\tdeprel: advmod\n",
      "id: 49\tword: well\thead id: 48\thead: as\tdeprel: fixed\n",
      "id: 50\tword: )\thead id: 41\thead: connection\tdeprel: punct\n",
      "id: 51\tword: led\thead id: 2\thead: One\tdeprel: parataxis\n",
      "id: 52\tword: me\thead id: 51\thead: led\tdeprel: obj\n",
      "id: 53\tword: to\thead id: 54\thead: purchase\tdeprel: mark\n",
      "id: 54\tword: purchase\thead id: 51\thead: led\tdeprel: xcomp\n",
      "id: 55\tword: the\thead id: 56\thead: soundtrack\tdeprel: det\n",
      "id: 56\tword: soundtrack\thead id: 54\thead: purchase\tdeprel: obj\n",
      "id: 57\tword: ,\thead id: 60\thead: remains\tdeprel: punct\n",
      "id: 58\tword: and\thead id: 60\thead: remains\tdeprel: cc\n",
      "id: 59\tword: it\thead id: 60\thead: remains\tdeprel: nsubj\n",
      "id: 60\tword: remains\thead id: 51\thead: led\tdeprel: conj\n",
      "id: 61\tword: one\thead id: 60\thead: remains\tdeprel: xcomp\n",
      "id: 62\tword: of\thead id: 65\thead: albums\tdeprel: case\n",
      "id: 63\tword: my\thead id: 65\thead: albums\tdeprel: nmod:poss\n",
      "id: 64\tword: favorite\thead id: 65\thead: albums\tdeprel: amod\n",
      "id: 65\tword: albums\thead id: 61\thead: one\tdeprel: nmod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c04d55a3f1749c6a4e93c2207967303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:27 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:28 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:28 INFO: Using device: cpu\n",
      "2023-11-26 23:49:28 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:28 INFO: Loading: pos\n",
      "2023-11-26 23:49:29 INFO: Loading: lemma\n",
      "2023-11-26 23:49:29 INFO: Loading: depparse\n",
      "2023-11-26 23:49:29 INFO: Done loading processors!\n",
      "2023-11-26 23:49:30 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: There\thead id: 2\thead: is\tdeprel: expl\n",
      "id: 2\tword: is\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: an\thead id: 5\thead: mix\tdeprel: det\n",
      "id: 4\tword: incredible\thead id: 5\thead: mix\tdeprel: amod\n",
      "id: 5\tword: mix\thead id: 2\thead: is\tdeprel: nsubj\n",
      "id: 6\tword: of\thead id: 13\thead: songs\tdeprel: case\n",
      "id: 7\tword: fun\thead id: 13\thead: songs\tdeprel: amod\n",
      "id: 8\tword: ,\thead id: 9\thead: epic\tdeprel: punct\n",
      "id: 9\tword: epic\thead id: 7\thead: fun\tdeprel: conj\n",
      "id: 10\tword: ,\thead id: 12\thead: emotional\tdeprel: punct\n",
      "id: 11\tword: and\thead id: 12\thead: emotional\tdeprel: cc\n",
      "id: 12\tword: emotional\thead id: 7\thead: fun\tdeprel: conj\n",
      "id: 13\tword: songs\thead id: 5\thead: mix\tdeprel: nmod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d725572804044c11b630eda375ac8627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:31 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:32 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:32 INFO: Using device: cpu\n",
      "2023-11-26 23:49:32 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:32 INFO: Loading: pos\n",
      "2023-11-26 23:49:32 INFO: Loading: lemma\n",
      "2023-11-26 23:49:32 INFO: Loading: depparse\n",
      "2023-11-26 23:49:33 INFO: Done loading processors!\n",
      "2023-11-26 23:49:35 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Those\thead id: 5\thead: tracks\tdeprel: det\n",
      "id: 2\tword: sad\thead id: 5\thead: tracks\tdeprel: amod\n",
      "id: 3\tword: and\thead id: 4\thead: beautiful\tdeprel: cc\n",
      "id: 4\tword: beautiful\thead id: 2\thead: sad\tdeprel: conj\n",
      "id: 5\tword: tracks\thead id: 0\thead: root\tdeprel: root\n",
      "id: 6\tword: I\thead id: 8\thead: like\tdeprel: nsubj\n",
      "id: 7\tword: especially\thead id: 8\thead: like\tdeprel: advmod\n",
      "id: 8\tword: like\thead id: 5\thead: tracks\tdeprel: acl:relcl\n",
      "id: 9\tword: ,\thead id: 5\thead: tracks\tdeprel: punct\n",
      "id: 10\tword: as\thead id: 12\thead: 's\tdeprel: mark\n",
      "id: 11\tword: there\thead id: 12\thead: 's\tdeprel: expl\n",
      "id: 12\tword: 's\thead id: 5\thead: tracks\tdeprel: advcl\n",
      "id: 13\tword: not\thead id: 12\thead: 's\tdeprel: advmod\n",
      "id: 14\tword: too\thead id: 15\thead: many\tdeprel: advmod\n",
      "id: 15\tword: many\thead id: 12\thead: 's\tdeprel: nsubj\n",
      "id: 16\tword: of\thead id: 18\thead: kinds\tdeprel: case\n",
      "id: 17\tword: those\thead id: 18\thead: kinds\tdeprel: det\n",
      "id: 18\tword: kinds\thead id: 15\thead: many\tdeprel: nmod\n",
      "id: 19\tword: of\thead id: 20\thead: songs\tdeprel: case\n",
      "id: 20\tword: songs\thead id: 18\thead: kinds\tdeprel: nmod\n",
      "id: 21\tword: in\thead id: 26\thead: soundtracks\tdeprel: case\n",
      "id: 22\tword: my\thead id: 26\thead: soundtracks\tdeprel: nmod:poss\n",
      "id: 23\tword: other\thead id: 26\thead: soundtracks\tdeprel: amod\n",
      "id: 24\tword: video\thead id: 25\thead: game\tdeprel: compound\n",
      "id: 25\tword: game\thead id: 26\thead: soundtracks\tdeprel: compound\n",
      "id: 26\tword: soundtracks\thead id: 20\thead: songs\tdeprel: nmod\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ddabbe505040e69ca4f4e31a2c9c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:35 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:36 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:36 INFO: Using device: cpu\n",
      "2023-11-26 23:49:36 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:36 INFO: Loading: pos\n",
      "2023-11-26 23:49:36 INFO: Loading: lemma\n",
      "2023-11-26 23:49:36 INFO: Loading: depparse\n",
      "2023-11-26 23:49:37 INFO: Done loading processors!\n",
      "2023-11-26 23:49:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: I\thead id: 3\thead: admit\tdeprel: nsubj\n",
      "id: 2\tword: must\thead id: 3\thead: admit\tdeprel: aux\n",
      "id: 3\tword: admit\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: that\thead id: 17\thead: brought\tdeprel: mark\n",
      "id: 5\tword: one\thead id: 17\thead: brought\tdeprel: nsubj\n",
      "id: 6\tword: of\thead id: 8\thead: songs\tdeprel: case\n",
      "id: 7\tword: the\thead id: 8\thead: songs\tdeprel: det\n",
      "id: 8\tword: songs\thead id: 5\thead: one\tdeprel: nmod\n",
      "id: 9\tword: (\thead id: 10\thead: Life\tdeprel: punct\n",
      "id: 10\tword: Life\thead id: 8\thead: songs\tdeprel: appos\n",
      "id: 11\tword: -\thead id: 10\thead: Life\tdeprel: punct\n",
      "id: 12\tword: A\thead id: 14\thead: Promise\tdeprel: det\n",
      "id: 13\tword: Distant\thead id: 14\thead: Promise\tdeprel: amod\n",
      "id: 14\tword: Promise\thead id: 10\thead: Life\tdeprel: appos\n",
      "id: 15\tword: )\thead id: 10\thead: Life\tdeprel: punct\n",
      "id: 16\tword: has\thead id: 17\thead: brought\tdeprel: aux\n",
      "id: 17\tword: brought\thead id: 3\thead: admit\tdeprel: ccomp\n",
      "id: 18\tword: tears\thead id: 17\thead: brought\tdeprel: obj\n",
      "id: 19\tword: to\thead id: 21\thead: eyes\tdeprel: case\n",
      "id: 20\tword: my\thead id: 21\thead: eyes\tdeprel: nmod:poss\n",
      "id: 21\tword: eyes\thead id: 17\thead: brought\tdeprel: obl\n",
      "id: 22\tword: on\thead id: 24\thead: occasions\tdeprel: case\n",
      "id: 23\tword: many\thead id: 24\thead: occasions\tdeprel: amod\n",
      "id: 24\tword: occasions\thead id: 17\thead: brought\tdeprel: obl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3731405d0619492e929676e09a1c08d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:39 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:40 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:40 INFO: Using device: cpu\n",
      "2023-11-26 23:49:40 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:40 INFO: Loading: pos\n",
      "2023-11-26 23:49:40 INFO: Loading: lemma\n",
      "2023-11-26 23:49:40 INFO: Loading: depparse\n",
      "2023-11-26 23:49:41 INFO: Done loading processors!\n",
      "2023-11-26 23:49:42 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: My\thead id: 3\thead: complaint\tdeprel: nmod:poss\n",
      "id: 2\tword: one\thead id: 3\thead: complaint\tdeprel: nummod\n",
      "id: 3\tword: complaint\thead id: 10\thead: use\tdeprel: nsubj:outer\n",
      "id: 4\tword: about\thead id: 6\thead: soundtrack\tdeprel: case\n",
      "id: 5\tword: this\thead id: 6\thead: soundtrack\tdeprel: det\n",
      "id: 6\tword: soundtrack\thead id: 3\thead: complaint\tdeprel: nmod\n",
      "id: 7\tword: is\thead id: 10\thead: use\tdeprel: cop\n",
      "id: 8\tword: that\thead id: 10\thead: use\tdeprel: mark\n",
      "id: 9\tword: they\thead id: 10\thead: use\tdeprel: nsubj\n",
      "id: 10\tword: use\thead id: 0\thead: root\tdeprel: root\n",
      "id: 11\tword: guitar\thead id: 12\thead: fretting\tdeprel: compound\n",
      "id: 12\tword: fretting\thead id: 13\thead: effects\tdeprel: compound\n",
      "id: 13\tword: effects\thead id: 10\thead: use\tdeprel: obj\n",
      "id: 14\tword: in\thead id: 15\thead: many\tdeprel: case\n",
      "id: 15\tword: many\thead id: 10\thead: use\tdeprel: obl\n",
      "id: 16\tword: of\thead id: 18\thead: songs\tdeprel: case\n",
      "id: 17\tword: the\thead id: 18\thead: songs\tdeprel: det\n",
      "id: 18\tword: songs\thead id: 15\thead: many\tdeprel: nmod\n",
      "id: 19\tword: ,\thead id: 22\thead: find\tdeprel: punct\n",
      "id: 20\tword: which\thead id: 22\thead: find\tdeprel: obj\n",
      "id: 21\tword: I\thead id: 22\thead: find\tdeprel: nsubj\n",
      "id: 22\tword: find\thead id: 18\thead: songs\tdeprel: acl:relcl\n",
      "id: 23\tword: distracting\thead id: 22\thead: find\tdeprel: xcomp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabed9743fe94691bc4f7c9791c70950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:43 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:43 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:43 INFO: Using device: cpu\n",
      "2023-11-26 23:49:43 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:43 INFO: Loading: pos\n",
      "2023-11-26 23:49:44 INFO: Loading: lemma\n",
      "2023-11-26 23:49:45 INFO: Loading: depparse\n",
      "2023-11-26 23:49:45 INFO: Done loading processors!\n",
      "2023-11-26 23:49:46 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: But\thead id: 11\thead: consider\tdeprel: cc\n",
      "id: 2\tword: even\thead id: 7\thead: included\tdeprel: advmod\n",
      "id: 3\tword: if\thead id: 7\thead: included\tdeprel: mark\n",
      "id: 4\tword: those\thead id: 7\thead: included\tdeprel: nsubj:pass\n",
      "id: 5\tword: were\thead id: 7\thead: included\tdeprel: aux:pass\n",
      "id: 6\tword: n't\thead id: 7\thead: included\tdeprel: advmod\n",
      "id: 7\tword: included\thead id: 11\thead: consider\tdeprel: advcl\n",
      "id: 8\tword: I\thead id: 11\thead: consider\tdeprel: nsubj\n",
      "id: 9\tword: would\thead id: 11\thead: consider\tdeprel: aux\n",
      "id: 10\tword: still\thead id: 11\thead: consider\tdeprel: advmod\n",
      "id: 11\tword: consider\thead id: 0\thead: root\tdeprel: root\n",
      "id: 12\tword: the\thead id: 13\thead: collection\tdeprel: det\n",
      "id: 13\tword: collection\thead id: 11\thead: consider\tdeprel: obj\n",
      "id: 14\tword: worth\thead id: 11\thead: consider\tdeprel: xcomp\n",
      "id: 15\tword: it\thead id: 14\thead: worth\tdeprel: obj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c063e57575d4fe88f32e84b2c54f737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 23:49:47 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-26 23:49:47 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-26 23:49:47 INFO: Using device: cpu\n",
      "2023-11-26 23:49:47 INFO: Loading: tokenize\n",
      "2023-11-26 23:49:47 INFO: Loading: pos\n",
      "2023-11-26 23:49:48 INFO: Loading: lemma\n",
      "2023-11-26 23:49:48 INFO: Loading: depparse\n",
      "2023-11-26 23:49:48 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: \"\thead id: 3\thead: Review\tdeprel: punct\n",
      "id: 2\tword: ,\thead id: 3\thead: Review\tdeprel: punct\n",
      "id: 3\tword: Review\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: ,\thead id: 3\thead: Review\tdeprel: punct\n",
      "id: 5\tword: Amazon\thead id: 6\thead: Reviews\tdeprel: compound\n",
      "id: 6\tword: Reviews\thead id: 3\thead: Review\tdeprel: list\n",
      "id: 7\tword: for\thead id: 10\thead: Dataset\tdeprel: case\n",
      "id: 8\tword: Sentiment\thead id: 9\thead: Analysis\tdeprel: compound\n",
      "id: 9\tword: Analysis\thead id: 10\thead: Dataset\tdeprel: compound\n",
      "id: 10\tword: Dataset\thead id: 6\thead: Reviews\tdeprel: nmod\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "for seleccionado in seleccionados:\n",
    "\n",
    "    oraciones = seleccionado.split(\".\")\n",
    "    print(np.matrix(oraciones))\n",
    "    for oracion in oraciones:\n",
    "    \n",
    "        nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "        doc = nlp(oracion)\n",
    "        print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')\n",
    "\n",
    "        # print(doc)    <- imprimibles adicionales para mayor informaci√≥n\n",
    "        # print(doc.entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_redes_avanzadas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
