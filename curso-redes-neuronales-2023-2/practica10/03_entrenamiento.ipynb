{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De La Huerta Avalos Gerardo Cristóbal\n",
    "#2021630243\n",
    "#5BM1\n",
    "#entrenamiento por epocas\n",
    "#Ephocs para el entrenamiento: 100    Learning rate del optimizador: 0.03\n",
    "\n",
    "#Hiperparámetros de la red neuronal\n",
    "#learning rate: 0.01\n",
    "\n",
    "#Menor Loss: 0.0029 -> epoca 92\n",
    "#Ultimo loss obtenido : Loss: 0.0523 -> epoca 100\n",
    "\n",
    "#batch size: 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de una red neuronal\n",
    "\n",
    "Al entrenar una red buscamos que ésta tenga un comportamiendo presumiblemente adecuado y observable en un conjunto de datos. Es decír a partir del conjunto de ejemplos esperamos que la red aprenda una función $f$ tal que la salida de la red imite el patrón en los datos. En nuestro caso, al utilizar el conjunto de entrenamiento MNIST esperamos que la función aprendida provea como salida el número al cual corresponde la imagen de entrada.\n",
    "\n",
    "<img src=\"archivos/function_approx.png\">\n",
    "\n",
    "Imagen tomada de [1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retropropagación y Autograd\n",
    "\n",
    "Pytorch provee el módulo *autograd* para calcular los gradientes, y si, !nos evita estar calculando las derivadas! Esto lo realiza a partir de mantener en la vista todas las operaciones que se ejecutan sobre los tensores.\n",
    "\n",
    "Si deseas asegurarte que autograd siga a un tensor especificamos *requires_grad*. Esto se puede hacer en la creación o en cualquier momento. \n",
    "\n",
    "Veamos el siguiente código de ejemplo:\n",
    "\n",
    "```python\n",
    "# especificamos que la variable x es seguida por autograd\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    "# si en algún momento desamos que temporalmente se deje de seguir el tensor usamos\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    "# establecemos de nuevo el seguimiento\n",
    ">>> y.requires_grad\n",
    "```\n",
    "\n",
    "Si queremos eliminar autograd de todos los tensores usamos `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "\n",
    "Ahora bien, para calcular los gradientes simplemente usamos el método *backward()*. Por ejemplo para un tensor *cualquiera* hacemos *z.backward()*\n",
    "\n",
    "Veamos a continuación el uso del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importamos paquetes\n",
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1421,  1.0940,  0.7406, -0.7400], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# especificamos que el tensor x es seguido por autograd \n",
    "x = torch.randn(4, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0202, 1.1968, 0.5484, 0.5476], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# generamos un nuevo tensor a partir de x\n",
    "# por ejemplo elevemos al cuadrado la variable x\n",
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7fef143bfa60>\n"
     ]
    }
   ],
   "source": [
    "## con grad_fn observamos la operación que generó y, es decir una operación potencia (pow)\n",
    "print(y.grad_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5783, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# De esta forma es posible saber las operaciónes que generan cada tensor, y por tanto, es posible calcular el gradiente.\n",
    "# Hagamos ahora una operación de media\n",
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# hasta este momento los gradientes son cero\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular los gradientes es necesario llamar al método *.backward* sobre la variable. Supongamos sobre *z*. Esto calcula el gradiente de z con respecto de x.\n",
    "\n",
    "El gradiente analítico de las operaciónes que hicimos es:\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$\n",
    "\n",
    "Ahora comprobemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0711,  0.5470,  0.3703, -0.3700])\n",
      "tensor([-0.0711,  0.5470,  0.3703, -0.3700], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos y red neuronal\n",
    "\n",
    "Ahora descargemos los datos y generemos una red tal cual lo vimos en el notebook anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                transforms.Normalize([0.5],[0.5])\n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('relu3', nn.ReLU()),\n",
    "                      ('relu4', nn.ReLU()),\n",
    "                      ('relu5', nn.ReLU()),\n",
    "                      ('relu6', nn.ReLU()),\n",
    "                      ('relu7', nn.ReLU()),\n",
    "                      ('relu8', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu5', nn.ReLU()),\n",
    "                      ('relu6', nn.ReLU()),\n",
    "                      ('relu7', nn.ReLU()),\n",
    "                      ('relu8', nn.ReLU()),\n",
    "                      ('relu9', nn.ReLU()),\n",
    "                      ('relu10', nn.ReLU()),\n",
    "                      ('relu11', nn.ReLU()),\n",
    "                      ('relu12', nn.ReLU()),\n",
    "                      ('logits', nn.Linear(hidden_sizes[1], output_size))]))\n",
    "\n",
    "# NOTA solo calcularemos los logits y definiremos la perdida a partir de ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que definiremos será la función de pérdida (loss) que es nombrada en pytorch como **criterion**. En este ejemplo estamos utilizando softmax, asi que definimos el criterio como *criterion = nn.CrossEntropyLoss()*. Más tarde, en el entrenamiento, veremos que *loss = criterion(output, targets)* calcula la pérdida.\n",
    "\n",
    "Lo segundo que definiremos será el optimizador, para este ejemplo usaremos SGD (stochastic gradient descent). Simplemente llamamos a *torch.optim.SGD* y le pasamos los parámetros de la red y el lerning rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de relizar el entrenamiento completo haremos un paso del aprendizaje. Este paso se compone de las siguientes tareas:\n",
    "\n",
    "1. Realizar un pase frontal de la red\n",
    "2. Utilizar los logits para calcular la pérdida\n",
    "3. Realizar la retropropagación para calcular los gradientes.\n",
    "4. Actualizar los pesos usando el optimizador.\n",
    "\n",
    "Veamos el ejemplo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0327, -0.0276,  0.0006,  ...,  0.0252,  0.0296,  0.0013],\n",
      "        [ 0.0179,  0.0266,  0.0008,  ...,  0.0102, -0.0095, -0.0140],\n",
      "        [-0.0051,  0.0199,  0.0199,  ...,  0.0335, -0.0074, -0.0349],\n",
      "        ...,\n",
      "        [-0.0054, -0.0113, -0.0123,  ..., -0.0344, -0.0029,  0.0333],\n",
      "        [ 0.0337, -0.0138,  0.0091,  ..., -0.0058, -0.0157, -0.0287],\n",
      "        [-0.0045,  0.0126, -0.0229,  ...,  0.0337,  0.0130, -0.0224]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model.fc1.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient - tensor([[-2.9855e-03, -2.9855e-03, -2.9855e-03,  ..., -2.9855e-03,\n",
      "         -2.9855e-03, -2.9855e-03],\n",
      "        [-2.9929e-03, -2.9929e-03, -2.9929e-03,  ..., -2.9929e-03,\n",
      "         -2.9929e-03, -2.9929e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.9240e-03, -6.9240e-03, -6.9240e-03,  ..., -6.9240e-03,\n",
      "         -6.9240e-03, -6.9240e-03],\n",
      "        [-3.1320e-05, -3.1320e-05, -3.1320e-05,  ..., -3.1320e-05,\n",
      "         -3.1320e-05, -3.1320e-05]])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Limpiar los gradientes por que se acumulan\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Pase hacia adelante\n",
    "output = model.forward(images)\n",
    "# Perdida\n",
    "loss = criterion(output, labels)\n",
    "# Pase de reversa\n",
    "loss.backward()\n",
    "print('Gradient -', model.fc1.weight.grad)\n",
    "# Actualiza los pesos de acuerdo a un paso del optimizador\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0327, -0.0276,  0.0006,  ...,  0.0252,  0.0297,  0.0013],\n",
      "        [ 0.0179,  0.0266,  0.0009,  ...,  0.0103, -0.0095, -0.0139],\n",
      "        [-0.0051,  0.0199,  0.0199,  ...,  0.0335, -0.0074, -0.0349],\n",
      "        ...,\n",
      "        [-0.0054, -0.0113, -0.0123,  ..., -0.0344, -0.0029,  0.0333],\n",
      "        [ 0.0338, -0.0138,  0.0092,  ..., -0.0057, -0.0156, -0.0286],\n",
      "        [-0.0045,  0.0126, -0.0229,  ...,  0.0337,  0.0130, -0.0224]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Updated weights - ', model.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento por épocas\n",
    "\n",
    "Ahora si, entrenemos la red por varias épocas. Para ello programaremos el algoritmo de gradiente descendente que de forma general funciona con los siguientes pasos:\n",
    "\n",
    "- Para un número de *épocas*:\n",
    "    - Para cada *lote* en el conjunto de datos:\n",
    "        - Salida = Red predice usando el *lote*\n",
    "        - Calcular *pérdida* a partir de la *salida* y de las *etiquetas* reales\n",
    "        - Error = Retropropagación a partir de la *pérdida*\n",
    "        - Actualizar pesos\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración del optimizador\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100...  Loss: 2.2853\n",
      "Epoch: 1/100...  Loss: 2.2567\n",
      "Epoch: 1/100...  Loss: 2.2279\n",
      "Epoch: 1/100...  Loss: 2.2086\n",
      "Epoch: 1/100...  Loss: 2.1781\n",
      "Epoch: 1/100...  Loss: 2.1488\n",
      "Epoch: 1/100...  Loss: 2.1092\n",
      "Epoch: 1/100...  Loss: 2.0761\n",
      "Epoch: 1/100...  Loss: 2.0377\n",
      "Epoch: 1/100...  Loss: 1.9853\n",
      "Epoch: 1/100...  Loss: 1.9494\n",
      "Epoch: 1/100...  Loss: 1.9083\n",
      "Epoch: 1/100...  Loss: 1.8265\n",
      "Epoch: 1/100...  Loss: 1.7757\n",
      "Epoch: 1/100...  Loss: 1.7300\n",
      "Epoch: 1/100...  Loss: 1.6500\n",
      "Epoch: 1/100...  Loss: 1.5972\n",
      "Epoch: 1/100...  Loss: 1.5311\n",
      "Epoch: 1/100...  Loss: 1.4556\n",
      "Epoch: 1/100...  Loss: 1.3956\n",
      "Epoch: 1/100...  Loss: 1.3476\n",
      "Epoch: 1/100...  Loss: 1.2588\n",
      "Epoch: 1/100...  Loss: 1.2023\n",
      "Epoch: 2/100...  Loss: 0.6130\n",
      "Epoch: 2/100...  Loss: 1.0988\n",
      "Epoch: 2/100...  Loss: 1.0564\n",
      "Epoch: 2/100...  Loss: 1.0216\n",
      "Epoch: 2/100...  Loss: 0.9951\n",
      "Epoch: 2/100...  Loss: 0.9540\n",
      "Epoch: 2/100...  Loss: 0.8824\n",
      "Epoch: 2/100...  Loss: 0.8639\n",
      "Epoch: 2/100...  Loss: 0.8332\n",
      "Epoch: 2/100...  Loss: 0.8095\n",
      "Epoch: 2/100...  Loss: 0.7866\n",
      "Epoch: 2/100...  Loss: 0.7605\n",
      "Epoch: 2/100...  Loss: 0.7567\n",
      "Epoch: 2/100...  Loss: 0.7269\n",
      "Epoch: 2/100...  Loss: 0.7170\n",
      "Epoch: 2/100...  Loss: 0.6768\n",
      "Epoch: 2/100...  Loss: 0.6836\n",
      "Epoch: 2/100...  Loss: 0.6774\n",
      "Epoch: 2/100...  Loss: 0.6303\n",
      "Epoch: 2/100...  Loss: 0.6013\n",
      "Epoch: 2/100...  Loss: 0.5965\n",
      "Epoch: 2/100...  Loss: 0.6036\n",
      "Epoch: 2/100...  Loss: 0.6152\n",
      "Epoch: 3/100...  Loss: 0.0648\n",
      "Epoch: 3/100...  Loss: 0.5650\n",
      "Epoch: 3/100...  Loss: 0.5423\n",
      "Epoch: 3/100...  Loss: 0.5687\n",
      "Epoch: 3/100...  Loss: 0.5604\n",
      "Epoch: 3/100...  Loss: 0.5413\n",
      "Epoch: 3/100...  Loss: 0.5179\n",
      "Epoch: 3/100...  Loss: 0.5490\n",
      "Epoch: 3/100...  Loss: 0.5168\n",
      "Epoch: 3/100...  Loss: 0.5361\n",
      "Epoch: 3/100...  Loss: 0.5248\n",
      "Epoch: 3/100...  Loss: 0.4896\n",
      "Epoch: 3/100...  Loss: 0.4865\n",
      "Epoch: 3/100...  Loss: 0.4939\n",
      "Epoch: 3/100...  Loss: 0.5207\n",
      "Epoch: 3/100...  Loss: 0.4982\n",
      "Epoch: 3/100...  Loss: 0.4578\n",
      "Epoch: 3/100...  Loss: 0.4541\n",
      "Epoch: 3/100...  Loss: 0.4685\n",
      "Epoch: 3/100...  Loss: 0.4718\n",
      "Epoch: 3/100...  Loss: 0.4516\n",
      "Epoch: 3/100...  Loss: 0.4694\n",
      "Epoch: 3/100...  Loss: 0.4396\n",
      "Epoch: 3/100...  Loss: 0.4658\n",
      "Epoch: 4/100...  Loss: 0.2841\n",
      "Epoch: 4/100...  Loss: 0.4391\n",
      "Epoch: 4/100...  Loss: 0.4691\n",
      "Epoch: 4/100...  Loss: 0.4581\n",
      "Epoch: 4/100...  Loss: 0.4363\n",
      "Epoch: 4/100...  Loss: 0.4358\n",
      "Epoch: 4/100...  Loss: 0.4467\n",
      "Epoch: 4/100...  Loss: 0.4114\n",
      "Epoch: 4/100...  Loss: 0.4090\n",
      "Epoch: 4/100...  Loss: 0.3886\n",
      "Epoch: 4/100...  Loss: 0.4061\n",
      "Epoch: 4/100...  Loss: 0.4183\n",
      "Epoch: 4/100...  Loss: 0.3971\n",
      "Epoch: 4/100...  Loss: 0.4297\n",
      "Epoch: 4/100...  Loss: 0.4212\n",
      "Epoch: 4/100...  Loss: 0.4221\n",
      "Epoch: 4/100...  Loss: 0.3922\n",
      "Epoch: 4/100...  Loss: 0.3813\n",
      "Epoch: 4/100...  Loss: 0.4220\n",
      "Epoch: 4/100...  Loss: 0.4201\n",
      "Epoch: 4/100...  Loss: 0.4002\n",
      "Epoch: 4/100...  Loss: 0.3981\n",
      "Epoch: 4/100...  Loss: 0.3978\n",
      "Epoch: 5/100...  Loss: 0.0736\n",
      "Epoch: 5/100...  Loss: 0.3997\n",
      "Epoch: 5/100...  Loss: 0.4019\n",
      "Epoch: 5/100...  Loss: 0.3614\n",
      "Epoch: 5/100...  Loss: 0.3947\n",
      "Epoch: 5/100...  Loss: 0.3560\n",
      "Epoch: 5/100...  Loss: 0.3671\n",
      "Epoch: 5/100...  Loss: 0.3900\n",
      "Epoch: 5/100...  Loss: 0.3955\n",
      "Epoch: 5/100...  Loss: 0.3996\n",
      "Epoch: 5/100...  Loss: 0.3702\n",
      "Epoch: 5/100...  Loss: 0.4059\n",
      "Epoch: 5/100...  Loss: 0.3719\n",
      "Epoch: 5/100...  Loss: 0.3785\n",
      "Epoch: 5/100...  Loss: 0.3664\n",
      "Epoch: 5/100...  Loss: 0.3637\n",
      "Epoch: 5/100...  Loss: 0.3729\n",
      "Epoch: 5/100...  Loss: 0.3797\n",
      "Epoch: 5/100...  Loss: 0.3367\n",
      "Epoch: 5/100...  Loss: 0.3643\n",
      "Epoch: 5/100...  Loss: 0.3708\n",
      "Epoch: 5/100...  Loss: 0.3831\n",
      "Epoch: 5/100...  Loss: 0.3977\n",
      "Epoch: 5/100...  Loss: 0.3920\n",
      "Epoch: 6/100...  Loss: 0.2475\n",
      "Epoch: 6/100...  Loss: 0.3613\n",
      "Epoch: 6/100...  Loss: 0.3752\n",
      "Epoch: 6/100...  Loss: 0.3527\n",
      "Epoch: 6/100...  Loss: 0.3792\n",
      "Epoch: 6/100...  Loss: 0.3671\n",
      "Epoch: 6/100...  Loss: 0.3584\n",
      "Epoch: 6/100...  Loss: 0.3765\n",
      "Epoch: 6/100...  Loss: 0.3597\n",
      "Epoch: 6/100...  Loss: 0.3623\n",
      "Epoch: 6/100...  Loss: 0.3308\n",
      "Epoch: 6/100...  Loss: 0.3658\n",
      "Epoch: 6/100...  Loss: 0.3580\n",
      "Epoch: 6/100...  Loss: 0.3602\n",
      "Epoch: 6/100...  Loss: 0.3562\n",
      "Epoch: 6/100...  Loss: 0.3709\n",
      "Epoch: 6/100...  Loss: 0.3215\n",
      "Epoch: 6/100...  Loss: 0.3628\n",
      "Epoch: 6/100...  Loss: 0.3334\n",
      "Epoch: 6/100...  Loss: 0.3190\n",
      "Epoch: 6/100...  Loss: 0.3126\n",
      "Epoch: 6/100...  Loss: 0.3524\n",
      "Epoch: 6/100...  Loss: 0.3466\n",
      "Epoch: 7/100...  Loss: 0.1040\n",
      "Epoch: 7/100...  Loss: 0.3761\n",
      "Epoch: 7/100...  Loss: 0.3395\n",
      "Epoch: 7/100...  Loss: 0.3535\n",
      "Epoch: 7/100...  Loss: 0.3512\n",
      "Epoch: 7/100...  Loss: 0.3367\n",
      "Epoch: 7/100...  Loss: 0.3418\n",
      "Epoch: 7/100...  Loss: 0.3344\n",
      "Epoch: 7/100...  Loss: 0.3302\n",
      "Epoch: 7/100...  Loss: 0.3279\n",
      "Epoch: 7/100...  Loss: 0.3050\n",
      "Epoch: 7/100...  Loss: 0.3816\n",
      "Epoch: 7/100...  Loss: 0.3214\n",
      "Epoch: 7/100...  Loss: 0.3261\n",
      "Epoch: 7/100...  Loss: 0.3243\n",
      "Epoch: 7/100...  Loss: 0.3173\n",
      "Epoch: 7/100...  Loss: 0.3244\n",
      "Epoch: 7/100...  Loss: 0.3322\n",
      "Epoch: 7/100...  Loss: 0.2991\n",
      "Epoch: 7/100...  Loss: 0.3320\n",
      "Epoch: 7/100...  Loss: 0.3439\n",
      "Epoch: 7/100...  Loss: 0.3644\n",
      "Epoch: 7/100...  Loss: 0.3352\n",
      "Epoch: 7/100...  Loss: 0.3039\n",
      "Epoch: 8/100...  Loss: 0.2892\n",
      "Epoch: 8/100...  Loss: 0.2922\n",
      "Epoch: 8/100...  Loss: 0.3464\n",
      "Epoch: 8/100...  Loss: 0.3471\n",
      "Epoch: 8/100...  Loss: 0.3428\n",
      "Epoch: 8/100...  Loss: 0.3408\n",
      "Epoch: 8/100...  Loss: 0.3269\n",
      "Epoch: 8/100...  Loss: 0.3541\n",
      "Epoch: 8/100...  Loss: 0.3285\n",
      "Epoch: 8/100...  Loss: 0.3072\n",
      "Epoch: 8/100...  Loss: 0.3261\n",
      "Epoch: 8/100...  Loss: 0.2794\n",
      "Epoch: 8/100...  Loss: 0.3081\n",
      "Epoch: 8/100...  Loss: 0.3349\n",
      "Epoch: 8/100...  Loss: 0.3351\n",
      "Epoch: 8/100...  Loss: 0.2883\n",
      "Epoch: 8/100...  Loss: 0.3163\n",
      "Epoch: 8/100...  Loss: 0.3244\n",
      "Epoch: 8/100...  Loss: 0.2952\n",
      "Epoch: 8/100...  Loss: 0.3090\n",
      "Epoch: 8/100...  Loss: 0.3059\n",
      "Epoch: 8/100...  Loss: 0.3205\n",
      "Epoch: 8/100...  Loss: 0.3017\n",
      "Epoch: 9/100...  Loss: 0.1167\n",
      "Epoch: 9/100...  Loss: 0.3118\n",
      "Epoch: 9/100...  Loss: 0.2920\n",
      "Epoch: 9/100...  Loss: 0.3089\n",
      "Epoch: 9/100...  Loss: 0.3113\n",
      "Epoch: 9/100...  Loss: 0.3276\n",
      "Epoch: 9/100...  Loss: 0.3215\n",
      "Epoch: 9/100...  Loss: 0.2984\n",
      "Epoch: 9/100...  Loss: 0.3005\n",
      "Epoch: 9/100...  Loss: 0.3232\n",
      "Epoch: 9/100...  Loss: 0.2902\n",
      "Epoch: 9/100...  Loss: 0.3067\n",
      "Epoch: 9/100...  Loss: 0.3396\n",
      "Epoch: 9/100...  Loss: 0.3087\n",
      "Epoch: 9/100...  Loss: 0.2729\n",
      "Epoch: 9/100...  Loss: 0.3305\n",
      "Epoch: 9/100...  Loss: 0.3077\n",
      "Epoch: 9/100...  Loss: 0.3179\n",
      "Epoch: 9/100...  Loss: 0.3112\n",
      "Epoch: 9/100...  Loss: 0.3208\n",
      "Epoch: 9/100...  Loss: 0.3056\n",
      "Epoch: 9/100...  Loss: 0.2961\n",
      "Epoch: 9/100...  Loss: 0.2982\n",
      "Epoch: 9/100...  Loss: 0.2976\n",
      "Epoch: 10/100...  Loss: 0.2882\n",
      "Epoch: 10/100...  Loss: 0.2782\n",
      "Epoch: 10/100...  Loss: 0.2856\n",
      "Epoch: 10/100...  Loss: 0.3077\n",
      "Epoch: 10/100...  Loss: 0.3170\n",
      "Epoch: 10/100...  Loss: 0.2910\n",
      "Epoch: 10/100...  Loss: 0.3092\n",
      "Epoch: 10/100...  Loss: 0.3088\n",
      "Epoch: 10/100...  Loss: 0.2918\n",
      "Epoch: 10/100...  Loss: 0.2959\n",
      "Epoch: 10/100...  Loss: 0.3073\n",
      "Epoch: 10/100...  Loss: 0.2946\n",
      "Epoch: 10/100...  Loss: 0.3039\n",
      "Epoch: 10/100...  Loss: 0.3061\n",
      "Epoch: 10/100...  Loss: 0.3031\n",
      "Epoch: 10/100...  Loss: 0.2991\n",
      "Epoch: 10/100...  Loss: 0.2842\n",
      "Epoch: 10/100...  Loss: 0.3114\n",
      "Epoch: 10/100...  Loss: 0.2994\n",
      "Epoch: 10/100...  Loss: 0.2902\n",
      "Epoch: 10/100...  Loss: 0.2718\n",
      "Epoch: 10/100...  Loss: 0.2793\n",
      "Epoch: 10/100...  Loss: 0.3222\n",
      "Epoch: 11/100...  Loss: 0.1398\n",
      "Epoch: 11/100...  Loss: 0.2829\n",
      "Epoch: 11/100...  Loss: 0.2871\n",
      "Epoch: 11/100...  Loss: 0.2913\n",
      "Epoch: 11/100...  Loss: 0.2998\n",
      "Epoch: 11/100...  Loss: 0.2907\n",
      "Epoch: 11/100...  Loss: 0.2666\n",
      "Epoch: 11/100...  Loss: 0.2986\n",
      "Epoch: 11/100...  Loss: 0.2929\n",
      "Epoch: 11/100...  Loss: 0.2745\n",
      "Epoch: 11/100...  Loss: 0.2821\n",
      "Epoch: 11/100...  Loss: 0.2960\n",
      "Epoch: 11/100...  Loss: 0.3172\n",
      "Epoch: 11/100...  Loss: 0.2763\n",
      "Epoch: 11/100...  Loss: 0.2962\n",
      "Epoch: 11/100...  Loss: 0.3192\n",
      "Epoch: 11/100...  Loss: 0.2799\n",
      "Epoch: 11/100...  Loss: 0.2809\n",
      "Epoch: 11/100...  Loss: 0.2877\n",
      "Epoch: 11/100...  Loss: 0.2593\n",
      "Epoch: 11/100...  Loss: 0.3009\n",
      "Epoch: 11/100...  Loss: 0.2905\n",
      "Epoch: 11/100...  Loss: 0.3044\n",
      "Epoch: 12/100...  Loss: 0.0093\n",
      "Epoch: 12/100...  Loss: 0.2847\n",
      "Epoch: 12/100...  Loss: 0.2694\n",
      "Epoch: 12/100...  Loss: 0.2842\n",
      "Epoch: 12/100...  Loss: 0.2840\n",
      "Epoch: 12/100...  Loss: 0.3100\n",
      "Epoch: 12/100...  Loss: 0.2934\n",
      "Epoch: 12/100...  Loss: 0.2889\n",
      "Epoch: 12/100...  Loss: 0.2919\n",
      "Epoch: 12/100...  Loss: 0.2781\n",
      "Epoch: 12/100...  Loss: 0.2786\n",
      "Epoch: 12/100...  Loss: 0.2893\n",
      "Epoch: 12/100...  Loss: 0.2627\n",
      "Epoch: 12/100...  Loss: 0.2794\n",
      "Epoch: 12/100...  Loss: 0.2710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100...  Loss: 0.2638\n",
      "Epoch: 12/100...  Loss: 0.2808\n",
      "Epoch: 12/100...  Loss: 0.2895\n",
      "Epoch: 12/100...  Loss: 0.2802\n",
      "Epoch: 12/100...  Loss: 0.2917\n",
      "Epoch: 12/100...  Loss: 0.2625\n",
      "Epoch: 12/100...  Loss: 0.2950\n",
      "Epoch: 12/100...  Loss: 0.2659\n",
      "Epoch: 12/100...  Loss: 0.2785\n",
      "Epoch: 13/100...  Loss: 0.1555\n",
      "Epoch: 13/100...  Loss: 0.2801\n",
      "Epoch: 13/100...  Loss: 0.2523\n",
      "Epoch: 13/100...  Loss: 0.2910\n",
      "Epoch: 13/100...  Loss: 0.2818\n",
      "Epoch: 13/100...  Loss: 0.2771\n",
      "Epoch: 13/100...  Loss: 0.2797\n",
      "Epoch: 13/100...  Loss: 0.2730\n",
      "Epoch: 13/100...  Loss: 0.2599\n",
      "Epoch: 13/100...  Loss: 0.2929\n",
      "Epoch: 13/100...  Loss: 0.2541\n",
      "Epoch: 13/100...  Loss: 0.2791\n",
      "Epoch: 13/100...  Loss: 0.2667\n",
      "Epoch: 13/100...  Loss: 0.2612\n",
      "Epoch: 13/100...  Loss: 0.2690\n",
      "Epoch: 13/100...  Loss: 0.2823\n",
      "Epoch: 13/100...  Loss: 0.2442\n",
      "Epoch: 13/100...  Loss: 0.2825\n",
      "Epoch: 13/100...  Loss: 0.2942\n",
      "Epoch: 13/100...  Loss: 0.2486\n",
      "Epoch: 13/100...  Loss: 0.2705\n",
      "Epoch: 13/100...  Loss: 0.2734\n",
      "Epoch: 13/100...  Loss: 0.2894\n",
      "Epoch: 14/100...  Loss: 0.0413\n",
      "Epoch: 14/100...  Loss: 0.2702\n",
      "Epoch: 14/100...  Loss: 0.2894\n",
      "Epoch: 14/100...  Loss: 0.2720\n",
      "Epoch: 14/100...  Loss: 0.2669\n",
      "Epoch: 14/100...  Loss: 0.2381\n",
      "Epoch: 14/100...  Loss: 0.2834\n",
      "Epoch: 14/100...  Loss: 0.2709\n",
      "Epoch: 14/100...  Loss: 0.2470\n",
      "Epoch: 14/100...  Loss: 0.2795\n",
      "Epoch: 14/100...  Loss: 0.2404\n",
      "Epoch: 14/100...  Loss: 0.2600\n",
      "Epoch: 14/100...  Loss: 0.2884\n",
      "Epoch: 14/100...  Loss: 0.2444\n",
      "Epoch: 14/100...  Loss: 0.2494\n",
      "Epoch: 14/100...  Loss: 0.2621\n",
      "Epoch: 14/100...  Loss: 0.2602\n",
      "Epoch: 14/100...  Loss: 0.2871\n",
      "Epoch: 14/100...  Loss: 0.2358\n",
      "Epoch: 14/100...  Loss: 0.2404\n",
      "Epoch: 14/100...  Loss: 0.3027\n",
      "Epoch: 14/100...  Loss: 0.2811\n",
      "Epoch: 14/100...  Loss: 0.2801\n",
      "Epoch: 14/100...  Loss: 0.2666\n",
      "Epoch: 15/100...  Loss: 0.1786\n",
      "Epoch: 15/100...  Loss: 0.2220\n",
      "Epoch: 15/100...  Loss: 0.2900\n",
      "Epoch: 15/100...  Loss: 0.2710\n",
      "Epoch: 15/100...  Loss: 0.2856\n",
      "Epoch: 15/100...  Loss: 0.2551\n",
      "Epoch: 15/100...  Loss: 0.2983\n",
      "Epoch: 15/100...  Loss: 0.2418\n",
      "Epoch: 15/100...  Loss: 0.2672\n",
      "Epoch: 15/100...  Loss: 0.2354\n",
      "Epoch: 15/100...  Loss: 0.2740\n",
      "Epoch: 15/100...  Loss: 0.2630\n",
      "Epoch: 15/100...  Loss: 0.2426\n",
      "Epoch: 15/100...  Loss: 0.2423\n",
      "Epoch: 15/100...  Loss: 0.2615\n",
      "Epoch: 15/100...  Loss: 0.2605\n",
      "Epoch: 15/100...  Loss: 0.2591\n",
      "Epoch: 15/100...  Loss: 0.2572\n",
      "Epoch: 15/100...  Loss: 0.2649\n",
      "Epoch: 15/100...  Loss: 0.2447\n",
      "Epoch: 15/100...  Loss: 0.2550\n",
      "Epoch: 15/100...  Loss: 0.2636\n",
      "Epoch: 15/100...  Loss: 0.2455\n",
      "Epoch: 16/100...  Loss: 0.0662\n",
      "Epoch: 16/100...  Loss: 0.2644\n",
      "Epoch: 16/100...  Loss: 0.2491\n",
      "Epoch: 16/100...  Loss: 0.2523\n",
      "Epoch: 16/100...  Loss: 0.2517\n",
      "Epoch: 16/100...  Loss: 0.2306\n",
      "Epoch: 16/100...  Loss: 0.2231\n",
      "Epoch: 16/100...  Loss: 0.2665\n",
      "Epoch: 16/100...  Loss: 0.2543\n",
      "Epoch: 16/100...  Loss: 0.2660\n",
      "Epoch: 16/100...  Loss: 0.2357\n",
      "Epoch: 16/100...  Loss: 0.2809\n",
      "Epoch: 16/100...  Loss: 0.2605\n",
      "Epoch: 16/100...  Loss: 0.2409\n",
      "Epoch: 16/100...  Loss: 0.2625\n",
      "Epoch: 16/100...  Loss: 0.2364\n",
      "Epoch: 16/100...  Loss: 0.2891\n",
      "Epoch: 16/100...  Loss: 0.2460\n",
      "Epoch: 16/100...  Loss: 0.2310\n",
      "Epoch: 16/100...  Loss: 0.2310\n",
      "Epoch: 16/100...  Loss: 0.2831\n",
      "Epoch: 16/100...  Loss: 0.2335\n",
      "Epoch: 16/100...  Loss: 0.2541\n",
      "Epoch: 16/100...  Loss: 0.2473\n",
      "Epoch: 17/100...  Loss: 0.2115\n",
      "Epoch: 17/100...  Loss: 0.2489\n",
      "Epoch: 17/100...  Loss: 0.2509\n",
      "Epoch: 17/100...  Loss: 0.2343\n",
      "Epoch: 17/100...  Loss: 0.2456\n",
      "Epoch: 17/100...  Loss: 0.2562\n",
      "Epoch: 17/100...  Loss: 0.2602\n",
      "Epoch: 17/100...  Loss: 0.2366\n",
      "Epoch: 17/100...  Loss: 0.2612\n",
      "Epoch: 17/100...  Loss: 0.2236\n",
      "Epoch: 17/100...  Loss: 0.2520\n",
      "Epoch: 17/100...  Loss: 0.2432\n",
      "Epoch: 17/100...  Loss: 0.2553\n",
      "Epoch: 17/100...  Loss: 0.2451\n",
      "Epoch: 17/100...  Loss: 0.2506\n",
      "Epoch: 17/100...  Loss: 0.2419\n",
      "Epoch: 17/100...  Loss: 0.2363\n",
      "Epoch: 17/100...  Loss: 0.2363\n",
      "Epoch: 17/100...  Loss: 0.2317\n",
      "Epoch: 17/100...  Loss: 0.2529\n",
      "Epoch: 17/100...  Loss: 0.2484\n",
      "Epoch: 17/100...  Loss: 0.2350\n",
      "Epoch: 17/100...  Loss: 0.2377\n",
      "Epoch: 18/100...  Loss: 0.0955\n",
      "Epoch: 18/100...  Loss: 0.2408\n",
      "Epoch: 18/100...  Loss: 0.2560\n",
      "Epoch: 18/100...  Loss: 0.2535\n",
      "Epoch: 18/100...  Loss: 0.2047\n",
      "Epoch: 18/100...  Loss: 0.2437\n",
      "Epoch: 18/100...  Loss: 0.2456\n",
      "Epoch: 18/100...  Loss: 0.2343\n",
      "Epoch: 18/100...  Loss: 0.2593\n",
      "Epoch: 18/100...  Loss: 0.2334\n",
      "Epoch: 18/100...  Loss: 0.2469\n",
      "Epoch: 18/100...  Loss: 0.2433\n",
      "Epoch: 18/100...  Loss: 0.2409\n",
      "Epoch: 18/100...  Loss: 0.2687\n",
      "Epoch: 18/100...  Loss: 0.2424\n",
      "Epoch: 18/100...  Loss: 0.2342\n",
      "Epoch: 18/100...  Loss: 0.2275\n",
      "Epoch: 18/100...  Loss: 0.2308\n",
      "Epoch: 18/100...  Loss: 0.2518\n",
      "Epoch: 18/100...  Loss: 0.2245\n",
      "Epoch: 18/100...  Loss: 0.2161\n",
      "Epoch: 18/100...  Loss: 0.2146\n",
      "Epoch: 18/100...  Loss: 0.2364\n",
      "Epoch: 18/100...  Loss: 0.2502\n",
      "Epoch: 19/100...  Loss: 0.1859\n",
      "Epoch: 19/100...  Loss: 0.2118\n",
      "Epoch: 19/100...  Loss: 0.2662\n",
      "Epoch: 19/100...  Loss: 0.2603\n",
      "Epoch: 19/100...  Loss: 0.2292\n",
      "Epoch: 19/100...  Loss: 0.2332\n",
      "Epoch: 19/100...  Loss: 0.2337\n",
      "Epoch: 19/100...  Loss: 0.2233\n",
      "Epoch: 19/100...  Loss: 0.2269\n",
      "Epoch: 19/100...  Loss: 0.2392\n",
      "Epoch: 19/100...  Loss: 0.2516\n",
      "Epoch: 19/100...  Loss: 0.2354\n",
      "Epoch: 19/100...  Loss: 0.2204\n",
      "Epoch: 19/100...  Loss: 0.2372\n",
      "Epoch: 19/100...  Loss: 0.2497\n",
      "Epoch: 19/100...  Loss: 0.2397\n",
      "Epoch: 19/100...  Loss: 0.2285\n",
      "Epoch: 19/100...  Loss: 0.2183\n",
      "Epoch: 19/100...  Loss: 0.2104\n",
      "Epoch: 19/100...  Loss: 0.2035\n",
      "Epoch: 19/100...  Loss: 0.2503\n",
      "Epoch: 19/100...  Loss: 0.2486\n",
      "Epoch: 19/100...  Loss: 0.2423\n",
      "Epoch: 20/100...  Loss: 0.1146\n",
      "Epoch: 20/100...  Loss: 0.2229\n",
      "Epoch: 20/100...  Loss: 0.2522\n",
      "Epoch: 20/100...  Loss: 0.2320\n",
      "Epoch: 20/100...  Loss: 0.2150\n",
      "Epoch: 20/100...  Loss: 0.2247\n",
      "Epoch: 20/100...  Loss: 0.2570\n",
      "Epoch: 20/100...  Loss: 0.2264\n",
      "Epoch: 20/100...  Loss: 0.2274\n",
      "Epoch: 20/100...  Loss: 0.2349\n",
      "Epoch: 20/100...  Loss: 0.2185\n",
      "Epoch: 20/100...  Loss: 0.2382\n",
      "Epoch: 20/100...  Loss: 0.2142\n",
      "Epoch: 20/100...  Loss: 0.2330\n",
      "Epoch: 20/100...  Loss: 0.2262\n",
      "Epoch: 20/100...  Loss: 0.2148\n",
      "Epoch: 20/100...  Loss: 0.2235\n",
      "Epoch: 20/100...  Loss: 0.1961\n",
      "Epoch: 20/100...  Loss: 0.2284\n",
      "Epoch: 20/100...  Loss: 0.2284\n",
      "Epoch: 20/100...  Loss: 0.2259\n",
      "Epoch: 20/100...  Loss: 0.2455\n",
      "Epoch: 20/100...  Loss: 0.2171\n",
      "Epoch: 20/100...  Loss: 0.2173\n",
      "Epoch: 21/100...  Loss: 0.2200\n",
      "Epoch: 21/100...  Loss: 0.2232\n",
      "Epoch: 21/100...  Loss: 0.2270\n",
      "Epoch: 21/100...  Loss: 0.2097\n",
      "Epoch: 21/100...  Loss: 0.2149\n",
      "Epoch: 21/100...  Loss: 0.2253\n",
      "Epoch: 21/100...  Loss: 0.2140\n",
      "Epoch: 21/100...  Loss: 0.2189\n",
      "Epoch: 21/100...  Loss: 0.2281\n",
      "Epoch: 21/100...  Loss: 0.2299\n",
      "Epoch: 21/100...  Loss: 0.2428\n",
      "Epoch: 21/100...  Loss: 0.2437\n",
      "Epoch: 21/100...  Loss: 0.2193\n",
      "Epoch: 21/100...  Loss: 0.2059\n",
      "Epoch: 21/100...  Loss: 0.2139\n",
      "Epoch: 21/100...  Loss: 0.2285\n",
      "Epoch: 21/100...  Loss: 0.2505\n",
      "Epoch: 21/100...  Loss: 0.2146\n",
      "Epoch: 21/100...  Loss: 0.2082\n",
      "Epoch: 21/100...  Loss: 0.2306\n",
      "Epoch: 21/100...  Loss: 0.2230\n",
      "Epoch: 21/100...  Loss: 0.2030\n",
      "Epoch: 21/100...  Loss: 0.2110\n",
      "Epoch: 22/100...  Loss: 0.1137\n",
      "Epoch: 22/100...  Loss: 0.2033\n",
      "Epoch: 22/100...  Loss: 0.2207\n",
      "Epoch: 22/100...  Loss: 0.2153\n",
      "Epoch: 22/100...  Loss: 0.2140\n",
      "Epoch: 22/100...  Loss: 0.2425\n",
      "Epoch: 22/100...  Loss: 0.2315\n",
      "Epoch: 22/100...  Loss: 0.2043\n",
      "Epoch: 22/100...  Loss: 0.2277\n",
      "Epoch: 22/100...  Loss: 0.2260\n",
      "Epoch: 22/100...  Loss: 0.2204\n",
      "Epoch: 22/100...  Loss: 0.2021\n",
      "Epoch: 22/100...  Loss: 0.2220\n",
      "Epoch: 22/100...  Loss: 0.2034\n",
      "Epoch: 22/100...  Loss: 0.2204\n",
      "Epoch: 22/100...  Loss: 0.2178\n",
      "Epoch: 22/100...  Loss: 0.2372\n",
      "Epoch: 22/100...  Loss: 0.1967\n",
      "Epoch: 22/100...  Loss: 0.2197\n",
      "Epoch: 22/100...  Loss: 0.2032\n",
      "Epoch: 22/100...  Loss: 0.2119\n",
      "Epoch: 22/100...  Loss: 0.2234\n",
      "Epoch: 22/100...  Loss: 0.2267\n",
      "Epoch: 23/100...  Loss: 0.0244\n",
      "Epoch: 23/100...  Loss: 0.2158\n",
      "Epoch: 23/100...  Loss: 0.2374\n",
      "Epoch: 23/100...  Loss: 0.2164\n",
      "Epoch: 23/100...  Loss: 0.2330\n",
      "Epoch: 23/100...  Loss: 0.1806\n",
      "Epoch: 23/100...  Loss: 0.1998\n",
      "Epoch: 23/100...  Loss: 0.1834\n",
      "Epoch: 23/100...  Loss: 0.1975\n",
      "Epoch: 23/100...  Loss: 0.1985\n",
      "Epoch: 23/100...  Loss: 0.2095\n",
      "Epoch: 23/100...  Loss: 0.2138\n",
      "Epoch: 23/100...  Loss: 0.2135\n",
      "Epoch: 23/100...  Loss: 0.2240\n",
      "Epoch: 23/100...  Loss: 0.1952\n",
      "Epoch: 23/100...  Loss: 0.2216\n",
      "Epoch: 23/100...  Loss: 0.2001\n",
      "Epoch: 23/100...  Loss: 0.2221\n",
      "Epoch: 23/100...  Loss: 0.2184\n",
      "Epoch: 23/100...  Loss: 0.2155\n",
      "Epoch: 23/100...  Loss: 0.2277\n",
      "Epoch: 23/100...  Loss: 0.2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100...  Loss: 0.2173\n",
      "Epoch: 23/100...  Loss: 0.1931\n",
      "Epoch: 24/100...  Loss: 0.1309\n",
      "Epoch: 24/100...  Loss: 0.1969\n",
      "Epoch: 24/100...  Loss: 0.1885\n",
      "Epoch: 24/100...  Loss: 0.2168\n",
      "Epoch: 24/100...  Loss: 0.2000\n",
      "Epoch: 24/100...  Loss: 0.1873\n",
      "Epoch: 24/100...  Loss: 0.2228\n",
      "Epoch: 24/100...  Loss: 0.2004\n",
      "Epoch: 24/100...  Loss: 0.2066\n",
      "Epoch: 24/100...  Loss: 0.1995\n",
      "Epoch: 24/100...  Loss: 0.2259\n",
      "Epoch: 24/100...  Loss: 0.1965\n",
      "Epoch: 24/100...  Loss: 0.2167\n",
      "Epoch: 24/100...  Loss: 0.2033\n",
      "Epoch: 24/100...  Loss: 0.1916\n",
      "Epoch: 24/100...  Loss: 0.2005\n",
      "Epoch: 24/100...  Loss: 0.2212\n",
      "Epoch: 24/100...  Loss: 0.2120\n",
      "Epoch: 24/100...  Loss: 0.2127\n",
      "Epoch: 24/100...  Loss: 0.2151\n",
      "Epoch: 24/100...  Loss: 0.2064\n",
      "Epoch: 24/100...  Loss: 0.2035\n",
      "Epoch: 24/100...  Loss: 0.1833\n",
      "Epoch: 25/100...  Loss: 0.0393\n",
      "Epoch: 25/100...  Loss: 0.2154\n",
      "Epoch: 25/100...  Loss: 0.2090\n",
      "Epoch: 25/100...  Loss: 0.2420\n",
      "Epoch: 25/100...  Loss: 0.2089\n",
      "Epoch: 25/100...  Loss: 0.1908\n",
      "Epoch: 25/100...  Loss: 0.2113\n",
      "Epoch: 25/100...  Loss: 0.2070\n",
      "Epoch: 25/100...  Loss: 0.2164\n",
      "Epoch: 25/100...  Loss: 0.2149\n",
      "Epoch: 25/100...  Loss: 0.1870\n",
      "Epoch: 25/100...  Loss: 0.1814\n",
      "Epoch: 25/100...  Loss: 0.1839\n",
      "Epoch: 25/100...  Loss: 0.1945\n",
      "Epoch: 25/100...  Loss: 0.2079\n",
      "Epoch: 25/100...  Loss: 0.1735\n",
      "Epoch: 25/100...  Loss: 0.1908\n",
      "Epoch: 25/100...  Loss: 0.2028\n",
      "Epoch: 25/100...  Loss: 0.1786\n",
      "Epoch: 25/100...  Loss: 0.1796\n",
      "Epoch: 25/100...  Loss: 0.2040\n",
      "Epoch: 25/100...  Loss: 0.1960\n",
      "Epoch: 25/100...  Loss: 0.2141\n",
      "Epoch: 25/100...  Loss: 0.2131\n",
      "Epoch: 26/100...  Loss: 0.1479\n",
      "Epoch: 26/100...  Loss: 0.2107\n",
      "Epoch: 26/100...  Loss: 0.2060\n",
      "Epoch: 26/100...  Loss: 0.1992\n",
      "Epoch: 26/100...  Loss: 0.2071\n",
      "Epoch: 26/100...  Loss: 0.1827\n",
      "Epoch: 26/100...  Loss: 0.1929\n",
      "Epoch: 26/100...  Loss: 0.1982\n",
      "Epoch: 26/100...  Loss: 0.1900\n",
      "Epoch: 26/100...  Loss: 0.2204\n",
      "Epoch: 26/100...  Loss: 0.2055\n",
      "Epoch: 26/100...  Loss: 0.1974\n",
      "Epoch: 26/100...  Loss: 0.1970\n",
      "Epoch: 26/100...  Loss: 0.1950\n",
      "Epoch: 26/100...  Loss: 0.2000\n",
      "Epoch: 26/100...  Loss: 0.2019\n",
      "Epoch: 26/100...  Loss: 0.1827\n",
      "Epoch: 26/100...  Loss: 0.1852\n",
      "Epoch: 26/100...  Loss: 0.1877\n",
      "Epoch: 26/100...  Loss: 0.1913\n",
      "Epoch: 26/100...  Loss: 0.1900\n",
      "Epoch: 26/100...  Loss: 0.1876\n",
      "Epoch: 26/100...  Loss: 0.2011\n",
      "Epoch: 27/100...  Loss: 0.0499\n",
      "Epoch: 27/100...  Loss: 0.1868\n",
      "Epoch: 27/100...  Loss: 0.1865\n",
      "Epoch: 27/100...  Loss: 0.1866\n",
      "Epoch: 27/100...  Loss: 0.2108\n",
      "Epoch: 27/100...  Loss: 0.1753\n",
      "Epoch: 27/100...  Loss: 0.1879\n",
      "Epoch: 27/100...  Loss: 0.1954\n",
      "Epoch: 27/100...  Loss: 0.1855\n",
      "Epoch: 27/100...  Loss: 0.2049\n",
      "Epoch: 27/100...  Loss: 0.1880\n",
      "Epoch: 27/100...  Loss: 0.1855\n",
      "Epoch: 27/100...  Loss: 0.1968\n",
      "Epoch: 27/100...  Loss: 0.2155\n",
      "Epoch: 27/100...  Loss: 0.1995\n",
      "Epoch: 27/100...  Loss: 0.1804\n",
      "Epoch: 27/100...  Loss: 0.1930\n",
      "Epoch: 27/100...  Loss: 0.1789\n",
      "Epoch: 27/100...  Loss: 0.1759\n",
      "Epoch: 27/100...  Loss: 0.2113\n",
      "Epoch: 27/100...  Loss: 0.2079\n",
      "Epoch: 27/100...  Loss: 0.1914\n",
      "Epoch: 27/100...  Loss: 0.1876\n",
      "Epoch: 27/100...  Loss: 0.1877\n",
      "Epoch: 28/100...  Loss: 0.1593\n",
      "Epoch: 28/100...  Loss: 0.2088\n",
      "Epoch: 28/100...  Loss: 0.1819\n",
      "Epoch: 28/100...  Loss: 0.1940\n",
      "Epoch: 28/100...  Loss: 0.1845\n",
      "Epoch: 28/100...  Loss: 0.1903\n",
      "Epoch: 28/100...  Loss: 0.2100\n",
      "Epoch: 28/100...  Loss: 0.1948\n",
      "Epoch: 28/100...  Loss: 0.1852\n",
      "Epoch: 28/100...  Loss: 0.1839\n",
      "Epoch: 28/100...  Loss: 0.1911\n",
      "Epoch: 28/100...  Loss: 0.2022\n",
      "Epoch: 28/100...  Loss: 0.1713\n",
      "Epoch: 28/100...  Loss: 0.1725\n",
      "Epoch: 28/100...  Loss: 0.1869\n",
      "Epoch: 28/100...  Loss: 0.1785\n",
      "Epoch: 28/100...  Loss: 0.1728\n",
      "Epoch: 28/100...  Loss: 0.1950\n",
      "Epoch: 28/100...  Loss: 0.1852\n",
      "Epoch: 28/100...  Loss: 0.1826\n",
      "Epoch: 28/100...  Loss: 0.2044\n",
      "Epoch: 28/100...  Loss: 0.1881\n",
      "Epoch: 28/100...  Loss: 0.1776\n",
      "Epoch: 29/100...  Loss: 0.0779\n",
      "Epoch: 29/100...  Loss: 0.1925\n",
      "Epoch: 29/100...  Loss: 0.1710\n",
      "Epoch: 29/100...  Loss: 0.1654\n",
      "Epoch: 29/100...  Loss: 0.1861\n",
      "Epoch: 29/100...  Loss: 0.2011\n",
      "Epoch: 29/100...  Loss: 0.2019\n",
      "Epoch: 29/100...  Loss: 0.1693\n",
      "Epoch: 29/100...  Loss: 0.1863\n",
      "Epoch: 29/100...  Loss: 0.1866\n",
      "Epoch: 29/100...  Loss: 0.2035\n",
      "Epoch: 29/100...  Loss: 0.1885\n",
      "Epoch: 29/100...  Loss: 0.1770\n",
      "Epoch: 29/100...  Loss: 0.1735\n",
      "Epoch: 29/100...  Loss: 0.1811\n",
      "Epoch: 29/100...  Loss: 0.1840\n",
      "Epoch: 29/100...  Loss: 0.1842\n",
      "Epoch: 29/100...  Loss: 0.1668\n",
      "Epoch: 29/100...  Loss: 0.1580\n",
      "Epoch: 29/100...  Loss: 0.1861\n",
      "Epoch: 29/100...  Loss: 0.1704\n",
      "Epoch: 29/100...  Loss: 0.1890\n",
      "Epoch: 29/100...  Loss: 0.1883\n",
      "Epoch: 29/100...  Loss: 0.2039\n",
      "Epoch: 30/100...  Loss: 0.2031\n",
      "Epoch: 30/100...  Loss: 0.1898\n",
      "Epoch: 30/100...  Loss: 0.1519\n",
      "Epoch: 30/100...  Loss: 0.1733\n",
      "Epoch: 30/100...  Loss: 0.1812\n",
      "Epoch: 30/100...  Loss: 0.1633\n",
      "Epoch: 30/100...  Loss: 0.2003\n",
      "Epoch: 30/100...  Loss: 0.1750\n",
      "Epoch: 30/100...  Loss: 0.1808\n",
      "Epoch: 30/100...  Loss: 0.1811\n",
      "Epoch: 30/100...  Loss: 0.1844\n",
      "Epoch: 30/100...  Loss: 0.1576\n",
      "Epoch: 30/100...  Loss: 0.1823\n",
      "Epoch: 30/100...  Loss: 0.1887\n",
      "Epoch: 30/100...  Loss: 0.1615\n",
      "Epoch: 30/100...  Loss: 0.1667\n",
      "Epoch: 30/100...  Loss: 0.1897\n",
      "Epoch: 30/100...  Loss: 0.1860\n",
      "Epoch: 30/100...  Loss: 0.1777\n",
      "Epoch: 30/100...  Loss: 0.1813\n",
      "Epoch: 30/100...  Loss: 0.1779\n",
      "Epoch: 30/100...  Loss: 0.1823\n",
      "Epoch: 30/100...  Loss: 0.1754\n",
      "Epoch: 31/100...  Loss: 0.0823\n",
      "Epoch: 31/100...  Loss: 0.1822\n",
      "Epoch: 31/100...  Loss: 0.2090\n",
      "Epoch: 31/100...  Loss: 0.1829\n",
      "Epoch: 31/100...  Loss: 0.1567\n",
      "Epoch: 31/100...  Loss: 0.1703\n",
      "Epoch: 31/100...  Loss: 0.1750\n",
      "Epoch: 31/100...  Loss: 0.1711\n",
      "Epoch: 31/100...  Loss: 0.1710\n",
      "Epoch: 31/100...  Loss: 0.1777\n",
      "Epoch: 31/100...  Loss: 0.1688\n",
      "Epoch: 31/100...  Loss: 0.1898\n",
      "Epoch: 31/100...  Loss: 0.1620\n",
      "Epoch: 31/100...  Loss: 0.1651\n",
      "Epoch: 31/100...  Loss: 0.1849\n",
      "Epoch: 31/100...  Loss: 0.1826\n",
      "Epoch: 31/100...  Loss: 0.1894\n",
      "Epoch: 31/100...  Loss: 0.1631\n",
      "Epoch: 31/100...  Loss: 0.1740\n",
      "Epoch: 31/100...  Loss: 0.1747\n",
      "Epoch: 31/100...  Loss: 0.1721\n",
      "Epoch: 31/100...  Loss: 0.1809\n",
      "Epoch: 31/100...  Loss: 0.1554\n",
      "Epoch: 32/100...  Loss: 0.0102\n",
      "Epoch: 32/100...  Loss: 0.1745\n",
      "Epoch: 32/100...  Loss: 0.1801\n",
      "Epoch: 32/100...  Loss: 0.1568\n",
      "Epoch: 32/100...  Loss: 0.2023\n",
      "Epoch: 32/100...  Loss: 0.1761\n",
      "Epoch: 32/100...  Loss: 0.1770\n",
      "Epoch: 32/100...  Loss: 0.1615\n",
      "Epoch: 32/100...  Loss: 0.1778\n",
      "Epoch: 32/100...  Loss: 0.1632\n",
      "Epoch: 32/100...  Loss: 0.1840\n",
      "Epoch: 32/100...  Loss: 0.1775\n",
      "Epoch: 32/100...  Loss: 0.1713\n",
      "Epoch: 32/100...  Loss: 0.1647\n",
      "Epoch: 32/100...  Loss: 0.1974\n",
      "Epoch: 32/100...  Loss: 0.1673\n",
      "Epoch: 32/100...  Loss: 0.1704\n",
      "Epoch: 32/100...  Loss: 0.1618\n",
      "Epoch: 32/100...  Loss: 0.1738\n",
      "Epoch: 32/100...  Loss: 0.1698\n",
      "Epoch: 32/100...  Loss: 0.1701\n",
      "Epoch: 32/100...  Loss: 0.1608\n",
      "Epoch: 32/100...  Loss: 0.1563\n",
      "Epoch: 32/100...  Loss: 0.1602\n",
      "Epoch: 33/100...  Loss: 0.1129\n",
      "Epoch: 33/100...  Loss: 0.1788\n",
      "Epoch: 33/100...  Loss: 0.1758\n",
      "Epoch: 33/100...  Loss: 0.1600\n",
      "Epoch: 33/100...  Loss: 0.1747\n",
      "Epoch: 33/100...  Loss: 0.1798\n",
      "Epoch: 33/100...  Loss: 0.1771\n",
      "Epoch: 33/100...  Loss: 0.1605\n",
      "Epoch: 33/100...  Loss: 0.1807\n",
      "Epoch: 33/100...  Loss: 0.1588\n",
      "Epoch: 33/100...  Loss: 0.1965\n",
      "Epoch: 33/100...  Loss: 0.1610\n",
      "Epoch: 33/100...  Loss: 0.1710\n",
      "Epoch: 33/100...  Loss: 0.1610\n",
      "Epoch: 33/100...  Loss: 0.1466\n",
      "Epoch: 33/100...  Loss: 0.1538\n",
      "Epoch: 33/100...  Loss: 0.1478\n",
      "Epoch: 33/100...  Loss: 0.1667\n",
      "Epoch: 33/100...  Loss: 0.1601\n",
      "Epoch: 33/100...  Loss: 0.1736\n",
      "Epoch: 33/100...  Loss: 0.1674\n",
      "Epoch: 33/100...  Loss: 0.1576\n",
      "Epoch: 33/100...  Loss: 0.1613\n",
      "Epoch: 34/100...  Loss: 0.0254\n",
      "Epoch: 34/100...  Loss: 0.1760\n",
      "Epoch: 34/100...  Loss: 0.1742\n",
      "Epoch: 34/100...  Loss: 0.1641\n",
      "Epoch: 34/100...  Loss: 0.1689\n",
      "Epoch: 34/100...  Loss: 0.1682\n",
      "Epoch: 34/100...  Loss: 0.1730\n",
      "Epoch: 34/100...  Loss: 0.1659\n",
      "Epoch: 34/100...  Loss: 0.1692\n",
      "Epoch: 34/100...  Loss: 0.1525\n",
      "Epoch: 34/100...  Loss: 0.1755\n",
      "Epoch: 34/100...  Loss: 0.1742\n",
      "Epoch: 34/100...  Loss: 0.1463\n",
      "Epoch: 34/100...  Loss: 0.1662\n",
      "Epoch: 34/100...  Loss: 0.1685\n",
      "Epoch: 34/100...  Loss: 0.1576\n",
      "Epoch: 34/100...  Loss: 0.1424\n",
      "Epoch: 34/100...  Loss: 0.1557\n",
      "Epoch: 34/100...  Loss: 0.1628\n",
      "Epoch: 34/100...  Loss: 0.1683\n",
      "Epoch: 34/100...  Loss: 0.1513\n",
      "Epoch: 34/100...  Loss: 0.1688\n",
      "Epoch: 34/100...  Loss: 0.1594\n",
      "Epoch: 34/100...  Loss: 0.1714\n",
      "Epoch: 35/100...  Loss: 0.1115\n",
      "Epoch: 35/100...  Loss: 0.1582\n",
      "Epoch: 35/100...  Loss: 0.1536\n",
      "Epoch: 35/100...  Loss: 0.1604\n",
      "Epoch: 35/100...  Loss: 0.1552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100...  Loss: 0.1444\n",
      "Epoch: 35/100...  Loss: 0.1782\n",
      "Epoch: 35/100...  Loss: 0.1696\n",
      "Epoch: 35/100...  Loss: 0.1475\n",
      "Epoch: 35/100...  Loss: 0.1592\n",
      "Epoch: 35/100...  Loss: 0.1563\n",
      "Epoch: 35/100...  Loss: 0.1597\n",
      "Epoch: 35/100...  Loss: 0.1782\n",
      "Epoch: 35/100...  Loss: 0.1583\n",
      "Epoch: 35/100...  Loss: 0.1503\n",
      "Epoch: 35/100...  Loss: 0.1501\n",
      "Epoch: 35/100...  Loss: 0.1552\n",
      "Epoch: 35/100...  Loss: 0.1681\n",
      "Epoch: 35/100...  Loss: 0.1606\n",
      "Epoch: 35/100...  Loss: 0.1951\n",
      "Epoch: 35/100...  Loss: 0.1693\n",
      "Epoch: 35/100...  Loss: 0.1488\n",
      "Epoch: 35/100...  Loss: 0.1651\n",
      "Epoch: 36/100...  Loss: 0.0460\n",
      "Epoch: 36/100...  Loss: 0.1466\n",
      "Epoch: 36/100...  Loss: 0.1578\n",
      "Epoch: 36/100...  Loss: 0.1543\n",
      "Epoch: 36/100...  Loss: 0.1607\n",
      "Epoch: 36/100...  Loss: 0.1685\n",
      "Epoch: 36/100...  Loss: 0.1605\n",
      "Epoch: 36/100...  Loss: 0.1523\n",
      "Epoch: 36/100...  Loss: 0.1549\n",
      "Epoch: 36/100...  Loss: 0.1395\n",
      "Epoch: 36/100...  Loss: 0.1710\n",
      "Epoch: 36/100...  Loss: 0.1651\n",
      "Epoch: 36/100...  Loss: 0.1482\n",
      "Epoch: 36/100...  Loss: 0.1591\n",
      "Epoch: 36/100...  Loss: 0.1496\n",
      "Epoch: 36/100...  Loss: 0.1550\n",
      "Epoch: 36/100...  Loss: 0.1481\n",
      "Epoch: 36/100...  Loss: 0.1636\n",
      "Epoch: 36/100...  Loss: 0.1555\n",
      "Epoch: 36/100...  Loss: 0.1554\n",
      "Epoch: 36/100...  Loss: 0.1489\n",
      "Epoch: 36/100...  Loss: 0.1702\n",
      "Epoch: 36/100...  Loss: 0.1721\n",
      "Epoch: 36/100...  Loss: 0.1688\n",
      "Epoch: 37/100...  Loss: 0.1102\n",
      "Epoch: 37/100...  Loss: 0.1593\n",
      "Epoch: 37/100...  Loss: 0.1398\n",
      "Epoch: 37/100...  Loss: 0.1412\n",
      "Epoch: 37/100...  Loss: 0.1472\n",
      "Epoch: 37/100...  Loss: 0.1639\n",
      "Epoch: 37/100...  Loss: 0.1507\n",
      "Epoch: 37/100...  Loss: 0.1553\n",
      "Epoch: 37/100...  Loss: 0.1523\n",
      "Epoch: 37/100...  Loss: 0.1773\n",
      "Epoch: 37/100...  Loss: 0.1475\n",
      "Epoch: 37/100...  Loss: 0.1577\n",
      "Epoch: 37/100...  Loss: 0.1534\n",
      "Epoch: 37/100...  Loss: 0.1480\n",
      "Epoch: 37/100...  Loss: 0.1659\n",
      "Epoch: 37/100...  Loss: 0.1562\n",
      "Epoch: 37/100...  Loss: 0.1777\n",
      "Epoch: 37/100...  Loss: 0.1457\n",
      "Epoch: 37/100...  Loss: 0.1514\n",
      "Epoch: 37/100...  Loss: 0.1647\n",
      "Epoch: 37/100...  Loss: 0.1496\n",
      "Epoch: 37/100...  Loss: 0.1520\n",
      "Epoch: 37/100...  Loss: 0.1608\n",
      "Epoch: 38/100...  Loss: 0.0577\n",
      "Epoch: 38/100...  Loss: 0.1618\n",
      "Epoch: 38/100...  Loss: 0.1480\n",
      "Epoch: 38/100...  Loss: 0.1373\n",
      "Epoch: 38/100...  Loss: 0.1541\n",
      "Epoch: 38/100...  Loss: 0.1706\n",
      "Epoch: 38/100...  Loss: 0.1661\n",
      "Epoch: 38/100...  Loss: 0.1601\n",
      "Epoch: 38/100...  Loss: 0.1433\n",
      "Epoch: 38/100...  Loss: 0.1670\n",
      "Epoch: 38/100...  Loss: 0.1442\n",
      "Epoch: 38/100...  Loss: 0.1458\n",
      "Epoch: 38/100...  Loss: 0.1522\n",
      "Epoch: 38/100...  Loss: 0.1480\n",
      "Epoch: 38/100...  Loss: 0.1507\n",
      "Epoch: 38/100...  Loss: 0.1558\n",
      "Epoch: 38/100...  Loss: 0.1391\n",
      "Epoch: 38/100...  Loss: 0.1463\n",
      "Epoch: 38/100...  Loss: 0.1518\n",
      "Epoch: 38/100...  Loss: 0.1578\n",
      "Epoch: 38/100...  Loss: 0.1493\n",
      "Epoch: 38/100...  Loss: 0.1426\n",
      "Epoch: 38/100...  Loss: 0.1369\n",
      "Epoch: 38/100...  Loss: 0.1538\n",
      "Epoch: 39/100...  Loss: 0.1272\n",
      "Epoch: 39/100...  Loss: 0.1506\n",
      "Epoch: 39/100...  Loss: 0.1487\n",
      "Epoch: 39/100...  Loss: 0.1355\n",
      "Epoch: 39/100...  Loss: 0.1400\n",
      "Epoch: 39/100...  Loss: 0.1617\n",
      "Epoch: 39/100...  Loss: 0.1420\n",
      "Epoch: 39/100...  Loss: 0.1444\n",
      "Epoch: 39/100...  Loss: 0.1666\n",
      "Epoch: 39/100...  Loss: 0.1359\n",
      "Epoch: 39/100...  Loss: 0.1411\n",
      "Epoch: 39/100...  Loss: 0.1505\n",
      "Epoch: 39/100...  Loss: 0.1600\n",
      "Epoch: 39/100...  Loss: 0.1568\n",
      "Epoch: 39/100...  Loss: 0.1349\n",
      "Epoch: 39/100...  Loss: 0.1571\n",
      "Epoch: 39/100...  Loss: 0.1522\n",
      "Epoch: 39/100...  Loss: 0.1382\n",
      "Epoch: 39/100...  Loss: 0.1742\n",
      "Epoch: 39/100...  Loss: 0.1413\n",
      "Epoch: 39/100...  Loss: 0.1469\n",
      "Epoch: 39/100...  Loss: 0.1530\n",
      "Epoch: 39/100...  Loss: 0.1410\n",
      "Epoch: 40/100...  Loss: 0.0618\n",
      "Epoch: 40/100...  Loss: 0.1503\n",
      "Epoch: 40/100...  Loss: 0.1388\n",
      "Epoch: 40/100...  Loss: 0.1554\n",
      "Epoch: 40/100...  Loss: 0.1517\n",
      "Epoch: 40/100...  Loss: 0.1482\n",
      "Epoch: 40/100...  Loss: 0.1202\n",
      "Epoch: 40/100...  Loss: 0.1278\n",
      "Epoch: 40/100...  Loss: 0.1440\n",
      "Epoch: 40/100...  Loss: 0.1376\n",
      "Epoch: 40/100...  Loss: 0.1526\n",
      "Epoch: 40/100...  Loss: 0.1348\n",
      "Epoch: 40/100...  Loss: 0.1483\n",
      "Epoch: 40/100...  Loss: 0.1417\n",
      "Epoch: 40/100...  Loss: 0.1456\n",
      "Epoch: 40/100...  Loss: 0.1476\n",
      "Epoch: 40/100...  Loss: 0.1597\n",
      "Epoch: 40/100...  Loss: 0.1424\n",
      "Epoch: 40/100...  Loss: 0.1483\n",
      "Epoch: 40/100...  Loss: 0.1460\n",
      "Epoch: 40/100...  Loss: 0.1469\n",
      "Epoch: 40/100...  Loss: 0.1545\n",
      "Epoch: 40/100...  Loss: 0.1545\n",
      "Epoch: 40/100...  Loss: 0.1489\n",
      "Epoch: 41/100...  Loss: 0.1376\n",
      "Epoch: 41/100...  Loss: 0.1409\n",
      "Epoch: 41/100...  Loss: 0.1424\n",
      "Epoch: 41/100...  Loss: 0.1414\n",
      "Epoch: 41/100...  Loss: 0.1503\n",
      "Epoch: 41/100...  Loss: 0.1453\n",
      "Epoch: 41/100...  Loss: 0.1386\n",
      "Epoch: 41/100...  Loss: 0.1364\n",
      "Epoch: 41/100...  Loss: 0.1444\n",
      "Epoch: 41/100...  Loss: 0.1337\n",
      "Epoch: 41/100...  Loss: 0.1458\n",
      "Epoch: 41/100...  Loss: 0.1390\n",
      "Epoch: 41/100...  Loss: 0.1446\n",
      "Epoch: 41/100...  Loss: 0.1380\n",
      "Epoch: 41/100...  Loss: 0.1284\n",
      "Epoch: 41/100...  Loss: 0.1815\n",
      "Epoch: 41/100...  Loss: 0.1449\n",
      "Epoch: 41/100...  Loss: 0.1363\n",
      "Epoch: 41/100...  Loss: 0.1392\n",
      "Epoch: 41/100...  Loss: 0.1382\n",
      "Epoch: 41/100...  Loss: 0.1327\n",
      "Epoch: 41/100...  Loss: 0.1642\n",
      "Epoch: 41/100...  Loss: 0.1460\n",
      "Epoch: 42/100...  Loss: 0.0648\n",
      "Epoch: 42/100...  Loss: 0.1352\n",
      "Epoch: 42/100...  Loss: 0.1389\n",
      "Epoch: 42/100...  Loss: 0.1391\n",
      "Epoch: 42/100...  Loss: 0.1609\n",
      "Epoch: 42/100...  Loss: 0.1392\n",
      "Epoch: 42/100...  Loss: 0.1141\n",
      "Epoch: 42/100...  Loss: 0.1506\n",
      "Epoch: 42/100...  Loss: 0.1416\n",
      "Epoch: 42/100...  Loss: 0.1457\n",
      "Epoch: 42/100...  Loss: 0.1404\n",
      "Epoch: 42/100...  Loss: 0.1342\n",
      "Epoch: 42/100...  Loss: 0.1517\n",
      "Epoch: 42/100...  Loss: 0.1443\n",
      "Epoch: 42/100...  Loss: 0.1454\n",
      "Epoch: 42/100...  Loss: 0.1439\n",
      "Epoch: 42/100...  Loss: 0.1378\n",
      "Epoch: 42/100...  Loss: 0.1322\n",
      "Epoch: 42/100...  Loss: 0.1522\n",
      "Epoch: 42/100...  Loss: 0.1429\n",
      "Epoch: 42/100...  Loss: 0.1257\n",
      "Epoch: 42/100...  Loss: 0.1421\n",
      "Epoch: 42/100...  Loss: 0.1446\n",
      "Epoch: 43/100...  Loss: 0.0131\n",
      "Epoch: 43/100...  Loss: 0.1479\n",
      "Epoch: 43/100...  Loss: 0.1238\n",
      "Epoch: 43/100...  Loss: 0.1285\n",
      "Epoch: 43/100...  Loss: 0.1372\n",
      "Epoch: 43/100...  Loss: 0.1385\n",
      "Epoch: 43/100...  Loss: 0.1423\n",
      "Epoch: 43/100...  Loss: 0.1388\n",
      "Epoch: 43/100...  Loss: 0.1258\n",
      "Epoch: 43/100...  Loss: 0.1317\n",
      "Epoch: 43/100...  Loss: 0.1315\n",
      "Epoch: 43/100...  Loss: 0.1436\n",
      "Epoch: 43/100...  Loss: 0.1243\n",
      "Epoch: 43/100...  Loss: 0.1279\n",
      "Epoch: 43/100...  Loss: 0.1388\n",
      "Epoch: 43/100...  Loss: 0.1488\n",
      "Epoch: 43/100...  Loss: 0.1477\n",
      "Epoch: 43/100...  Loss: 0.1322\n",
      "Epoch: 43/100...  Loss: 0.1456\n",
      "Epoch: 43/100...  Loss: 0.1489\n",
      "Epoch: 43/100...  Loss: 0.1447\n",
      "Epoch: 43/100...  Loss: 0.1387\n",
      "Epoch: 43/100...  Loss: 0.1341\n",
      "Epoch: 43/100...  Loss: 0.1435\n",
      "Epoch: 44/100...  Loss: 0.0982\n",
      "Epoch: 44/100...  Loss: 0.1280\n",
      "Epoch: 44/100...  Loss: 0.1415\n",
      "Epoch: 44/100...  Loss: 0.1354\n",
      "Epoch: 44/100...  Loss: 0.1197\n",
      "Epoch: 44/100...  Loss: 0.1335\n",
      "Epoch: 44/100...  Loss: 0.1368\n",
      "Epoch: 44/100...  Loss: 0.1354\n",
      "Epoch: 44/100...  Loss: 0.1451\n",
      "Epoch: 44/100...  Loss: 0.1325\n",
      "Epoch: 44/100...  Loss: 0.1268\n",
      "Epoch: 44/100...  Loss: 0.1239\n",
      "Epoch: 44/100...  Loss: 0.1438\n",
      "Epoch: 44/100...  Loss: 0.1271\n",
      "Epoch: 44/100...  Loss: 0.1466\n",
      "Epoch: 44/100...  Loss: 0.1295\n",
      "Epoch: 44/100...  Loss: 0.1130\n",
      "Epoch: 44/100...  Loss: 0.1321\n",
      "Epoch: 44/100...  Loss: 0.1440\n",
      "Epoch: 44/100...  Loss: 0.1309\n",
      "Epoch: 44/100...  Loss: 0.1375\n",
      "Epoch: 44/100...  Loss: 0.1353\n",
      "Epoch: 44/100...  Loss: 0.1580\n",
      "Epoch: 45/100...  Loss: 0.0258\n",
      "Epoch: 45/100...  Loss: 0.1324\n",
      "Epoch: 45/100...  Loss: 0.1367\n",
      "Epoch: 45/100...  Loss: 0.1261\n",
      "Epoch: 45/100...  Loss: 0.1275\n",
      "Epoch: 45/100...  Loss: 0.1360\n",
      "Epoch: 45/100...  Loss: 0.1317\n",
      "Epoch: 45/100...  Loss: 0.1418\n",
      "Epoch: 45/100...  Loss: 0.1222\n",
      "Epoch: 45/100...  Loss: 0.1242\n",
      "Epoch: 45/100...  Loss: 0.1131\n",
      "Epoch: 45/100...  Loss: 0.1353\n",
      "Epoch: 45/100...  Loss: 0.1463\n",
      "Epoch: 45/100...  Loss: 0.1233\n",
      "Epoch: 45/100...  Loss: 0.1337\n",
      "Epoch: 45/100...  Loss: 0.1559\n",
      "Epoch: 45/100...  Loss: 0.1359\n",
      "Epoch: 45/100...  Loss: 0.1144\n",
      "Epoch: 45/100...  Loss: 0.1364\n",
      "Epoch: 45/100...  Loss: 0.1373\n",
      "Epoch: 45/100...  Loss: 0.1181\n",
      "Epoch: 45/100...  Loss: 0.1404\n",
      "Epoch: 45/100...  Loss: 0.1368\n",
      "Epoch: 45/100...  Loss: 0.1378\n",
      "Epoch: 46/100...  Loss: 0.0953\n",
      "Epoch: 46/100...  Loss: 0.1314\n",
      "Epoch: 46/100...  Loss: 0.1161\n",
      "Epoch: 46/100...  Loss: 0.1160\n",
      "Epoch: 46/100...  Loss: 0.1414\n",
      "Epoch: 46/100...  Loss: 0.1439\n",
      "Epoch: 46/100...  Loss: 0.1301\n",
      "Epoch: 46/100...  Loss: 0.1263\n",
      "Epoch: 46/100...  Loss: 0.1413\n",
      "Epoch: 46/100...  Loss: 0.1282\n",
      "Epoch: 46/100...  Loss: 0.1175\n",
      "Epoch: 46/100...  Loss: 0.1225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100...  Loss: 0.1479\n",
      "Epoch: 46/100...  Loss: 0.1302\n",
      "Epoch: 46/100...  Loss: 0.1680\n",
      "Epoch: 46/100...  Loss: 0.1341\n",
      "Epoch: 46/100...  Loss: 0.1082\n",
      "Epoch: 46/100...  Loss: 0.1223\n",
      "Epoch: 46/100...  Loss: 0.1289\n",
      "Epoch: 46/100...  Loss: 0.1227\n",
      "Epoch: 46/100...  Loss: 0.1269\n",
      "Epoch: 46/100...  Loss: 0.1246\n",
      "Epoch: 46/100...  Loss: 0.1297\n",
      "Epoch: 47/100...  Loss: 0.0386\n",
      "Epoch: 47/100...  Loss: 0.1397\n",
      "Epoch: 47/100...  Loss: 0.1209\n",
      "Epoch: 47/100...  Loss: 0.1214\n",
      "Epoch: 47/100...  Loss: 0.1419\n",
      "Epoch: 47/100...  Loss: 0.1256\n",
      "Epoch: 47/100...  Loss: 0.1209\n",
      "Epoch: 47/100...  Loss: 0.1176\n",
      "Epoch: 47/100...  Loss: 0.1307\n",
      "Epoch: 47/100...  Loss: 0.1139\n",
      "Epoch: 47/100...  Loss: 0.1324\n",
      "Epoch: 47/100...  Loss: 0.1191\n",
      "Epoch: 47/100...  Loss: 0.1518\n",
      "Epoch: 47/100...  Loss: 0.1259\n",
      "Epoch: 47/100...  Loss: 0.1375\n",
      "Epoch: 47/100...  Loss: 0.1198\n",
      "Epoch: 47/100...  Loss: 0.1141\n",
      "Epoch: 47/100...  Loss: 0.1378\n",
      "Epoch: 47/100...  Loss: 0.1197\n",
      "Epoch: 47/100...  Loss: 0.1187\n",
      "Epoch: 47/100...  Loss: 0.1320\n",
      "Epoch: 47/100...  Loss: 0.1296\n",
      "Epoch: 47/100...  Loss: 0.1321\n",
      "Epoch: 47/100...  Loss: 0.1246\n",
      "Epoch: 48/100...  Loss: 0.1155\n",
      "Epoch: 48/100...  Loss: 0.1241\n",
      "Epoch: 48/100...  Loss: 0.1200\n",
      "Epoch: 48/100...  Loss: 0.1362\n",
      "Epoch: 48/100...  Loss: 0.1250\n",
      "Epoch: 48/100...  Loss: 0.1395\n",
      "Epoch: 48/100...  Loss: 0.1173\n",
      "Epoch: 48/100...  Loss: 0.1410\n",
      "Epoch: 48/100...  Loss: 0.1292\n",
      "Epoch: 48/100...  Loss: 0.1099\n",
      "Epoch: 48/100...  Loss: 0.1305\n",
      "Epoch: 48/100...  Loss: 0.1313\n",
      "Epoch: 48/100...  Loss: 0.1440\n",
      "Epoch: 48/100...  Loss: 0.1374\n",
      "Epoch: 48/100...  Loss: 0.1110\n",
      "Epoch: 48/100...  Loss: 0.1268\n",
      "Epoch: 48/100...  Loss: 0.1119\n",
      "Epoch: 48/100...  Loss: 0.1220\n",
      "Epoch: 48/100...  Loss: 0.1196\n",
      "Epoch: 48/100...  Loss: 0.1192\n",
      "Epoch: 48/100...  Loss: 0.1302\n",
      "Epoch: 48/100...  Loss: 0.1058\n",
      "Epoch: 48/100...  Loss: 0.1217\n",
      "Epoch: 49/100...  Loss: 0.0600\n",
      "Epoch: 49/100...  Loss: 0.1153\n",
      "Epoch: 49/100...  Loss: 0.1219\n",
      "Epoch: 49/100...  Loss: 0.1284\n",
      "Epoch: 49/100...  Loss: 0.1213\n",
      "Epoch: 49/100...  Loss: 0.1142\n",
      "Epoch: 49/100...  Loss: 0.1170\n",
      "Epoch: 49/100...  Loss: 0.1367\n",
      "Epoch: 49/100...  Loss: 0.1162\n",
      "Epoch: 49/100...  Loss: 0.1451\n",
      "Epoch: 49/100...  Loss: 0.0974\n",
      "Epoch: 49/100...  Loss: 0.1291\n",
      "Epoch: 49/100...  Loss: 0.1231\n",
      "Epoch: 49/100...  Loss: 0.1137\n",
      "Epoch: 49/100...  Loss: 0.1249\n",
      "Epoch: 49/100...  Loss: 0.1495\n",
      "Epoch: 49/100...  Loss: 0.1225\n",
      "Epoch: 49/100...  Loss: 0.1014\n",
      "Epoch: 49/100...  Loss: 0.1325\n",
      "Epoch: 49/100...  Loss: 0.1146\n",
      "Epoch: 49/100...  Loss: 0.1238\n",
      "Epoch: 49/100...  Loss: 0.1197\n",
      "Epoch: 49/100...  Loss: 0.1143\n",
      "Epoch: 49/100...  Loss: 0.1424\n",
      "Epoch: 50/100...  Loss: 0.1117\n",
      "Epoch: 50/100...  Loss: 0.1168\n",
      "Epoch: 50/100...  Loss: 0.1213\n",
      "Epoch: 50/100...  Loss: 0.1321\n",
      "Epoch: 50/100...  Loss: 0.0995\n",
      "Epoch: 50/100...  Loss: 0.1096\n",
      "Epoch: 50/100...  Loss: 0.1084\n",
      "Epoch: 50/100...  Loss: 0.1109\n",
      "Epoch: 50/100...  Loss: 0.1261\n",
      "Epoch: 50/100...  Loss: 0.1231\n",
      "Epoch: 50/100...  Loss: 0.1243\n",
      "Epoch: 50/100...  Loss: 0.1242\n",
      "Epoch: 50/100...  Loss: 0.1370\n",
      "Epoch: 50/100...  Loss: 0.1227\n",
      "Epoch: 50/100...  Loss: 0.1154\n",
      "Epoch: 50/100...  Loss: 0.1358\n",
      "Epoch: 50/100...  Loss: 0.1262\n",
      "Epoch: 50/100...  Loss: 0.1411\n",
      "Epoch: 50/100...  Loss: 0.1299\n",
      "Epoch: 50/100...  Loss: 0.1161\n",
      "Epoch: 50/100...  Loss: 0.1276\n",
      "Epoch: 50/100...  Loss: 0.1036\n",
      "Epoch: 50/100...  Loss: 0.1108\n",
      "Epoch: 51/100...  Loss: 0.0693\n",
      "Epoch: 51/100...  Loss: 0.1164\n",
      "Epoch: 51/100...  Loss: 0.1215\n",
      "Epoch: 51/100...  Loss: 0.1283\n",
      "Epoch: 51/100...  Loss: 0.1113\n",
      "Epoch: 51/100...  Loss: 0.1108\n",
      "Epoch: 51/100...  Loss: 0.1354\n",
      "Epoch: 51/100...  Loss: 0.1209\n",
      "Epoch: 51/100...  Loss: 0.1192\n",
      "Epoch: 51/100...  Loss: 0.1114\n",
      "Epoch: 51/100...  Loss: 0.1101\n",
      "Epoch: 51/100...  Loss: 0.1213\n",
      "Epoch: 51/100...  Loss: 0.1300\n",
      "Epoch: 51/100...  Loss: 0.1050\n",
      "Epoch: 51/100...  Loss: 0.1055\n",
      "Epoch: 51/100...  Loss: 0.0991\n",
      "Epoch: 51/100...  Loss: 0.1336\n",
      "Epoch: 51/100...  Loss: 0.1205\n",
      "Epoch: 51/100...  Loss: 0.1252\n",
      "Epoch: 51/100...  Loss: 0.1124\n",
      "Epoch: 51/100...  Loss: 0.1148\n",
      "Epoch: 51/100...  Loss: 0.1382\n",
      "Epoch: 51/100...  Loss: 0.1161\n",
      "Epoch: 52/100...  Loss: 0.0036\n",
      "Epoch: 52/100...  Loss: 0.1055\n",
      "Epoch: 52/100...  Loss: 0.1072\n",
      "Epoch: 52/100...  Loss: 0.1126\n",
      "Epoch: 52/100...  Loss: 0.1366\n",
      "Epoch: 52/100...  Loss: 0.1140\n",
      "Epoch: 52/100...  Loss: 0.1268\n",
      "Epoch: 52/100...  Loss: 0.1232\n",
      "Epoch: 52/100...  Loss: 0.1148\n",
      "Epoch: 52/100...  Loss: 0.1129\n",
      "Epoch: 52/100...  Loss: 0.1203\n",
      "Epoch: 52/100...  Loss: 0.1127\n",
      "Epoch: 52/100...  Loss: 0.1093\n",
      "Epoch: 52/100...  Loss: 0.1379\n",
      "Epoch: 52/100...  Loss: 0.1200\n",
      "Epoch: 52/100...  Loss: 0.1103\n",
      "Epoch: 52/100...  Loss: 0.1140\n",
      "Epoch: 52/100...  Loss: 0.0977\n",
      "Epoch: 52/100...  Loss: 0.1288\n",
      "Epoch: 52/100...  Loss: 0.1189\n",
      "Epoch: 52/100...  Loss: 0.1244\n",
      "Epoch: 52/100...  Loss: 0.1270\n",
      "Epoch: 52/100...  Loss: 0.1029\n",
      "Epoch: 52/100...  Loss: 0.1135\n",
      "Epoch: 53/100...  Loss: 0.0726\n",
      "Epoch: 53/100...  Loss: 0.1143\n",
      "Epoch: 53/100...  Loss: 0.1180\n",
      "Epoch: 53/100...  Loss: 0.1131\n",
      "Epoch: 53/100...  Loss: 0.1194\n",
      "Epoch: 53/100...  Loss: 0.1432\n",
      "Epoch: 53/100...  Loss: 0.1256\n",
      "Epoch: 53/100...  Loss: 0.1196\n",
      "Epoch: 53/100...  Loss: 0.1109\n",
      "Epoch: 53/100...  Loss: 0.1127\n",
      "Epoch: 53/100...  Loss: 0.1149\n",
      "Epoch: 53/100...  Loss: 0.1024\n",
      "Epoch: 53/100...  Loss: 0.1020\n",
      "Epoch: 53/100...  Loss: 0.1229\n",
      "Epoch: 53/100...  Loss: 0.1194\n",
      "Epoch: 53/100...  Loss: 0.1065\n",
      "Epoch: 53/100...  Loss: 0.1027\n",
      "Epoch: 53/100...  Loss: 0.1031\n",
      "Epoch: 53/100...  Loss: 0.1116\n",
      "Epoch: 53/100...  Loss: 0.1076\n",
      "Epoch: 53/100...  Loss: 0.1146\n",
      "Epoch: 53/100...  Loss: 0.1261\n",
      "Epoch: 53/100...  Loss: 0.1208\n",
      "Epoch: 54/100...  Loss: 0.0135\n",
      "Epoch: 54/100...  Loss: 0.1105\n",
      "Epoch: 54/100...  Loss: 0.1070\n",
      "Epoch: 54/100...  Loss: 0.1356\n",
      "Epoch: 54/100...  Loss: 0.1033\n",
      "Epoch: 54/100...  Loss: 0.1105\n",
      "Epoch: 54/100...  Loss: 0.1060\n",
      "Epoch: 54/100...  Loss: 0.1172\n",
      "Epoch: 54/100...  Loss: 0.1201\n",
      "Epoch: 54/100...  Loss: 0.1074\n",
      "Epoch: 54/100...  Loss: 0.1142\n",
      "Epoch: 54/100...  Loss: 0.1166\n",
      "Epoch: 54/100...  Loss: 0.1204\n",
      "Epoch: 54/100...  Loss: 0.1071\n",
      "Epoch: 54/100...  Loss: 0.1074\n",
      "Epoch: 54/100...  Loss: 0.1388\n",
      "Epoch: 54/100...  Loss: 0.1158\n",
      "Epoch: 54/100...  Loss: 0.1068\n",
      "Epoch: 54/100...  Loss: 0.1161\n",
      "Epoch: 54/100...  Loss: 0.0969\n",
      "Epoch: 54/100...  Loss: 0.1123\n",
      "Epoch: 54/100...  Loss: 0.1159\n",
      "Epoch: 54/100...  Loss: 0.1037\n",
      "Epoch: 54/100...  Loss: 0.1149\n",
      "Epoch: 55/100...  Loss: 0.0713\n",
      "Epoch: 55/100...  Loss: 0.1137\n",
      "Epoch: 55/100...  Loss: 0.1131\n",
      "Epoch: 55/100...  Loss: 0.1073\n",
      "Epoch: 55/100...  Loss: 0.1233\n",
      "Epoch: 55/100...  Loss: 0.1054\n",
      "Epoch: 55/100...  Loss: 0.1166\n",
      "Epoch: 55/100...  Loss: 0.1267\n",
      "Epoch: 55/100...  Loss: 0.1279\n",
      "Epoch: 55/100...  Loss: 0.1286\n",
      "Epoch: 55/100...  Loss: 0.0968\n",
      "Epoch: 55/100...  Loss: 0.1134\n",
      "Epoch: 55/100...  Loss: 0.1020\n",
      "Epoch: 55/100...  Loss: 0.1045\n",
      "Epoch: 55/100...  Loss: 0.1053\n",
      "Epoch: 55/100...  Loss: 0.1260\n",
      "Epoch: 55/100...  Loss: 0.1080\n",
      "Epoch: 55/100...  Loss: 0.1032\n",
      "Epoch: 55/100...  Loss: 0.1046\n",
      "Epoch: 55/100...  Loss: 0.1153\n",
      "Epoch: 55/100...  Loss: 0.0987\n",
      "Epoch: 55/100...  Loss: 0.1173\n",
      "Epoch: 55/100...  Loss: 0.1040\n",
      "Epoch: 56/100...  Loss: 0.0273\n",
      "Epoch: 56/100...  Loss: 0.1147\n",
      "Epoch: 56/100...  Loss: 0.1155\n",
      "Epoch: 56/100...  Loss: 0.1125\n",
      "Epoch: 56/100...  Loss: 0.1081\n",
      "Epoch: 56/100...  Loss: 0.1016\n",
      "Epoch: 56/100...  Loss: 0.1117\n",
      "Epoch: 56/100...  Loss: 0.1049\n",
      "Epoch: 56/100...  Loss: 0.1188\n",
      "Epoch: 56/100...  Loss: 0.1169\n",
      "Epoch: 56/100...  Loss: 0.1142\n",
      "Epoch: 56/100...  Loss: 0.1131\n",
      "Epoch: 56/100...  Loss: 0.0968\n",
      "Epoch: 56/100...  Loss: 0.1069\n",
      "Epoch: 56/100...  Loss: 0.1256\n",
      "Epoch: 56/100...  Loss: 0.1172\n",
      "Epoch: 56/100...  Loss: 0.1007\n",
      "Epoch: 56/100...  Loss: 0.1218\n",
      "Epoch: 56/100...  Loss: 0.1145\n",
      "Epoch: 56/100...  Loss: 0.0980\n",
      "Epoch: 56/100...  Loss: 0.0968\n",
      "Epoch: 56/100...  Loss: 0.0886\n",
      "Epoch: 56/100...  Loss: 0.1033\n",
      "Epoch: 56/100...  Loss: 0.1208\n",
      "Epoch: 57/100...  Loss: 0.0769\n",
      "Epoch: 57/100...  Loss: 0.1378\n",
      "Epoch: 57/100...  Loss: 0.1066\n",
      "Epoch: 57/100...  Loss: 0.0986\n",
      "Epoch: 57/100...  Loss: 0.1135\n",
      "Epoch: 57/100...  Loss: 0.1153\n",
      "Epoch: 57/100...  Loss: 0.1111\n",
      "Epoch: 57/100...  Loss: 0.1198\n",
      "Epoch: 57/100...  Loss: 0.1042\n",
      "Epoch: 57/100...  Loss: 0.1023\n",
      "Epoch: 57/100...  Loss: 0.1209\n",
      "Epoch: 57/100...  Loss: 0.1151\n",
      "Epoch: 57/100...  Loss: 0.1056\n",
      "Epoch: 57/100...  Loss: 0.0974\n",
      "Epoch: 57/100...  Loss: 0.1128\n",
      "Epoch: 57/100...  Loss: 0.0931\n",
      "Epoch: 57/100...  Loss: 0.1079\n",
      "Epoch: 57/100...  Loss: 0.1061\n",
      "Epoch: 57/100...  Loss: 0.1117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100...  Loss: 0.0932\n",
      "Epoch: 57/100...  Loss: 0.1003\n",
      "Epoch: 57/100...  Loss: 0.1106\n",
      "Epoch: 57/100...  Loss: 0.0942\n",
      "Epoch: 58/100...  Loss: 0.0345\n",
      "Epoch: 58/100...  Loss: 0.1124\n",
      "Epoch: 58/100...  Loss: 0.1234\n",
      "Epoch: 58/100...  Loss: 0.1213\n",
      "Epoch: 58/100...  Loss: 0.1180\n",
      "Epoch: 58/100...  Loss: 0.1120\n",
      "Epoch: 58/100...  Loss: 0.1181\n",
      "Epoch: 58/100...  Loss: 0.0976\n",
      "Epoch: 58/100...  Loss: 0.1001\n",
      "Epoch: 58/100...  Loss: 0.1167\n",
      "Epoch: 58/100...  Loss: 0.1058\n",
      "Epoch: 58/100...  Loss: 0.0868\n",
      "Epoch: 58/100...  Loss: 0.0957\n",
      "Epoch: 58/100...  Loss: 0.0964\n",
      "Epoch: 58/100...  Loss: 0.1002\n",
      "Epoch: 58/100...  Loss: 0.1118\n",
      "Epoch: 58/100...  Loss: 0.1161\n",
      "Epoch: 58/100...  Loss: 0.0956\n",
      "Epoch: 58/100...  Loss: 0.1012\n",
      "Epoch: 58/100...  Loss: 0.0877\n",
      "Epoch: 58/100...  Loss: 0.1163\n",
      "Epoch: 58/100...  Loss: 0.0988\n",
      "Epoch: 58/100...  Loss: 0.0879\n",
      "Epoch: 58/100...  Loss: 0.1138\n",
      "Epoch: 59/100...  Loss: 0.0874\n",
      "Epoch: 59/100...  Loss: 0.1136\n",
      "Epoch: 59/100...  Loss: 0.1067\n",
      "Epoch: 59/100...  Loss: 0.1020\n",
      "Epoch: 59/100...  Loss: 0.1004\n",
      "Epoch: 59/100...  Loss: 0.1159\n",
      "Epoch: 59/100...  Loss: 0.1120\n",
      "Epoch: 59/100...  Loss: 0.0962\n",
      "Epoch: 59/100...  Loss: 0.1023\n",
      "Epoch: 59/100...  Loss: 0.1199\n",
      "Epoch: 59/100...  Loss: 0.0962\n",
      "Epoch: 59/100...  Loss: 0.1081\n",
      "Epoch: 59/100...  Loss: 0.1118\n",
      "Epoch: 59/100...  Loss: 0.1010\n",
      "Epoch: 59/100...  Loss: 0.1096\n",
      "Epoch: 59/100...  Loss: 0.1063\n",
      "Epoch: 59/100...  Loss: 0.1032\n",
      "Epoch: 59/100...  Loss: 0.0900\n",
      "Epoch: 59/100...  Loss: 0.1028\n",
      "Epoch: 59/100...  Loss: 0.1149\n",
      "Epoch: 59/100...  Loss: 0.0955\n",
      "Epoch: 59/100...  Loss: 0.0906\n",
      "Epoch: 59/100...  Loss: 0.1026\n",
      "Epoch: 60/100...  Loss: 0.0508\n",
      "Epoch: 60/100...  Loss: 0.1167\n",
      "Epoch: 60/100...  Loss: 0.0927\n",
      "Epoch: 60/100...  Loss: 0.1110\n",
      "Epoch: 60/100...  Loss: 0.0941\n",
      "Epoch: 60/100...  Loss: 0.1050\n",
      "Epoch: 60/100...  Loss: 0.0936\n",
      "Epoch: 60/100...  Loss: 0.1083\n",
      "Epoch: 60/100...  Loss: 0.1057\n",
      "Epoch: 60/100...  Loss: 0.1027\n",
      "Epoch: 60/100...  Loss: 0.1043\n",
      "Epoch: 60/100...  Loss: 0.0960\n",
      "Epoch: 60/100...  Loss: 0.0968\n",
      "Epoch: 60/100...  Loss: 0.1052\n",
      "Epoch: 60/100...  Loss: 0.1010\n",
      "Epoch: 60/100...  Loss: 0.0850\n",
      "Epoch: 60/100...  Loss: 0.0926\n",
      "Epoch: 60/100...  Loss: 0.1098\n",
      "Epoch: 60/100...  Loss: 0.0890\n",
      "Epoch: 60/100...  Loss: 0.1187\n",
      "Epoch: 60/100...  Loss: 0.1040\n",
      "Epoch: 60/100...  Loss: 0.1129\n",
      "Epoch: 60/100...  Loss: 0.1001\n",
      "Epoch: 60/100...  Loss: 0.1071\n",
      "Epoch: 61/100...  Loss: 0.1104\n",
      "Epoch: 61/100...  Loss: 0.1002\n",
      "Epoch: 61/100...  Loss: 0.1054\n",
      "Epoch: 61/100...  Loss: 0.1094\n",
      "Epoch: 61/100...  Loss: 0.0990\n",
      "Epoch: 61/100...  Loss: 0.1058\n",
      "Epoch: 61/100...  Loss: 0.0894\n",
      "Epoch: 61/100...  Loss: 0.1191\n",
      "Epoch: 61/100...  Loss: 0.0931\n",
      "Epoch: 61/100...  Loss: 0.1017\n",
      "Epoch: 61/100...  Loss: 0.1108\n",
      "Epoch: 61/100...  Loss: 0.0924\n",
      "Epoch: 61/100...  Loss: 0.1050\n",
      "Epoch: 61/100...  Loss: 0.1067\n",
      "Epoch: 61/100...  Loss: 0.1063\n",
      "Epoch: 61/100...  Loss: 0.1018\n",
      "Epoch: 61/100...  Loss: 0.1002\n",
      "Epoch: 61/100...  Loss: 0.0984\n",
      "Epoch: 61/100...  Loss: 0.1015\n",
      "Epoch: 61/100...  Loss: 0.1053\n",
      "Epoch: 61/100...  Loss: 0.0883\n",
      "Epoch: 61/100...  Loss: 0.0901\n",
      "Epoch: 61/100...  Loss: 0.0805\n",
      "Epoch: 62/100...  Loss: 0.0705\n",
      "Epoch: 62/100...  Loss: 0.0909\n",
      "Epoch: 62/100...  Loss: 0.1202\n",
      "Epoch: 62/100...  Loss: 0.1045\n",
      "Epoch: 62/100...  Loss: 0.0858\n",
      "Epoch: 62/100...  Loss: 0.1158\n",
      "Epoch: 62/100...  Loss: 0.1170\n",
      "Epoch: 62/100...  Loss: 0.0728\n",
      "Epoch: 62/100...  Loss: 0.0891\n",
      "Epoch: 62/100...  Loss: 0.0917\n",
      "Epoch: 62/100...  Loss: 0.0923\n",
      "Epoch: 62/100...  Loss: 0.1000\n",
      "Epoch: 62/100...  Loss: 0.0935\n",
      "Epoch: 62/100...  Loss: 0.0985\n",
      "Epoch: 62/100...  Loss: 0.0977\n",
      "Epoch: 62/100...  Loss: 0.1140\n",
      "Epoch: 62/100...  Loss: 0.0882\n",
      "Epoch: 62/100...  Loss: 0.1101\n",
      "Epoch: 62/100...  Loss: 0.0909\n",
      "Epoch: 62/100...  Loss: 0.0895\n",
      "Epoch: 62/100...  Loss: 0.1033\n",
      "Epoch: 62/100...  Loss: 0.1053\n",
      "Epoch: 62/100...  Loss: 0.0963\n",
      "Epoch: 63/100...  Loss: 0.0108\n",
      "Epoch: 63/100...  Loss: 0.1027\n",
      "Epoch: 63/100...  Loss: 0.1008\n",
      "Epoch: 63/100...  Loss: 0.0835\n",
      "Epoch: 63/100...  Loss: 0.1011\n",
      "Epoch: 63/100...  Loss: 0.0952\n",
      "Epoch: 63/100...  Loss: 0.0896\n",
      "Epoch: 63/100...  Loss: 0.0909\n",
      "Epoch: 63/100...  Loss: 0.1145\n",
      "Epoch: 63/100...  Loss: 0.0912\n",
      "Epoch: 63/100...  Loss: 0.0853\n",
      "Epoch: 63/100...  Loss: 0.1005\n",
      "Epoch: 63/100...  Loss: 0.1212\n",
      "Epoch: 63/100...  Loss: 0.0923\n",
      "Epoch: 63/100...  Loss: 0.0980\n",
      "Epoch: 63/100...  Loss: 0.1021\n",
      "Epoch: 63/100...  Loss: 0.1112\n",
      "Epoch: 63/100...  Loss: 0.0864\n",
      "Epoch: 63/100...  Loss: 0.1028\n",
      "Epoch: 63/100...  Loss: 0.0883\n",
      "Epoch: 63/100...  Loss: 0.0964\n",
      "Epoch: 63/100...  Loss: 0.0983\n",
      "Epoch: 63/100...  Loss: 0.1066\n",
      "Epoch: 63/100...  Loss: 0.1027\n",
      "Epoch: 64/100...  Loss: 0.0586\n",
      "Epoch: 64/100...  Loss: 0.0820\n",
      "Epoch: 64/100...  Loss: 0.0987\n",
      "Epoch: 64/100...  Loss: 0.0960\n",
      "Epoch: 64/100...  Loss: 0.0988\n",
      "Epoch: 64/100...  Loss: 0.0891\n",
      "Epoch: 64/100...  Loss: 0.1000\n",
      "Epoch: 64/100...  Loss: 0.1015\n",
      "Epoch: 64/100...  Loss: 0.1037\n",
      "Epoch: 64/100...  Loss: 0.0896\n",
      "Epoch: 64/100...  Loss: 0.0977\n",
      "Epoch: 64/100...  Loss: 0.0847\n",
      "Epoch: 64/100...  Loss: 0.0917\n",
      "Epoch: 64/100...  Loss: 0.0895\n",
      "Epoch: 64/100...  Loss: 0.1189\n",
      "Epoch: 64/100...  Loss: 0.0992\n",
      "Epoch: 64/100...  Loss: 0.0926\n",
      "Epoch: 64/100...  Loss: 0.0932\n",
      "Epoch: 64/100...  Loss: 0.0850\n",
      "Epoch: 64/100...  Loss: 0.1030\n",
      "Epoch: 64/100...  Loss: 0.0879\n",
      "Epoch: 64/100...  Loss: 0.1095\n",
      "Epoch: 64/100...  Loss: 0.1079\n",
      "Epoch: 65/100...  Loss: 0.0189\n",
      "Epoch: 65/100...  Loss: 0.0886\n",
      "Epoch: 65/100...  Loss: 0.0906\n",
      "Epoch: 65/100...  Loss: 0.0945\n",
      "Epoch: 65/100...  Loss: 0.0970\n",
      "Epoch: 65/100...  Loss: 0.0891\n",
      "Epoch: 65/100...  Loss: 0.0989\n",
      "Epoch: 65/100...  Loss: 0.0894\n",
      "Epoch: 65/100...  Loss: 0.1068\n",
      "Epoch: 65/100...  Loss: 0.0891\n",
      "Epoch: 65/100...  Loss: 0.0945\n",
      "Epoch: 65/100...  Loss: 0.0943\n",
      "Epoch: 65/100...  Loss: 0.1076\n",
      "Epoch: 65/100...  Loss: 0.0944\n",
      "Epoch: 65/100...  Loss: 0.1001\n",
      "Epoch: 65/100...  Loss: 0.0992\n",
      "Epoch: 65/100...  Loss: 0.0882\n",
      "Epoch: 65/100...  Loss: 0.1010\n",
      "Epoch: 65/100...  Loss: 0.0867\n",
      "Epoch: 65/100...  Loss: 0.0909\n",
      "Epoch: 65/100...  Loss: 0.1013\n",
      "Epoch: 65/100...  Loss: 0.0808\n",
      "Epoch: 65/100...  Loss: 0.1123\n",
      "Epoch: 65/100...  Loss: 0.0909\n",
      "Epoch: 66/100...  Loss: 0.0611\n",
      "Epoch: 66/100...  Loss: 0.0926\n",
      "Epoch: 66/100...  Loss: 0.1048\n",
      "Epoch: 66/100...  Loss: 0.0894\n",
      "Epoch: 66/100...  Loss: 0.1000\n",
      "Epoch: 66/100...  Loss: 0.0955\n",
      "Epoch: 66/100...  Loss: 0.0876\n",
      "Epoch: 66/100...  Loss: 0.0852\n",
      "Epoch: 66/100...  Loss: 0.1093\n",
      "Epoch: 66/100...  Loss: 0.1026\n",
      "Epoch: 66/100...  Loss: 0.0988\n",
      "Epoch: 66/100...  Loss: 0.0938\n",
      "Epoch: 66/100...  Loss: 0.0943\n",
      "Epoch: 66/100...  Loss: 0.0866\n",
      "Epoch: 66/100...  Loss: 0.0947\n",
      "Epoch: 66/100...  Loss: 0.0833\n",
      "Epoch: 66/100...  Loss: 0.0836\n",
      "Epoch: 66/100...  Loss: 0.0919\n",
      "Epoch: 66/100...  Loss: 0.0845\n",
      "Epoch: 66/100...  Loss: 0.0853\n",
      "Epoch: 66/100...  Loss: 0.0945\n",
      "Epoch: 66/100...  Loss: 0.1057\n",
      "Epoch: 66/100...  Loss: 0.0902\n",
      "Epoch: 67/100...  Loss: 0.0197\n",
      "Epoch: 67/100...  Loss: 0.0902\n",
      "Epoch: 67/100...  Loss: 0.0826\n",
      "Epoch: 67/100...  Loss: 0.1063\n",
      "Epoch: 67/100...  Loss: 0.0850\n",
      "Epoch: 67/100...  Loss: 0.0910\n",
      "Epoch: 67/100...  Loss: 0.1156\n",
      "Epoch: 67/100...  Loss: 0.0794\n",
      "Epoch: 67/100...  Loss: 0.0939\n",
      "Epoch: 67/100...  Loss: 0.1004\n",
      "Epoch: 67/100...  Loss: 0.1001\n",
      "Epoch: 67/100...  Loss: 0.0778\n",
      "Epoch: 67/100...  Loss: 0.0984\n",
      "Epoch: 67/100...  Loss: 0.0801\n",
      "Epoch: 67/100...  Loss: 0.0960\n",
      "Epoch: 67/100...  Loss: 0.0876\n",
      "Epoch: 67/100...  Loss: 0.0995\n",
      "Epoch: 67/100...  Loss: 0.0938\n",
      "Epoch: 67/100...  Loss: 0.0916\n",
      "Epoch: 67/100...  Loss: 0.0883\n",
      "Epoch: 67/100...  Loss: 0.0863\n",
      "Epoch: 67/100...  Loss: 0.0955\n",
      "Epoch: 67/100...  Loss: 0.0896\n",
      "Epoch: 67/100...  Loss: 0.0973\n",
      "Epoch: 68/100...  Loss: 0.0719\n",
      "Epoch: 68/100...  Loss: 0.0922\n",
      "Epoch: 68/100...  Loss: 0.1021\n",
      "Epoch: 68/100...  Loss: 0.0898\n",
      "Epoch: 68/100...  Loss: 0.0697\n",
      "Epoch: 68/100...  Loss: 0.0825\n",
      "Epoch: 68/100...  Loss: 0.0856\n",
      "Epoch: 68/100...  Loss: 0.0808\n",
      "Epoch: 68/100...  Loss: 0.0866\n",
      "Epoch: 68/100...  Loss: 0.0896\n",
      "Epoch: 68/100...  Loss: 0.1004\n",
      "Epoch: 68/100...  Loss: 0.0954\n",
      "Epoch: 68/100...  Loss: 0.0995\n",
      "Epoch: 68/100...  Loss: 0.0991\n",
      "Epoch: 68/100...  Loss: 0.0949\n",
      "Epoch: 68/100...  Loss: 0.0867\n",
      "Epoch: 68/100...  Loss: 0.0929\n",
      "Epoch: 68/100...  Loss: 0.1005\n",
      "Epoch: 68/100...  Loss: 0.0897\n",
      "Epoch: 68/100...  Loss: 0.0815\n",
      "Epoch: 68/100...  Loss: 0.0919\n",
      "Epoch: 68/100...  Loss: 0.0899\n",
      "Epoch: 68/100...  Loss: 0.0931\n",
      "Epoch: 69/100...  Loss: 0.0321\n",
      "Epoch: 69/100...  Loss: 0.0951\n",
      "Epoch: 69/100...  Loss: 0.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100...  Loss: 0.0814\n",
      "Epoch: 69/100...  Loss: 0.0812\n",
      "Epoch: 69/100...  Loss: 0.1045\n",
      "Epoch: 69/100...  Loss: 0.0946\n",
      "Epoch: 69/100...  Loss: 0.1039\n",
      "Epoch: 69/100...  Loss: 0.0782\n",
      "Epoch: 69/100...  Loss: 0.0804\n",
      "Epoch: 69/100...  Loss: 0.0851\n",
      "Epoch: 69/100...  Loss: 0.0931\n",
      "Epoch: 69/100...  Loss: 0.0854\n",
      "Epoch: 69/100...  Loss: 0.0835\n",
      "Epoch: 69/100...  Loss: 0.0781\n",
      "Epoch: 69/100...  Loss: 0.1027\n",
      "Epoch: 69/100...  Loss: 0.0979\n",
      "Epoch: 69/100...  Loss: 0.0852\n",
      "Epoch: 69/100...  Loss: 0.0852\n",
      "Epoch: 69/100...  Loss: 0.1049\n",
      "Epoch: 69/100...  Loss: 0.0977\n",
      "Epoch: 69/100...  Loss: 0.0857\n",
      "Epoch: 69/100...  Loss: 0.0903\n",
      "Epoch: 69/100...  Loss: 0.0844\n",
      "Epoch: 70/100...  Loss: 0.0891\n",
      "Epoch: 70/100...  Loss: 0.0985\n",
      "Epoch: 70/100...  Loss: 0.0949\n",
      "Epoch: 70/100...  Loss: 0.0860\n",
      "Epoch: 70/100...  Loss: 0.0722\n",
      "Epoch: 70/100...  Loss: 0.0891\n",
      "Epoch: 70/100...  Loss: 0.0850\n",
      "Epoch: 70/100...  Loss: 0.0867\n",
      "Epoch: 70/100...  Loss: 0.0937\n",
      "Epoch: 70/100...  Loss: 0.0799\n",
      "Epoch: 70/100...  Loss: 0.0836\n",
      "Epoch: 70/100...  Loss: 0.0998\n",
      "Epoch: 70/100...  Loss: 0.0881\n",
      "Epoch: 70/100...  Loss: 0.0867\n",
      "Epoch: 70/100...  Loss: 0.0893\n",
      "Epoch: 70/100...  Loss: 0.0841\n",
      "Epoch: 70/100...  Loss: 0.0823\n",
      "Epoch: 70/100...  Loss: 0.0934\n",
      "Epoch: 70/100...  Loss: 0.0753\n",
      "Epoch: 70/100...  Loss: 0.0883\n",
      "Epoch: 70/100...  Loss: 0.0772\n",
      "Epoch: 70/100...  Loss: 0.0983\n",
      "Epoch: 70/100...  Loss: 0.0982\n",
      "Epoch: 71/100...  Loss: 0.0373\n",
      "Epoch: 71/100...  Loss: 0.0908\n",
      "Epoch: 71/100...  Loss: 0.0930\n",
      "Epoch: 71/100...  Loss: 0.0935\n",
      "Epoch: 71/100...  Loss: 0.0933\n",
      "Epoch: 71/100...  Loss: 0.0981\n",
      "Epoch: 71/100...  Loss: 0.0871\n",
      "Epoch: 71/100...  Loss: 0.0953\n",
      "Epoch: 71/100...  Loss: 0.0924\n",
      "Epoch: 71/100...  Loss: 0.0924\n",
      "Epoch: 71/100...  Loss: 0.0877\n",
      "Epoch: 71/100...  Loss: 0.0868\n",
      "Epoch: 71/100...  Loss: 0.0906\n",
      "Epoch: 71/100...  Loss: 0.0847\n",
      "Epoch: 71/100...  Loss: 0.0783\n",
      "Epoch: 71/100...  Loss: 0.0838\n",
      "Epoch: 71/100...  Loss: 0.0783\n",
      "Epoch: 71/100...  Loss: 0.0812\n",
      "Epoch: 71/100...  Loss: 0.0746\n",
      "Epoch: 71/100...  Loss: 0.0876\n",
      "Epoch: 71/100...  Loss: 0.0769\n",
      "Epoch: 71/100...  Loss: 0.0852\n",
      "Epoch: 71/100...  Loss: 0.0868\n",
      "Epoch: 72/100...  Loss: 0.0052\n",
      "Epoch: 72/100...  Loss: 0.0836\n",
      "Epoch: 72/100...  Loss: 0.0701\n",
      "Epoch: 72/100...  Loss: 0.0814\n",
      "Epoch: 72/100...  Loss: 0.0957\n",
      "Epoch: 72/100...  Loss: 0.0939\n",
      "Epoch: 72/100...  Loss: 0.0798\n",
      "Epoch: 72/100...  Loss: 0.0924\n",
      "Epoch: 72/100...  Loss: 0.0904\n",
      "Epoch: 72/100...  Loss: 0.0754\n",
      "Epoch: 72/100...  Loss: 0.0830\n",
      "Epoch: 72/100...  Loss: 0.1009\n",
      "Epoch: 72/100...  Loss: 0.0925\n",
      "Epoch: 72/100...  Loss: 0.0798\n",
      "Epoch: 72/100...  Loss: 0.0711\n",
      "Epoch: 72/100...  Loss: 0.0921\n",
      "Epoch: 72/100...  Loss: 0.0916\n",
      "Epoch: 72/100...  Loss: 0.0876\n",
      "Epoch: 72/100...  Loss: 0.0849\n",
      "Epoch: 72/100...  Loss: 0.0845\n",
      "Epoch: 72/100...  Loss: 0.0822\n",
      "Epoch: 72/100...  Loss: 0.0964\n",
      "Epoch: 72/100...  Loss: 0.0818\n",
      "Epoch: 72/100...  Loss: 0.0846\n",
      "Epoch: 73/100...  Loss: 0.0418\n",
      "Epoch: 73/100...  Loss: 0.0674\n",
      "Epoch: 73/100...  Loss: 0.0890\n",
      "Epoch: 73/100...  Loss: 0.0719\n",
      "Epoch: 73/100...  Loss: 0.0749\n",
      "Epoch: 73/100...  Loss: 0.0892\n",
      "Epoch: 73/100...  Loss: 0.0818\n",
      "Epoch: 73/100...  Loss: 0.0857\n",
      "Epoch: 73/100...  Loss: 0.0883\n",
      "Epoch: 73/100...  Loss: 0.0773\n",
      "Epoch: 73/100...  Loss: 0.0903\n",
      "Epoch: 73/100...  Loss: 0.0803\n",
      "Epoch: 73/100...  Loss: 0.0821\n",
      "Epoch: 73/100...  Loss: 0.0911\n",
      "Epoch: 73/100...  Loss: 0.0833\n",
      "Epoch: 73/100...  Loss: 0.0918\n",
      "Epoch: 73/100...  Loss: 0.0741\n",
      "Epoch: 73/100...  Loss: 0.0979\n",
      "Epoch: 73/100...  Loss: 0.0811\n",
      "Epoch: 73/100...  Loss: 0.0826\n",
      "Epoch: 73/100...  Loss: 0.0842\n",
      "Epoch: 73/100...  Loss: 0.0894\n",
      "Epoch: 73/100...  Loss: 0.0971\n",
      "Epoch: 74/100...  Loss: 0.0154\n",
      "Epoch: 74/100...  Loss: 0.0784\n",
      "Epoch: 74/100...  Loss: 0.1007\n",
      "Epoch: 74/100...  Loss: 0.0897\n",
      "Epoch: 74/100...  Loss: 0.0814\n",
      "Epoch: 74/100...  Loss: 0.0787\n",
      "Epoch: 74/100...  Loss: 0.0908\n",
      "Epoch: 74/100...  Loss: 0.0738\n",
      "Epoch: 74/100...  Loss: 0.0797\n",
      "Epoch: 74/100...  Loss: 0.0952\n",
      "Epoch: 74/100...  Loss: 0.0967\n",
      "Epoch: 74/100...  Loss: 0.0689\n",
      "Epoch: 74/100...  Loss: 0.0683\n",
      "Epoch: 74/100...  Loss: 0.0842\n",
      "Epoch: 74/100...  Loss: 0.0764\n",
      "Epoch: 74/100...  Loss: 0.0897\n",
      "Epoch: 74/100...  Loss: 0.0880\n",
      "Epoch: 74/100...  Loss: 0.0792\n",
      "Epoch: 74/100...  Loss: 0.0902\n",
      "Epoch: 74/100...  Loss: 0.0905\n",
      "Epoch: 74/100...  Loss: 0.0744\n",
      "Epoch: 74/100...  Loss: 0.0720\n",
      "Epoch: 74/100...  Loss: 0.0954\n",
      "Epoch: 74/100...  Loss: 0.0758\n",
      "Epoch: 75/100...  Loss: 0.0602\n",
      "Epoch: 75/100...  Loss: 0.0854\n",
      "Epoch: 75/100...  Loss: 0.0839\n",
      "Epoch: 75/100...  Loss: 0.0801\n",
      "Epoch: 75/100...  Loss: 0.0732\n",
      "Epoch: 75/100...  Loss: 0.0937\n",
      "Epoch: 75/100...  Loss: 0.1008\n",
      "Epoch: 75/100...  Loss: 0.0817\n",
      "Epoch: 75/100...  Loss: 0.0827\n",
      "Epoch: 75/100...  Loss: 0.0779\n",
      "Epoch: 75/100...  Loss: 0.0812\n",
      "Epoch: 75/100...  Loss: 0.0735\n",
      "Epoch: 75/100...  Loss: 0.0772\n",
      "Epoch: 75/100...  Loss: 0.0902\n",
      "Epoch: 75/100...  Loss: 0.0798\n",
      "Epoch: 75/100...  Loss: 0.0774\n",
      "Epoch: 75/100...  Loss: 0.0789\n",
      "Epoch: 75/100...  Loss: 0.0903\n",
      "Epoch: 75/100...  Loss: 0.0809\n",
      "Epoch: 75/100...  Loss: 0.0908\n",
      "Epoch: 75/100...  Loss: 0.0926\n",
      "Epoch: 75/100...  Loss: 0.0639\n",
      "Epoch: 75/100...  Loss: 0.0811\n",
      "Epoch: 76/100...  Loss: 0.0225\n",
      "Epoch: 76/100...  Loss: 0.0725\n",
      "Epoch: 76/100...  Loss: 0.0780\n",
      "Epoch: 76/100...  Loss: 0.0740\n",
      "Epoch: 76/100...  Loss: 0.0875\n",
      "Epoch: 76/100...  Loss: 0.0708\n",
      "Epoch: 76/100...  Loss: 0.0897\n",
      "Epoch: 76/100...  Loss: 0.0709\n",
      "Epoch: 76/100...  Loss: 0.0757\n",
      "Epoch: 76/100...  Loss: 0.0797\n",
      "Epoch: 76/100...  Loss: 0.0830\n",
      "Epoch: 76/100...  Loss: 0.0935\n",
      "Epoch: 76/100...  Loss: 0.0990\n",
      "Epoch: 76/100...  Loss: 0.0682\n",
      "Epoch: 76/100...  Loss: 0.0789\n",
      "Epoch: 76/100...  Loss: 0.0828\n",
      "Epoch: 76/100...  Loss: 0.0829\n",
      "Epoch: 76/100...  Loss: 0.0894\n",
      "Epoch: 76/100...  Loss: 0.0845\n",
      "Epoch: 76/100...  Loss: 0.0703\n",
      "Epoch: 76/100...  Loss: 0.0946\n",
      "Epoch: 76/100...  Loss: 0.0761\n",
      "Epoch: 76/100...  Loss: 0.0762\n",
      "Epoch: 76/100...  Loss: 0.0938\n",
      "Epoch: 77/100...  Loss: 0.0673\n",
      "Epoch: 77/100...  Loss: 0.0797\n",
      "Epoch: 77/100...  Loss: 0.0866\n",
      "Epoch: 77/100...  Loss: 0.0686\n",
      "Epoch: 77/100...  Loss: 0.0763\n",
      "Epoch: 77/100...  Loss: 0.0789\n",
      "Epoch: 77/100...  Loss: 0.0759\n",
      "Epoch: 77/100...  Loss: 0.0721\n",
      "Epoch: 77/100...  Loss: 0.0747\n",
      "Epoch: 77/100...  Loss: 0.0812\n",
      "Epoch: 77/100...  Loss: 0.0702\n",
      "Epoch: 77/100...  Loss: 0.0811\n",
      "Epoch: 77/100...  Loss: 0.0784\n",
      "Epoch: 77/100...  Loss: 0.0863\n",
      "Epoch: 77/100...  Loss: 0.0733\n",
      "Epoch: 77/100...  Loss: 0.0812\n",
      "Epoch: 77/100...  Loss: 0.0828\n",
      "Epoch: 77/100...  Loss: 0.0880\n",
      "Epoch: 77/100...  Loss: 0.0885\n",
      "Epoch: 77/100...  Loss: 0.0874\n",
      "Epoch: 77/100...  Loss: 0.0708\n",
      "Epoch: 77/100...  Loss: 0.0833\n",
      "Epoch: 77/100...  Loss: 0.0858\n",
      "Epoch: 78/100...  Loss: 0.0388\n",
      "Epoch: 78/100...  Loss: 0.0826\n",
      "Epoch: 78/100...  Loss: 0.0750\n",
      "Epoch: 78/100...  Loss: 0.0813\n",
      "Epoch: 78/100...  Loss: 0.0762\n",
      "Epoch: 78/100...  Loss: 0.0767\n",
      "Epoch: 78/100...  Loss: 0.0795\n",
      "Epoch: 78/100...  Loss: 0.0732\n",
      "Epoch: 78/100...  Loss: 0.0789\n",
      "Epoch: 78/100...  Loss: 0.0806\n",
      "Epoch: 78/100...  Loss: 0.0835\n",
      "Epoch: 78/100...  Loss: 0.1022\n",
      "Epoch: 78/100...  Loss: 0.0647\n",
      "Epoch: 78/100...  Loss: 0.0902\n",
      "Epoch: 78/100...  Loss: 0.0762\n",
      "Epoch: 78/100...  Loss: 0.0619\n",
      "Epoch: 78/100...  Loss: 0.0847\n",
      "Epoch: 78/100...  Loss: 0.0735\n",
      "Epoch: 78/100...  Loss: 0.0841\n",
      "Epoch: 78/100...  Loss: 0.0685\n",
      "Epoch: 78/100...  Loss: 0.0882\n",
      "Epoch: 78/100...  Loss: 0.0622\n",
      "Epoch: 78/100...  Loss: 0.0745\n",
      "Epoch: 78/100...  Loss: 0.0890\n",
      "Epoch: 79/100...  Loss: 0.0806\n",
      "Epoch: 79/100...  Loss: 0.0702\n",
      "Epoch: 79/100...  Loss: 0.0795\n",
      "Epoch: 79/100...  Loss: 0.0802\n",
      "Epoch: 79/100...  Loss: 0.0825\n",
      "Epoch: 79/100...  Loss: 0.0836\n",
      "Epoch: 79/100...  Loss: 0.0689\n",
      "Epoch: 79/100...  Loss: 0.0660\n",
      "Epoch: 79/100...  Loss: 0.0827\n",
      "Epoch: 79/100...  Loss: 0.0953\n",
      "Epoch: 79/100...  Loss: 0.0943\n",
      "Epoch: 79/100...  Loss: 0.0861\n",
      "Epoch: 79/100...  Loss: 0.0737\n",
      "Epoch: 79/100...  Loss: 0.0751\n",
      "Epoch: 79/100...  Loss: 0.0742\n",
      "Epoch: 79/100...  Loss: 0.0680\n",
      "Epoch: 79/100...  Loss: 0.0690\n",
      "Epoch: 79/100...  Loss: 0.0770\n",
      "Epoch: 79/100...  Loss: 0.0779\n",
      "Epoch: 79/100...  Loss: 0.0688\n",
      "Epoch: 79/100...  Loss: 0.0826\n",
      "Epoch: 79/100...  Loss: 0.0911\n",
      "Epoch: 79/100...  Loss: 0.0592\n",
      "Epoch: 80/100...  Loss: 0.0299\n",
      "Epoch: 80/100...  Loss: 0.0764\n",
      "Epoch: 80/100...  Loss: 0.0674\n",
      "Epoch: 80/100...  Loss: 0.0806\n",
      "Epoch: 80/100...  Loss: 0.0742\n",
      "Epoch: 80/100...  Loss: 0.0857\n",
      "Epoch: 80/100...  Loss: 0.0769\n",
      "Epoch: 80/100...  Loss: 0.0808\n",
      "Epoch: 80/100...  Loss: 0.0747\n",
      "Epoch: 80/100...  Loss: 0.0876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100...  Loss: 0.0808\n",
      "Epoch: 80/100...  Loss: 0.0693\n",
      "Epoch: 80/100...  Loss: 0.0758\n",
      "Epoch: 80/100...  Loss: 0.0811\n",
      "Epoch: 80/100...  Loss: 0.0691\n",
      "Epoch: 80/100...  Loss: 0.0821\n",
      "Epoch: 80/100...  Loss: 0.0685\n",
      "Epoch: 80/100...  Loss: 0.0787\n",
      "Epoch: 80/100...  Loss: 0.0747\n",
      "Epoch: 80/100...  Loss: 0.0749\n",
      "Epoch: 80/100...  Loss: 0.0634\n",
      "Epoch: 80/100...  Loss: 0.0913\n",
      "Epoch: 80/100...  Loss: 0.0866\n",
      "Epoch: 80/100...  Loss: 0.0679\n",
      "Epoch: 81/100...  Loss: 0.0777\n",
      "Epoch: 81/100...  Loss: 0.0730\n",
      "Epoch: 81/100...  Loss: 0.0699\n",
      "Epoch: 81/100...  Loss: 0.0681\n",
      "Epoch: 81/100...  Loss: 0.0727\n",
      "Epoch: 81/100...  Loss: 0.0777\n",
      "Epoch: 81/100...  Loss: 0.0680\n",
      "Epoch: 81/100...  Loss: 0.0834\n",
      "Epoch: 81/100...  Loss: 0.0842\n",
      "Epoch: 81/100...  Loss: 0.0731\n",
      "Epoch: 81/100...  Loss: 0.0693\n",
      "Epoch: 81/100...  Loss: 0.0769\n",
      "Epoch: 81/100...  Loss: 0.0844\n",
      "Epoch: 81/100...  Loss: 0.0755\n",
      "Epoch: 81/100...  Loss: 0.0744\n",
      "Epoch: 81/100...  Loss: 0.0664\n",
      "Epoch: 81/100...  Loss: 0.0758\n",
      "Epoch: 81/100...  Loss: 0.0696\n",
      "Epoch: 81/100...  Loss: 0.0984\n",
      "Epoch: 81/100...  Loss: 0.0837\n",
      "Epoch: 81/100...  Loss: 0.0700\n",
      "Epoch: 81/100...  Loss: 0.0823\n",
      "Epoch: 81/100...  Loss: 0.0674\n",
      "Epoch: 82/100...  Loss: 0.0452\n",
      "Epoch: 82/100...  Loss: 0.0729\n",
      "Epoch: 82/100...  Loss: 0.0780\n",
      "Epoch: 82/100...  Loss: 0.0889\n",
      "Epoch: 82/100...  Loss: 0.0723\n",
      "Epoch: 82/100...  Loss: 0.0728\n",
      "Epoch: 82/100...  Loss: 0.0758\n",
      "Epoch: 82/100...  Loss: 0.0772\n",
      "Epoch: 82/100...  Loss: 0.0701\n",
      "Epoch: 82/100...  Loss: 0.0785\n",
      "Epoch: 82/100...  Loss: 0.0865\n",
      "Epoch: 82/100...  Loss: 0.0830\n",
      "Epoch: 82/100...  Loss: 0.0680\n",
      "Epoch: 82/100...  Loss: 0.0724\n",
      "Epoch: 82/100...  Loss: 0.0852\n",
      "Epoch: 82/100...  Loss: 0.0801\n",
      "Epoch: 82/100...  Loss: 0.0769\n",
      "Epoch: 82/100...  Loss: 0.0607\n",
      "Epoch: 82/100...  Loss: 0.0747\n",
      "Epoch: 82/100...  Loss: 0.0718\n",
      "Epoch: 82/100...  Loss: 0.0685\n",
      "Epoch: 82/100...  Loss: 0.0648\n",
      "Epoch: 82/100...  Loss: 0.0652\n",
      "Epoch: 83/100...  Loss: 0.0070\n",
      "Epoch: 83/100...  Loss: 0.0773\n",
      "Epoch: 83/100...  Loss: 0.0707\n",
      "Epoch: 83/100...  Loss: 0.0690\n",
      "Epoch: 83/100...  Loss: 0.0659\n",
      "Epoch: 83/100...  Loss: 0.0622\n",
      "Epoch: 83/100...  Loss: 0.0698\n",
      "Epoch: 83/100...  Loss: 0.0748\n",
      "Epoch: 83/100...  Loss: 0.0809\n",
      "Epoch: 83/100...  Loss: 0.0636\n",
      "Epoch: 83/100...  Loss: 0.0728\n",
      "Epoch: 83/100...  Loss: 0.0761\n",
      "Epoch: 83/100...  Loss: 0.0745\n",
      "Epoch: 83/100...  Loss: 0.0679\n",
      "Epoch: 83/100...  Loss: 0.0838\n",
      "Epoch: 83/100...  Loss: 0.0791\n",
      "Epoch: 83/100...  Loss: 0.0810\n",
      "Epoch: 83/100...  Loss: 0.0717\n",
      "Epoch: 83/100...  Loss: 0.0798\n",
      "Epoch: 83/100...  Loss: 0.0690\n",
      "Epoch: 83/100...  Loss: 0.0731\n",
      "Epoch: 83/100...  Loss: 0.0770\n",
      "Epoch: 83/100...  Loss: 0.0709\n",
      "Epoch: 83/100...  Loss: 0.0811\n",
      "Epoch: 84/100...  Loss: 0.0461\n",
      "Epoch: 84/100...  Loss: 0.0860\n",
      "Epoch: 84/100...  Loss: 0.0730\n",
      "Epoch: 84/100...  Loss: 0.0710\n",
      "Epoch: 84/100...  Loss: 0.0623\n",
      "Epoch: 84/100...  Loss: 0.0692\n",
      "Epoch: 84/100...  Loss: 0.0552\n",
      "Epoch: 84/100...  Loss: 0.0747\n",
      "Epoch: 84/100...  Loss: 0.0737\n",
      "Epoch: 84/100...  Loss: 0.0748\n",
      "Epoch: 84/100...  Loss: 0.0873\n",
      "Epoch: 84/100...  Loss: 0.0772\n",
      "Epoch: 84/100...  Loss: 0.0757\n",
      "Epoch: 84/100...  Loss: 0.0810\n",
      "Epoch: 84/100...  Loss: 0.0690\n",
      "Epoch: 84/100...  Loss: 0.0658\n",
      "Epoch: 84/100...  Loss: 0.0861\n",
      "Epoch: 84/100...  Loss: 0.0753\n",
      "Epoch: 84/100...  Loss: 0.0674\n",
      "Epoch: 84/100...  Loss: 0.0596\n",
      "Epoch: 84/100...  Loss: 0.0794\n",
      "Epoch: 84/100...  Loss: 0.0733\n",
      "Epoch: 84/100...  Loss: 0.0732\n",
      "Epoch: 85/100...  Loss: 0.0152\n",
      "Epoch: 85/100...  Loss: 0.0679\n",
      "Epoch: 85/100...  Loss: 0.0637\n",
      "Epoch: 85/100...  Loss: 0.0642\n",
      "Epoch: 85/100...  Loss: 0.0747\n",
      "Epoch: 85/100...  Loss: 0.0765\n",
      "Epoch: 85/100...  Loss: 0.0761\n",
      "Epoch: 85/100...  Loss: 0.0689\n",
      "Epoch: 85/100...  Loss: 0.0821\n",
      "Epoch: 85/100...  Loss: 0.0649\n",
      "Epoch: 85/100...  Loss: 0.0680\n",
      "Epoch: 85/100...  Loss: 0.0600\n",
      "Epoch: 85/100...  Loss: 0.0784\n",
      "Epoch: 85/100...  Loss: 0.0861\n",
      "Epoch: 85/100...  Loss: 0.0598\n",
      "Epoch: 85/100...  Loss: 0.0705\n",
      "Epoch: 85/100...  Loss: 0.0808\n",
      "Epoch: 85/100...  Loss: 0.0700\n",
      "Epoch: 85/100...  Loss: 0.0817\n",
      "Epoch: 85/100...  Loss: 0.0839\n",
      "Epoch: 85/100...  Loss: 0.0583\n",
      "Epoch: 85/100...  Loss: 0.0731\n",
      "Epoch: 85/100...  Loss: 0.0780\n",
      "Epoch: 85/100...  Loss: 0.0647\n",
      "Epoch: 86/100...  Loss: 0.0472\n",
      "Epoch: 86/100...  Loss: 0.0700\n",
      "Epoch: 86/100...  Loss: 0.0650\n",
      "Epoch: 86/100...  Loss: 0.0755\n",
      "Epoch: 86/100...  Loss: 0.0671\n",
      "Epoch: 86/100...  Loss: 0.0650\n",
      "Epoch: 86/100...  Loss: 0.0707\n",
      "Epoch: 86/100...  Loss: 0.0688\n",
      "Epoch: 86/100...  Loss: 0.0808\n",
      "Epoch: 86/100...  Loss: 0.0701\n",
      "Epoch: 86/100...  Loss: 0.0681\n",
      "Epoch: 86/100...  Loss: 0.0648\n",
      "Epoch: 86/100...  Loss: 0.0672\n",
      "Epoch: 86/100...  Loss: 0.0731\n",
      "Epoch: 86/100...  Loss: 0.0719\n",
      "Epoch: 86/100...  Loss: 0.0682\n",
      "Epoch: 86/100...  Loss: 0.0845\n",
      "Epoch: 86/100...  Loss: 0.0667\n",
      "Epoch: 86/100...  Loss: 0.0754\n",
      "Epoch: 86/100...  Loss: 0.0633\n",
      "Epoch: 86/100...  Loss: 0.0671\n",
      "Epoch: 86/100...  Loss: 0.0797\n",
      "Epoch: 86/100...  Loss: 0.0807\n",
      "Epoch: 87/100...  Loss: 0.0198\n",
      "Epoch: 87/100...  Loss: 0.0783\n",
      "Epoch: 87/100...  Loss: 0.0656\n",
      "Epoch: 87/100...  Loss: 0.0718\n",
      "Epoch: 87/100...  Loss: 0.0828\n",
      "Epoch: 87/100...  Loss: 0.0669\n",
      "Epoch: 87/100...  Loss: 0.0698\n",
      "Epoch: 87/100...  Loss: 0.0715\n",
      "Epoch: 87/100...  Loss: 0.0625\n",
      "Epoch: 87/100...  Loss: 0.0732\n",
      "Epoch: 87/100...  Loss: 0.0855\n",
      "Epoch: 87/100...  Loss: 0.0803\n",
      "Epoch: 87/100...  Loss: 0.0739\n",
      "Epoch: 87/100...  Loss: 0.0774\n",
      "Epoch: 87/100...  Loss: 0.0631\n",
      "Epoch: 87/100...  Loss: 0.0537\n",
      "Epoch: 87/100...  Loss: 0.0672\n",
      "Epoch: 87/100...  Loss: 0.0655\n",
      "Epoch: 87/100...  Loss: 0.0700\n",
      "Epoch: 87/100...  Loss: 0.0692\n",
      "Epoch: 87/100...  Loss: 0.0643\n",
      "Epoch: 87/100...  Loss: 0.0647\n",
      "Epoch: 87/100...  Loss: 0.0630\n",
      "Epoch: 87/100...  Loss: 0.0717\n",
      "Epoch: 88/100...  Loss: 0.0679\n",
      "Epoch: 88/100...  Loss: 0.0668\n",
      "Epoch: 88/100...  Loss: 0.0678\n",
      "Epoch: 88/100...  Loss: 0.0773\n",
      "Epoch: 88/100...  Loss: 0.0665\n",
      "Epoch: 88/100...  Loss: 0.0693\n",
      "Epoch: 88/100...  Loss: 0.0593\n",
      "Epoch: 88/100...  Loss: 0.0696\n",
      "Epoch: 88/100...  Loss: 0.0678\n",
      "Epoch: 88/100...  Loss: 0.0748\n",
      "Epoch: 88/100...  Loss: 0.0623\n",
      "Epoch: 88/100...  Loss: 0.0685\n",
      "Epoch: 88/100...  Loss: 0.0748\n",
      "Epoch: 88/100...  Loss: 0.0670\n",
      "Epoch: 88/100...  Loss: 0.0545\n",
      "Epoch: 88/100...  Loss: 0.0639\n",
      "Epoch: 88/100...  Loss: 0.0608\n",
      "Epoch: 88/100...  Loss: 0.0751\n",
      "Epoch: 88/100...  Loss: 0.0699\n",
      "Epoch: 88/100...  Loss: 0.0661\n",
      "Epoch: 88/100...  Loss: 0.0836\n",
      "Epoch: 88/100...  Loss: 0.0764\n",
      "Epoch: 88/100...  Loss: 0.0671\n",
      "Epoch: 89/100...  Loss: 0.0342\n",
      "Epoch: 89/100...  Loss: 0.0727\n",
      "Epoch: 89/100...  Loss: 0.0658\n",
      "Epoch: 89/100...  Loss: 0.0633\n",
      "Epoch: 89/100...  Loss: 0.0707\n",
      "Epoch: 89/100...  Loss: 0.0596\n",
      "Epoch: 89/100...  Loss: 0.0654\n",
      "Epoch: 89/100...  Loss: 0.0665\n",
      "Epoch: 89/100...  Loss: 0.0664\n",
      "Epoch: 89/100...  Loss: 0.0504\n",
      "Epoch: 89/100...  Loss: 0.0756\n",
      "Epoch: 89/100...  Loss: 0.0647\n",
      "Epoch: 89/100...  Loss: 0.0661\n",
      "Epoch: 89/100...  Loss: 0.0621\n",
      "Epoch: 89/100...  Loss: 0.0785\n",
      "Epoch: 89/100...  Loss: 0.0720\n",
      "Epoch: 89/100...  Loss: 0.0754\n",
      "Epoch: 89/100...  Loss: 0.0726\n",
      "Epoch: 89/100...  Loss: 0.0711\n",
      "Epoch: 89/100...  Loss: 0.0713\n",
      "Epoch: 89/100...  Loss: 0.0621\n",
      "Epoch: 89/100...  Loss: 0.0736\n",
      "Epoch: 89/100...  Loss: 0.0687\n",
      "Epoch: 89/100...  Loss: 0.0698\n",
      "Epoch: 90/100...  Loss: 0.0596\n",
      "Epoch: 90/100...  Loss: 0.0810\n",
      "Epoch: 90/100...  Loss: 0.0638\n",
      "Epoch: 90/100...  Loss: 0.0597\n",
      "Epoch: 90/100...  Loss: 0.0600\n",
      "Epoch: 90/100...  Loss: 0.0668\n",
      "Epoch: 90/100...  Loss: 0.0819\n",
      "Epoch: 90/100...  Loss: 0.0663\n",
      "Epoch: 90/100...  Loss: 0.0682\n",
      "Epoch: 90/100...  Loss: 0.0705\n",
      "Epoch: 90/100...  Loss: 0.0669\n",
      "Epoch: 90/100...  Loss: 0.0813\n",
      "Epoch: 90/100...  Loss: 0.0681\n",
      "Epoch: 90/100...  Loss: 0.0679\n",
      "Epoch: 90/100...  Loss: 0.0664\n",
      "Epoch: 90/100...  Loss: 0.0660\n",
      "Epoch: 90/100...  Loss: 0.0687\n",
      "Epoch: 90/100...  Loss: 0.0673\n",
      "Epoch: 90/100...  Loss: 0.0590\n",
      "Epoch: 90/100...  Loss: 0.0622\n",
      "Epoch: 90/100...  Loss: 0.0715\n",
      "Epoch: 90/100...  Loss: 0.0598\n",
      "Epoch: 90/100...  Loss: 0.0642\n",
      "Epoch: 91/100...  Loss: 0.0330\n",
      "Epoch: 91/100...  Loss: 0.0690\n",
      "Epoch: 91/100...  Loss: 0.0675\n",
      "Epoch: 91/100...  Loss: 0.0705\n",
      "Epoch: 91/100...  Loss: 0.0601\n",
      "Epoch: 91/100...  Loss: 0.0684\n",
      "Epoch: 91/100...  Loss: 0.0737\n",
      "Epoch: 91/100...  Loss: 0.0742\n",
      "Epoch: 91/100...  Loss: 0.0529\n",
      "Epoch: 91/100...  Loss: 0.0662\n",
      "Epoch: 91/100...  Loss: 0.0619\n",
      "Epoch: 91/100...  Loss: 0.0677\n",
      "Epoch: 91/100...  Loss: 0.0665\n",
      "Epoch: 91/100...  Loss: 0.0697\n",
      "Epoch: 91/100...  Loss: 0.0604\n",
      "Epoch: 91/100...  Loss: 0.0650\n",
      "Epoch: 91/100...  Loss: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100...  Loss: 0.0570\n",
      "Epoch: 91/100...  Loss: 0.0619\n",
      "Epoch: 91/100...  Loss: 0.0564\n",
      "Epoch: 91/100...  Loss: 0.0706\n",
      "Epoch: 91/100...  Loss: 0.0740\n",
      "Epoch: 91/100...  Loss: 0.0757\n",
      "Epoch: 92/100...  Loss: 0.0029\n",
      "Epoch: 92/100...  Loss: 0.0553\n",
      "Epoch: 92/100...  Loss: 0.0588\n",
      "Epoch: 92/100...  Loss: 0.0602\n",
      "Epoch: 92/100...  Loss: 0.0631\n",
      "Epoch: 92/100...  Loss: 0.0603\n",
      "Epoch: 92/100...  Loss: 0.0607\n",
      "Epoch: 92/100...  Loss: 0.0523\n",
      "Epoch: 92/100...  Loss: 0.0659\n",
      "Epoch: 92/100...  Loss: 0.0854\n",
      "Epoch: 92/100...  Loss: 0.0706\n",
      "Epoch: 92/100...  Loss: 0.0647\n",
      "Epoch: 92/100...  Loss: 0.0715\n",
      "Epoch: 92/100...  Loss: 0.0711\n",
      "Epoch: 92/100...  Loss: 0.0603\n",
      "Epoch: 92/100...  Loss: 0.0726\n",
      "Epoch: 92/100...  Loss: 0.0708\n",
      "Epoch: 92/100...  Loss: 0.0741\n",
      "Epoch: 92/100...  Loss: 0.0640\n",
      "Epoch: 92/100...  Loss: 0.0611\n",
      "Epoch: 92/100...  Loss: 0.0684\n",
      "Epoch: 92/100...  Loss: 0.0647\n",
      "Epoch: 92/100...  Loss: 0.0638\n",
      "Epoch: 92/100...  Loss: 0.0651\n",
      "Epoch: 93/100...  Loss: 0.0417\n",
      "Epoch: 93/100...  Loss: 0.0687\n",
      "Epoch: 93/100...  Loss: 0.0556\n",
      "Epoch: 93/100...  Loss: 0.0639\n",
      "Epoch: 93/100...  Loss: 0.0576\n",
      "Epoch: 93/100...  Loss: 0.0710\n",
      "Epoch: 93/100...  Loss: 0.0779\n",
      "Epoch: 93/100...  Loss: 0.0748\n",
      "Epoch: 93/100...  Loss: 0.0762\n",
      "Epoch: 93/100...  Loss: 0.0626\n",
      "Epoch: 93/100...  Loss: 0.0612\n",
      "Epoch: 93/100...  Loss: 0.0574\n",
      "Epoch: 93/100...  Loss: 0.0626\n",
      "Epoch: 93/100...  Loss: 0.0517\n",
      "Epoch: 93/100...  Loss: 0.0599\n",
      "Epoch: 93/100...  Loss: 0.0704\n",
      "Epoch: 93/100...  Loss: 0.0603\n",
      "Epoch: 93/100...  Loss: 0.0544\n",
      "Epoch: 93/100...  Loss: 0.0645\n",
      "Epoch: 93/100...  Loss: 0.0685\n",
      "Epoch: 93/100...  Loss: 0.0639\n",
      "Epoch: 93/100...  Loss: 0.0738\n",
      "Epoch: 93/100...  Loss: 0.0677\n",
      "Epoch: 94/100...  Loss: 0.0103\n",
      "Epoch: 94/100...  Loss: 0.0647\n",
      "Epoch: 94/100...  Loss: 0.0701\n",
      "Epoch: 94/100...  Loss: 0.0677\n",
      "Epoch: 94/100...  Loss: 0.0637\n",
      "Epoch: 94/100...  Loss: 0.0555\n",
      "Epoch: 94/100...  Loss: 0.0774\n",
      "Epoch: 94/100...  Loss: 0.0548\n",
      "Epoch: 94/100...  Loss: 0.0574\n",
      "Epoch: 94/100...  Loss: 0.0635\n",
      "Epoch: 94/100...  Loss: 0.0698\n",
      "Epoch: 94/100...  Loss: 0.0703\n",
      "Epoch: 94/100...  Loss: 0.0782\n",
      "Epoch: 94/100...  Loss: 0.0763\n",
      "Epoch: 94/100...  Loss: 0.0542\n",
      "Epoch: 94/100...  Loss: 0.0626\n",
      "Epoch: 94/100...  Loss: 0.0616\n",
      "Epoch: 94/100...  Loss: 0.0596\n",
      "Epoch: 94/100...  Loss: 0.0589\n",
      "Epoch: 94/100...  Loss: 0.0553\n",
      "Epoch: 94/100...  Loss: 0.0695\n",
      "Epoch: 94/100...  Loss: 0.0617\n",
      "Epoch: 94/100...  Loss: 0.0594\n",
      "Epoch: 94/100...  Loss: 0.0654\n",
      "Epoch: 95/100...  Loss: 0.0428\n",
      "Epoch: 95/100...  Loss: 0.0596\n",
      "Epoch: 95/100...  Loss: 0.0614\n",
      "Epoch: 95/100...  Loss: 0.0646\n",
      "Epoch: 95/100...  Loss: 0.0582\n",
      "Epoch: 95/100...  Loss: 0.0683\n",
      "Epoch: 95/100...  Loss: 0.0608\n",
      "Epoch: 95/100...  Loss: 0.0698\n",
      "Epoch: 95/100...  Loss: 0.0577\n",
      "Epoch: 95/100...  Loss: 0.0619\n",
      "Epoch: 95/100...  Loss: 0.0779\n",
      "Epoch: 95/100...  Loss: 0.0614\n",
      "Epoch: 95/100...  Loss: 0.0558\n",
      "Epoch: 95/100...  Loss: 0.0639\n",
      "Epoch: 95/100...  Loss: 0.0899\n",
      "Epoch: 95/100...  Loss: 0.0622\n",
      "Epoch: 95/100...  Loss: 0.0647\n",
      "Epoch: 95/100...  Loss: 0.0573\n",
      "Epoch: 95/100...  Loss: 0.0592\n",
      "Epoch: 95/100...  Loss: 0.0708\n",
      "Epoch: 95/100...  Loss: 0.0626\n",
      "Epoch: 95/100...  Loss: 0.0535\n",
      "Epoch: 95/100...  Loss: 0.0577\n",
      "Epoch: 96/100...  Loss: 0.0144\n",
      "Epoch: 96/100...  Loss: 0.0708\n",
      "Epoch: 96/100...  Loss: 0.0570\n",
      "Epoch: 96/100...  Loss: 0.0550\n",
      "Epoch: 96/100...  Loss: 0.0710\n",
      "Epoch: 96/100...  Loss: 0.0517\n",
      "Epoch: 96/100...  Loss: 0.0728\n",
      "Epoch: 96/100...  Loss: 0.0638\n",
      "Epoch: 96/100...  Loss: 0.0473\n",
      "Epoch: 96/100...  Loss: 0.0687\n",
      "Epoch: 96/100...  Loss: 0.0556\n",
      "Epoch: 96/100...  Loss: 0.0617\n",
      "Epoch: 96/100...  Loss: 0.0681\n",
      "Epoch: 96/100...  Loss: 0.0631\n",
      "Epoch: 96/100...  Loss: 0.0541\n",
      "Epoch: 96/100...  Loss: 0.0642\n",
      "Epoch: 96/100...  Loss: 0.0619\n",
      "Epoch: 96/100...  Loss: 0.0656\n",
      "Epoch: 96/100...  Loss: 0.0794\n",
      "Epoch: 96/100...  Loss: 0.0616\n",
      "Epoch: 96/100...  Loss: 0.0614\n",
      "Epoch: 96/100...  Loss: 0.0573\n",
      "Epoch: 96/100...  Loss: 0.0640\n",
      "Epoch: 96/100...  Loss: 0.0584\n",
      "Epoch: 97/100...  Loss: 0.0444\n",
      "Epoch: 97/100...  Loss: 0.0593\n",
      "Epoch: 97/100...  Loss: 0.0571\n",
      "Epoch: 97/100...  Loss: 0.0571\n",
      "Epoch: 97/100...  Loss: 0.0738\n",
      "Epoch: 97/100...  Loss: 0.0661\n",
      "Epoch: 97/100...  Loss: 0.0698\n",
      "Epoch: 97/100...  Loss: 0.0605\n",
      "Epoch: 97/100...  Loss: 0.0573\n",
      "Epoch: 97/100...  Loss: 0.0573\n",
      "Epoch: 97/100...  Loss: 0.0767\n",
      "Epoch: 97/100...  Loss: 0.0586\n",
      "Epoch: 97/100...  Loss: 0.0644\n",
      "Epoch: 97/100...  Loss: 0.0613\n",
      "Epoch: 97/100...  Loss: 0.0549\n",
      "Epoch: 97/100...  Loss: 0.0538\n",
      "Epoch: 97/100...  Loss: 0.0607\n",
      "Epoch: 97/100...  Loss: 0.0550\n",
      "Epoch: 97/100...  Loss: 0.0480\n",
      "Epoch: 97/100...  Loss: 0.0761\n",
      "Epoch: 97/100...  Loss: 0.0607\n",
      "Epoch: 97/100...  Loss: 0.0644\n",
      "Epoch: 97/100...  Loss: 0.0718\n",
      "Epoch: 98/100...  Loss: 0.0188\n",
      "Epoch: 98/100...  Loss: 0.0523\n",
      "Epoch: 98/100...  Loss: 0.0629\n",
      "Epoch: 98/100...  Loss: 0.0594\n",
      "Epoch: 98/100...  Loss: 0.0633\n",
      "Epoch: 98/100...  Loss: 0.0730\n",
      "Epoch: 98/100...  Loss: 0.0625\n",
      "Epoch: 98/100...  Loss: 0.0604\n",
      "Epoch: 98/100...  Loss: 0.0591\n",
      "Epoch: 98/100...  Loss: 0.0509\n",
      "Epoch: 98/100...  Loss: 0.0575\n",
      "Epoch: 98/100...  Loss: 0.0537\n",
      "Epoch: 98/100...  Loss: 0.0560\n",
      "Epoch: 98/100...  Loss: 0.0723\n",
      "Epoch: 98/100...  Loss: 0.0619\n",
      "Epoch: 98/100...  Loss: 0.0668\n",
      "Epoch: 98/100...  Loss: 0.0511\n",
      "Epoch: 98/100...  Loss: 0.0578\n",
      "Epoch: 98/100...  Loss: 0.0600\n",
      "Epoch: 98/100...  Loss: 0.0515\n",
      "Epoch: 98/100...  Loss: 0.0644\n",
      "Epoch: 98/100...  Loss: 0.0709\n",
      "Epoch: 98/100...  Loss: 0.0599\n",
      "Epoch: 98/100...  Loss: 0.0769\n",
      "Epoch: 99/100...  Loss: 0.0548\n",
      "Epoch: 99/100...  Loss: 0.0527\n",
      "Epoch: 99/100...  Loss: 0.0490\n",
      "Epoch: 99/100...  Loss: 0.0568\n",
      "Epoch: 99/100...  Loss: 0.0531\n",
      "Epoch: 99/100...  Loss: 0.0589\n",
      "Epoch: 99/100...  Loss: 0.0526\n",
      "Epoch: 99/100...  Loss: 0.0562\n",
      "Epoch: 99/100...  Loss: 0.0686\n",
      "Epoch: 99/100...  Loss: 0.0763\n",
      "Epoch: 99/100...  Loss: 0.0491\n",
      "Epoch: 99/100...  Loss: 0.0593\n",
      "Epoch: 99/100...  Loss: 0.0647\n",
      "Epoch: 99/100...  Loss: 0.0643\n",
      "Epoch: 99/100...  Loss: 0.0669\n",
      "Epoch: 99/100...  Loss: 0.0646\n",
      "Epoch: 99/100...  Loss: 0.0664\n",
      "Epoch: 99/100...  Loss: 0.0593\n",
      "Epoch: 99/100...  Loss: 0.0595\n",
      "Epoch: 99/100...  Loss: 0.0653\n",
      "Epoch: 99/100...  Loss: 0.0597\n",
      "Epoch: 99/100...  Loss: 0.0618\n",
      "Epoch: 99/100...  Loss: 0.0555\n",
      "Epoch: 100/100...  Loss: 0.0211\n",
      "Epoch: 100/100...  Loss: 0.0715\n",
      "Epoch: 100/100...  Loss: 0.0705\n",
      "Epoch: 100/100...  Loss: 0.0570\n",
      "Epoch: 100/100...  Loss: 0.0488\n",
      "Epoch: 100/100...  Loss: 0.0630\n",
      "Epoch: 100/100...  Loss: 0.0679\n",
      "Epoch: 100/100...  Loss: 0.0485\n",
      "Epoch: 100/100...  Loss: 0.0571\n",
      "Epoch: 100/100...  Loss: 0.0596\n",
      "Epoch: 100/100...  Loss: 0.0582\n",
      "Epoch: 100/100...  Loss: 0.0552\n",
      "Epoch: 100/100...  Loss: 0.0661\n",
      "Epoch: 100/100...  Loss: 0.0534\n",
      "Epoch: 100/100...  Loss: 0.0655\n",
      "Epoch: 100/100...  Loss: 0.0534\n",
      "Epoch: 100/100...  Loss: 0.0655\n",
      "Epoch: 100/100...  Loss: 0.0758\n",
      "Epoch: 100/100...  Loss: 0.0566\n",
      "Epoch: 100/100...  Loss: 0.0473\n",
      "Epoch: 100/100...  Loss: 0.0587\n",
      "Epoch: 100/100...  Loss: 0.0518\n",
      "Epoch: 100/100...  Loss: 0.0671\n",
      "Epoch: 100/100...  Loss: 0.0523\n"
     ]
    }
   ],
   "source": [
    "# hiperparámetro: número de épocas\n",
    "epochs = 100\n",
    "print_every = 40\n",
    "steps = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    # en cada iteración del for cargamos un batch\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        # Aplanar las imagenes de MNIST\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        # Reiniciar el gradiente\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pase frontal de la red\n",
    "        output = model.forward(images)\n",
    "        \n",
    "        # Estimar la perdida\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backprogation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Actualizamos los pesos\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Guardamos la perdida para control del entrenamiento\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # imprimimos cada 40 lotes\n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, veamos que tan bien está clasificando la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "[1] Udacity Computer vision Nanodegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
